{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#TO work with fb meme dataset, factory reset the runtime and then use previously created csv dataset\nimport os\nos.environ['KAGGLE_CONFIG_DIR'] = '/content/'\n!kaggle datasets download -d parthplc/facebook-hateful-meme-dataset\npassword = 'KexZs4tn8hujn1nK'\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"63yPNNSfOFqP","outputId":"ff675794-145a-4059-de2b-6d66b5574cda","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip -qq /kaggle/working/facebook-hateful-meme-dataset.zip","metadata":{"id":"aMkOf2jmRtGC","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/openai/CLIP.git","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YnB-m88xQNEZ","outputId":"a9965b2b-2bab-4626-b005-322dd3db9bb7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm /kaggle/working/facebook-hateful-meme-dataset.zip","metadata":{"id":"wJTQULflRxd-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://drive.google.com/drive/folders/1RzxW8-kjGVR21A2RriEg9PlDfW9AYhDB?usp=sharing","metadata":{"id":"_6zlEJLPSG1Q","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !gdown 1RzxW8-kjGVR21A2RriEg9PlDfW9AYhDB","metadata":{"id":"znu4XE2rRr3B","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://drive.google.com/drive/folders/1RzxW8-kjGVR21A2RriEg9PlDfW9AYhDB?usp=share_link","metadata":{"id":"T-5xOCLzS7pE","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install gdown==4.6.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install --upgrade --no-cache-dir gdown","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gdown","metadata":{"id":"mrvvvAouTSRZ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gdown.download_folder(id='1RzxW8-kjGVR21A2RriEg9PlDfW9AYhDB',use_cookies=True, remaining_ok=True)\n# # https://drive.google.com/drive/folders/1RzxW8-kjGVR21A2RriEg9PlDfW9AYhDB?usp=sharing\n\n\n\n!gdown --folder '1RzxW8-kjGVR21A2RriEg9PlDfW9AYhDB'","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ASDHVClvTSTP","outputId":"a94924c1-6d70-4ecc-d05c-1f46f1725cc0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\nimport random\nimport torch\nimport numpy as np\nimport os\nfrom tqdm import tqdm\ntorch.use_deterministic_algorithms(True)\ndef set_seed(seed):\n\n    random.seed(seed)     # python random generator\n    np.random.seed(seed)  # numpy random generator\n\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n\nfrom PIL import Image\n\n\n\nimport torch\nimport clip\nfrom PIL import Image\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel, preprocess = clip.load(\"ViT-B/32\", device=device)\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Simulated batch sizes and vector dimensions\nbatch_size = 32\nvector_dim = 1024\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nclass fusion(nn.Module):\n    def __init__(self,img_feat_size, txt_feat_size, is_first, K, O, DROPOUT_R):\n        super(fusion, self).__init__()\n        #self.__C = __C\n        self.K = K\n        self.O = O\n        self.DROPOUT_R = DROPOUT_R\n\n        self.is_first = is_first\n        self.proj_i = nn.Linear(img_feat_size, K * O)\n        self.proj_t = nn.Linear(txt_feat_size, K * O)\n\n        self.dropout = nn.Dropout(DROPOUT_R)\n        self.pool = nn.AvgPool1d(K, stride = K)\n\n    def forward(self, img_feat, txt_feat, exp_in=1):\n\n        batch_size = img_feat.shape[0]\n        img_feat = self.proj_i(img_feat)\n        txt_feat = self.proj_t(txt_feat)\n\n        exp_out = img_feat * txt_feat\n        exp_out = self.dropout(exp_out) if self.is_first else self.dropout(exp_out * exp_in)\n        z = self.pool(exp_out) * self.K\n        z = F.normalize(z.view(batch_size, -1))\n        z = z.view(batch_size, -1, self.O)\n        return z\n\nimport os","metadata":{"id":"-SgbHGW7PNze","execution":{"iopub.status.busy":"2024-06-22T18:22:22.226860Z","iopub.execute_input":"2024-06-22T18:22:22.227529Z","iopub.status.idle":"2024-06-22T18:22:27.950705Z","shell.execute_reply.started":"2024-06-22T18:22:22.227498Z","shell.execute_reply":"2024-06-22T18:22:27.949802Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install jsonlines","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z40kMW20UjjK","outputId":"51bbb208-c905-4ab2-f9e0-1c8dd99c54f3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import jsonlines\n\nid2text = {}\nwith jsonlines.open('/kaggle/working/data/train.jsonl') as f:\n    for line in tqdm(f):\n\n        id2text[str(line['img']).split('/')[1]] = line['text']\n\nimport os\nimport json\nimport pickle\nfrom tqdm import tqdm\nimport requests\nimport pandas as pd\n\n#nlp = spacy.load(\"en_core_web_sm\")\n\n\n\nprefix = '/kaggle/working/ijcai_ckpts/tensors/'\nim_tensor = torch.load(prefix+'im_tensor.pt')\nim_tensor_ = torch.load(prefix+'im_tensor_.pt')\ntx_tensor = torch.load(prefix+'tx_tensor.pt')\ntx_tensor_ = torch.load(prefix+'tx_tensor_.pt')\n\ngl = torch.load(prefix+'gl.pt')\ngl_ = torch.load(prefix+'gl_.pt')\n\nkb_fb = torch.load('/kaggle/working/ijcai_ckpts/kb_fb.pt')\nimg_id = torch.load(prefix+'img_id.pt')\nimg_id_ = torch.load(prefix+'img_id_.pt')\n\nimport torch\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eXb7Lt5tPN1r","outputId":"e92ac4ce-2324-4177-cf48-759ccffb60a6","execution":{"iopub.status.busy":"2024-06-22T18:22:30.939589Z","iopub.execute_input":"2024-06-22T18:22:30.940192Z","iopub.status.idle":"2024-06-22T18:22:31.448365Z","shell.execute_reply.started":"2024-06-22T18:22:30.940161Z","shell.execute_reply":"2024-06-22T18:22:31.447583Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"8500it [00:00, 227941.10it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"class TinyModel(torch.nn.Module):\n\n    def __init__(self, mdl, mdl_rand, rand=False):\n        super(TinyModel, self).__init__()\n        if rand:\n            self.linear1 = nn.Sequential(nn.Linear(1024, 256), nn.ReLU(), nn.Linear(256, 512))\n        else:\n            self.linear1 = mdl_rand\n        self.activation = torch.nn.ReLU()\n        self.linear2 = torch.nn.Linear(512, 128)\n        self.linear3 = torch.nn.Linear(128, 2)\n        self.rand = rand\n        self.softmax = torch.nn.Softmax()\n        self.proj = torch.nn.Linear(512,768)\n        # self.proj = torch.nn.Linear(512,5120)\n\n    def forward(self, x, y):\n        joint_tensor = torch.cat((x, y), dim=1)\n        if self.rand:\n            m_ = self.linear1(joint_tensor)\n        else:\n            x = x.unsqueeze(1)\n            y = y.unsqueeze(1)\n            m_ = self.linear1(x, y).squeeze(dim=1)\n        m = self.activation(m_)\n        m = self.linear3(self.linear2(m))\n        # m = self.softmax(m)\n        return m, self.proj(m_)\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass CustomDataset(Dataset):\n    def __init__(self, tensor1, tensor2, gold_label, ids):\n        self.tensor1 = tensor1\n        self.tensor2 = tensor2\n        self.gl = gold_label\n        self.ids = ids\n\n    def __len__(self):\n        return len(self.tensor1)\n\n    def __getitem__(self, idx):\n        return self.tensor1[idx], self.tensor2[idx], self.gl[idx], self.ids[idx]\n\n# def collate_fn(batch):\n#     tensor1_batch, tensor2_batch = zip(*batch)\n#     return torch.stack(tensor1_batch), torch.stack(tensor2_batch)\n\n# Create your tensors\n#N = 100  # Example number of samples\ntensor1 = im_tensor\ntensor2 = tx_tensor\n\n# Create a custom dataset\ncustom_dataset = CustomDataset(tensor1, tensor2, gl, img_id)\ntrain_size = int(0.8 * len(custom_dataset))\ntest_size = len(custom_dataset) - train_size\n","metadata":{"id":"9jPoA9gWPN37","execution":{"iopub.status.busy":"2024-06-22T18:22:32.181807Z","iopub.execute_input":"2024-06-22T18:22:32.182342Z","iopub.status.idle":"2024-06-22T18:22:32.197284Z","shell.execute_reply.started":"2024-06-22T18:22:32.182312Z","shell.execute_reply":"2024-06-22T18:22:32.196115Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"set_seed(42)\ntrain_dataset, test_dataset = torch.utils.data.random_split(custom_dataset, [train_size, test_size], generator=torch.Generator().manual_seed(42))\n\n# Create a DataLoader with your collate_fn\nbatch_size = 4\nimport torch\ntorch.manual_seed(42)\n\n\ndef seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n\ng = torch.Generator()\ng.manual_seed(42)\n\nset_seed(42)\ndataloader = DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=2,\n    worker_init_fn=seed_worker,\n    generator=g,\n)\n\n\n\n# dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n\n# Iterate through the DataLoader\ncounter = 0\nfor batch_tensor1, batch_tensor2, b3, b4 in dataloader:\n    print(\"Tensor 1 batch shape:\", batch_tensor1.shape)\n    print(\"Tensor 2 batch shape:\", batch_tensor2.shape)\n    print(\"Tensor 3 batch shape:\", b3.shape)\n    print(\"Tensor 4 batch shape:\", b4)\n    print(\"-\" * 30)\n    counter+=1\n    if counter==10:\n        break\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ut-dSbDMPN6I","outputId":"a359cbdc-dc01-4621-8d59-4f1cbfbd8901","execution":{"iopub.status.busy":"2024-06-22T18:22:33.269826Z","iopub.execute_input":"2024-06-22T18:22:33.270181Z","iopub.status.idle":"2024-06-22T18:22:33.406965Z","shell.execute_reply.started":"2024-06-22T18:22:33.270155Z","shell.execute_reply":"2024-06-22T18:22:33.405846Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Tensor 1 batch shape: torch.Size([4, 512])\nTensor 2 batch shape: torch.Size([4, 512])\nTensor 3 batch shape: torch.Size([4])\nTensor 4 batch shape: ('img/24859.png', 'img/96235.png', 'img/72084.png', 'img/21653.png')\n------------------------------\nTensor 1 batch shape: torch.Size([4, 512])\nTensor 2 batch shape: torch.Size([4, 512])\nTensor 3 batch shape: torch.Size([4])\nTensor 4 batch shape: ('img/58096.png', 'img/78215.png', 'img/38427.png', 'img/75016.png')\n------------------------------\nTensor 1 batch shape: torch.Size([4, 512])\nTensor 2 batch shape: torch.Size([4, 512])\nTensor 3 batch shape: torch.Size([4])\nTensor 4 batch shape: ('img/10976.png', 'img/63057.png', 'img/31764.png', 'img/95763.png')\n------------------------------\nTensor 1 batch shape: torch.Size([4, 512])\nTensor 2 batch shape: torch.Size([4, 512])\nTensor 3 batch shape: torch.Size([4])\nTensor 4 batch shape: ('img/49316.png', 'img/62439.png', 'img/29354.png', 'img/19532.png')\n------------------------------\nTensor 1 batch shape: torch.Size([4, 512])\nTensor 2 batch shape: torch.Size([4, 512])\nTensor 3 batch shape: torch.Size([4])\nTensor 4 batch shape: ('img/81576.png', 'img/21486.png', 'img/23504.png', 'img/74956.png')\n------------------------------\nTensor 1 batch shape: torch.Size([4, 512])\nTensor 2 batch shape: torch.Size([4, 512])\nTensor 3 batch shape: torch.Size([4])\nTensor 4 batch shape: ('img/07839.png', 'img/30487.png', 'img/97643.png', 'img/57412.png')\n------------------------------\nTensor 1 batch shape: torch.Size([4, 512])\nTensor 2 batch shape: torch.Size([4, 512])\nTensor 3 batch shape: torch.Size([4])\nTensor 4 batch shape: ('img/58924.png', 'img/64720.png', 'img/09267.png', 'img/48309.png')\n------------------------------\nTensor 1 batch shape: torch.Size([4, 512])\nTensor 2 batch shape: torch.Size([4, 512])\nTensor 3 batch shape: torch.Size([4])\nTensor 4 batch shape: ('img/82104.png', 'img/43190.png', 'img/73192.png', 'img/85496.png')\n------------------------------\nTensor 1 batch shape: torch.Size([4, 512])\nTensor 2 batch shape: torch.Size([4, 512])\nTensor 3 batch shape: torch.Size([4])\nTensor 4 batch shape: ('img/09462.png', 'img/75462.png', 'img/19753.png', 'img/37928.png')\n------------------------------\nTensor 1 batch shape: torch.Size([4, 512])\nTensor 2 batch shape: torch.Size([4, 512])\nTensor 3 batch shape: torch.Size([4])\nTensor 4 batch shape: ('img/05781.png', 'img/48756.png', 'img/68715.png', 'img/62705.png')\n------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2LMHeadModel\n\nimport gc\ngc.collect()\ntorch.cuda.empty_cache()\n\ndef get_tokens(prpmt,begin=False):\n    set_seed(42)\n    if begin:\n        prepended_inp = [tokenizer1.encode(i) for i in prpmt]\n    else:\n        prepended_inp = [tokenizer1.encode(i) for i in prpmt]\n    max_len = max([len(i) for i in prepended_inp])\n    #print(max_len)\n    attn_mask = []\n    bs = len(prpmt)\n    for i in range(bs):\n        tmp_len = max_len - len(prepended_inp[i])\n        tmp_mask = torch.tensor([1]* len(prepended_inp[i]) + [0]* tmp_len)\n        attn_mask.append(tmp_mask)\n        extra_tokens = tokenizer1.encode(tokenizer1.eos_token)*tmp_len\n        prepended_inp[i] = prepended_inp[i]+extra_tokens\n\n    attn_mask = torch.stack(attn_mask)\n    #print(prepended_inp)\n    #print(attn_mask, attn_mask.shape)\n    fin = []\n    for i in prepended_inp:\n        inter = []\n        for j in i:\n            inter.append(E[j,:])\n        fin.append(torch.stack(inter))\n\n\n\n\n\n\n    return torch.stack(fin), torch.tensor(prepended_inp), attn_mask\n\nfrom sklearn.metrics import *\n","metadata":{"id":"5QVW_NMOPN97","execution":{"iopub.status.busy":"2024-06-22T18:22:33.769709Z","iopub.execute_input":"2024-06-22T18:22:33.770116Z","iopub.status.idle":"2024-06-22T18:22:35.300051Z","shell.execute_reply.started":"2024-06-22T18:22:33.770082Z","shell.execute_reply":"2024-06-22T18:22:35.299058Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"_9n42MTCWCaI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_performance_test():\n    torch.use_deterministic_algorithms(mode=True)\n    set_seed(42)\n    tinymodel.eval()\n    model1.eval()\n    #set_seed(42)\n    all_labs = []\n    all_labs_clf = []\n    counter = 0\n    for ii,ti, gol, ids in tqdm(test_dataset):\n\n        #     print(0/0)\n        ti = ti.unsqueeze(0)\n        ii = ii.unsqueeze(0)\n        gol = [gol]\n        ids = [ids]\n        # print(batch_model1, batch_model1)\n\n        ids = list(map(lambda x: x.split('/')[1], ids))\n        #         ids_ = []\n        #         for i in range(len(ids)):\n        #             kbs = ids[i].split('[KB]')\n        #             caps = ids[i].split('[CAPTION]')[-1]\n        #             try:\n        #                 kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n        #             except IndexError as e:\n        #                 kb = '[CAPTION] '+ caps\n        #             ids_.append(kb)\n        #         ids = ids_\n\n        ids_ = []\n        for i in range(len(ids)):\n            kbs = ids[i].split('[KB]')\n            #print('kbs ', kbs)\n            caps = ids[i].split('[CAPTION]')[-1]\n            #print(caps)\n            kb = ''\n            if len(kbs)>3:\n                kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n            elif len(kbs)==3:\n                #print('in len3')\n                kb = '[KB] '+kbs[1]\n                caps = kbs[2].split('[CAPTION]')\n                kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n            elif len(kbs)==2:\n                #print('in len 1')\n                caps = kbs[1].split('[CAPTION]')\n                kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n            elif len(kbs)==1:\n                kb = kbs[0].strip()\n                #print('int ', kb)\n\n\n\n            ids_.append(kb)\n\n        ids = ids_\n\n\n\n        #         print(ids)\n        texts = [id2text[i] for i in ids]\n        ids = [kb_fb[i] for i in ids]\n\n        #     prpmt = []\n        #     for i,j in zip(ids,texts):\n        #         prpmt.append(i+'. The meme text reads :'+j + '. Classifier thinks the meme is')\n\n\n\n        i = ii.float().to(device)\n        t = ti.float().to(device)\n        batch_size = i.shape[0]\n        with torch.no_grad():\n            logits, m = tinymodel(i,t)\n        # print(m)\n        m = m.unsqueeze(dim=1)\n        all_labs_clf.append(logits.argmax(dim=-1)[0].item())\n        #         prmpt0, lab0 = get_tokens([tokenizer1.bos_token]*batch_size, begin=True)\n\n        #         print(prmpt0.shape)\n\n        gumbel_logits = F.gumbel_softmax(logits, tau=1, hard=True)\n        # print(gumbel_logits)\n        agmx = gumbel_logits.argmax(dim=1)\n\n        # print(agmx, logits.argmax(dim=1))\n        #         prpmt = ['model thinks the meme is ']*batch_size\n\n        #portion1,lab1, a1 = get_tokens(prpmt)\n\n        portion2,lab3, _ = get_tokens(['output of the classifier multimodal embedding is ']*batch_size)\n        lab4 = [tokenizer1.encode('-')[:] for i in range(batch_size)]\n        lab4 = torch.tensor(lab4)\n\n        # portion3 = get_tokens(['the meme is actually'])\n\n\n\n\n\n\n        kk = []\n        labs_verbalized = []\n        # batch_prompt = ['the model thinks the meme is ']*32\n        lab2 = []\n        for i in gumbel_logits:\n            agmx = i.argmax()\n            # print(agmx)\n            # print(dix[agmx.item()])\n            tokenized_ = tokenizer1.encode(dix[agmx.item()])[:]\n            labs_verbalized.append(dix[agmx.item()])\n            # print(tokenized_)\n            lab2.append(tokenized_)\n            embedding = E[tokenized_[0]]\n            one_hot = i.view(-1, 1)\n            # print(embedding.shape, one_hot, one_hot.shape)\n\n            e = torch.sum(one_hot*embedding.to(device), dim=0)\n            kk.append(e)\n        lab2 = torch.tensor(lab2)\n        prpmt = []\n        for i,j,z in zip(ids,texts,labs_verbalized):\n            prpmt.append(i+'. The meme text reads :'+j + '. Classifier thinks the meme is {}'.format(z))\n            #all_labs_clf.append(z)\n        portion1,lab1, a1 = get_tokens(prpmt)\n        string = ['the meme is actually']\n        portion3,lab5,_ = get_tokens(string)\n        inp_embed = torch.stack(kk).unsqueeze(dim=1)\n        # print(inp_embed)\n        # print(inp_embed.shape)\n        # print(portion1.shape,inp_embed.shape,portion2.shape,m.shape,portion3.shape)\n\n        final_embeds = torch.cat((portion1,inp_embed,portion2,m,portion3),dim=1)\n        # print(final_embeds.shape)\n        # print(lab1.shape, lab2.shape, lab3.shape, lab4.shape, lab5.shape)\n        labs_shape = torch.cat((lab2,lab3,lab4,lab5),dim=1).shape\n        remaining_mask = torch.ones(labs_shape[0], labs_shape[1]).long()\n        #print(a1)\n        #print(remaining_mask)\n\n        full_mask = torch.cat((a1,remaining_mask),dim=1)\n        #print('fm ', full_mask.shape)\n        labs = torch.cat((lab1,lab2,lab3,lab4,lab5),dim=1).to('cuda')\n        #print(full_mask)\n        #print(0/0)\n        #         print(final_embeds.shape, labs.shape)\n        #         print(0/0)\n        with torch.no_grad():\n            output2 = model1(inputs_embeds = final_embeds.float(), labels = labs.long(), attention_mask=full_mask.to('cuda'))\n        # print(output2.loss)\n        # print(0/0)\n        loss_lm = output2.loss\n        #print(tokenizer1.batch_decode(output2.logits.argmax(dim=-1)))\n\n        #print(loss_lm)\n        llm_lab = tokenizer1.decode(output2.logits.argmax(dim=-1)[0][-1])\n        all_labs.append(llm_lab)\n        counter+=1\n        #if counter==10:\n        #    break\n\n    return all_labs, all_labs_clf\n","metadata":{"id":"XOGIp-cOWCeK","execution":{"iopub.status.busy":"2024-06-22T18:22:35.302038Z","iopub.execute_input":"2024-06-22T18:22:35.302804Z","iopub.status.idle":"2024-06-22T18:22:35.328021Z","shell.execute_reply.started":"2024-06-22T18:22:35.302766Z","shell.execute_reply":"2024-06-22T18:22:35.327117Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"gl_test  = []\nfor _,_,g,_ in test_dataset:\n    gl_test.append(g)\n\n\n\nimport torch\n#os.environ['CUBLAS_WORKSPACE_CONFIG']=:4096:8\ntorch.use_deterministic_algorithms(True)\nset_seed(42)\nimport numpy as np\nmodel1_name = 'gpt2'\ntokenizer1 = GPT2Tokenizer.from_pretrained(model1_name)\nmodel1 = GPT2LMHeadModel.from_pretrained(model1_name,output_hidden_states=True).to(device)\nmdl = fusion(512,512,True,256,512,0.1).to(device)\nmdl_rand = fusion(512,512,True,256,512,0.1).to(device)\ntinymodel = TinyModel(mdl,mdl_rand,rand=False).to(device)\n\nmodel1.load_state_dict(torch.load('/kaggle/working/ijcai_ckpts/ckpt_ijcai/gpt2_backbone.pt'), strict=False)\ntinymodel.load_state_dict(torch.load('/kaggle/working/ijcai_ckpts/ckpt_ijcai/classifier (1).pt'), strict=False)\n\n\n\nE = model1.transformer.wte.weight.detach()\nmodel1.eval()\ntinymodel.eval()\ndix = {0:'normal', 1:'offensive'}\nal, alc = get_performance_test()\nl2l = {'normal':0, 'offensive':1}\n\nal_ = list(map(lambda x: l2l[x.strip()], al))\nprint(f1_score(gl_test, al_, average='macro'), f1_score(gl_test, alc, average='macro'))\nprint(accuracy_score(gl_test, al_), accuracy_score(gl_test, alc))\n","metadata":{"id":"qL9orDP7VRNy","execution":{"iopub.status.busy":"2024-06-22T18:22:35.473872Z","iopub.execute_input":"2024-06-22T18:22:35.474245Z","iopub.status.idle":"2024-06-22T18:23:30.128157Z","shell.execute_reply.started":"2024-06-22T18:22:35.474217Z","shell.execute_reply":"2024-06-22T18:23:30.127155Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"100%|██████████| 1700/1700 [00:50<00:00, 33.99it/s]","output_type":"stream"},{"name":"stdout","text":"0.7346009738085326 0.7191584967320261\n0.7564705882352941 0.7411764705882353\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f1_score(gl_test, alc, average='macro'))\naccuracy_score(gl_test, alc)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-22T18:25:39.216932Z","iopub.execute_input":"2024-06-22T18:25:39.217611Z","iopub.status.idle":"2024-06-22T18:25:39.232206Z","shell.execute_reply.started":"2024-06-22T18:25:39.217578Z","shell.execute_reply":"2024-06-22T18:25:39.231234Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"0.7191584967320261\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0.7411764705882353"},"metadata":{}}]},{"cell_type":"code","source":"def prepare_inputs_for_generation(input_ids, past_key_values=None, **kwargs):\n    token_type_ids = kwargs.get(\"token_type_ids\", None)\n    # only last token for inputs_ids if past_key_values is defined in kwargs\n    if past_key_values:\n        input_ids = input_ids[:, -1].unsqueeze(-1)\n        if token_type_ids is not None:\n            token_type_ids = token_type_ids[:, -1].unsqueeze(-1)\n\n    attention_mask = kwargs.get(\"attention_mask\", None)\n    position_ids = kwargs.get(\"position_ids\", None)\n\n    if attention_mask is not None and position_ids is None:\n        # create position_ids on the fly for batch generation\n        position_ids = attention_mask.long().cumsum(-1) - 1\n        position_ids.masked_fill_(attention_mask == 0, 1)\n        if past_key_values:\n            position_ids = position_ids[:, -1].unsqueeze(-1)\n    else:\n        position_ids = None\n\n    # !!!!!!!!!!!!!!!!!!! start: modified vs original, to pass inputs_embeds when they are available\n    if \"inputs_embeds\" in kwargs and past_key_values is None:  # we only want to use them in the 1st generation step\n        model_inputs = {\"inputs_embeds\": inputs_embeds}\n    else:\n        model_inputs = {\"input_ids\": input_ids}\n    model_inputs.update({\n        \"past_key_values\": past_key_values,\n        \"use_cache\": kwargs.get(\"use_cache\"),\n        \"position_ids\": position_ids,\n        \"attention_mask\": attention_mask,\n        \"token_type_ids\": token_type_ids,\n    })\n    return model_inputs\n    # !!!!!!!!!!!!!!!!!!! end: modified vs original, to pass inputs_embeds when they are available\n","metadata":{"id":"5ui50TlgVkYp","execution":{"iopub.status.busy":"2024-06-22T18:25:42.448706Z","iopub.execute_input":"2024-06-22T18:25:42.449644Z","iopub.status.idle":"2024-06-22T18:25:42.458876Z","shell.execute_reply.started":"2024-06-22T18:25:42.449608Z","shell.execute_reply":"2024-06-22T18:25:42.457724Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from matplotlib.pyplot import imshow\nfrom IPython.display import display\n","metadata":{"id":"buIYfhRFXVvi","execution":{"iopub.status.busy":"2024-06-22T18:25:43.831781Z","iopub.execute_input":"2024-06-22T18:25:43.832626Z","iopub.status.idle":"2024-06-22T18:25:43.836868Z","shell.execute_reply.started":"2024-06-22T18:25:43.832595Z","shell.execute_reply":"2024-06-22T18:25:43.835753Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"set_seed(42)","metadata":{"id":"QRuJaInFXYzr","execution":{"iopub.status.busy":"2024-06-22T18:30:29.547364Z","iopub.execute_input":"2024-06-22T18:30:29.547777Z","iopub.status.idle":"2024-06-22T18:30:29.552330Z","shell.execute_reply.started":"2024-06-22T18:30:29.547726Z","shell.execute_reply":"2024-06-22T18:30:29.551348Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# test_dataset_1 = test_dataset\n\n\n# d_ids = {}","metadata":{"id":"uY9nEJgvXcex","execution":{"iopub.status.busy":"2024-06-22T18:30:32.910933Z","iopub.execute_input":"2024-06-22T18:30:32.911590Z","iopub.status.idle":"2024-06-22T18:30:32.915523Z","shell.execute_reply.started":"2024-06-22T18:30:32.911560Z","shell.execute_reply":"2024-06-22T18:30:32.914566Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"TOPK = 500\nEPSILON = 0.1 # it must be within [0, 1], otherwise this stage will be skipped\nCLIP_FILTER = True\nOP_PRESERVE = True\nCUTOFF = 10","metadata":{"id":"EuO2Gz0WYpt6","execution":{"iopub.status.busy":"2024-06-22T18:30:33.717696Z","iopub.execute_input":"2024-06-22T18:30:33.718478Z","iopub.status.idle":"2024-06-22T18:30:33.722768Z","shell.execute_reply.started":"2024-06-22T18:30:33.718448Z","shell.execute_reply":"2024-06-22T18:30:33.721762Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"set_seed(42)\n_, test_dataset_1 = torch.utils.data.random_split(test_dataset, [1690, 10], generator=torch.Generator().manual_seed(42))\n","metadata":{"id":"S1kiT1HdYp0K","execution":{"iopub.status.busy":"2024-06-22T18:30:34.758122Z","iopub.execute_input":"2024-06-22T18:30:34.758936Z","iopub.status.idle":"2024-06-22T18:30:34.763719Z","shell.execute_reply.started":"2024-06-22T18:30:34.758902Z","shell.execute_reply":"2024-06-22T18:30:34.762802Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"\ndef get_performance_test(second_pass=False, llm_label='', prev_prob = 0, prev_lab = '', counter=0):\n    #print(test_dataset)\n\n\n    torch.use_deterministic_algorithms(True)\n    set_seed(42)\n\n    if second_pass:\n        #print('IN SECOND PASS')\n        test_dataset_ = [test_dataset_1[counter]]\n\n\n    else:\n        test_dataset_ = test_dataset_1\n\n    tinymodel.eval()\n    model1.eval()\n    all_labs = []\n    all_labs_clf = []\n    counter = 0\n\n    if counter==0 and not second_pass:\n        print('USING TopK {}, eps {}, CLIP Filter {}, Output Filter {} d_ids {}'.format(TOPK, EPSILON, CLIP_FILTER, OP_PRESERVE, d_ids))\n\n\n    for ii,ti, gol, ids in tqdm(test_dataset_,disable=second_pass):\n\n        #     print(0/0)\n        #print(ids)\n        tmp_id = ids\n\n        #         raw_image = Image.open('./data/'+ids)\n        #         if not second_pass:\n        #             display(raw_image)\n        ti = ti.unsqueeze(0)\n        ii = ii.unsqueeze(0)\n        gol = [gol]\n        ids = [ids]\n        # print(batch_model1, batch_model1)\n\n        ids = list(map(lambda x: x.split('/')[1], ids))\n        #         ids_ = []\n        #         for i in range(len(ids)):\n        #             kbs = ids[i].split('[KB]')\n        #             caps = ids[i].split('[CAPTION]')[-1]\n        #             try:\n        #                 kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n        #             except IndexError as e:\n        #                 kb = '[CAPTION] '+ caps\n        #             ids_.append(kb)\n        #         ids = ids_\n\n        ids_ = []\n        for i in range(len(ids)):\n            kbs = ids[i].split('[KB]')\n            #print('kbs ', kbs)\n            caps = ids[i].split('[CAPTION]')[-1]\n            #print(caps)\n            kb = ''\n            if len(kbs)>3:\n                kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n            elif len(kbs)==3:\n                #print('in len3')\n                kb = '[KB] '+kbs[1]\n                caps = kbs[2].split('[CAPTION]')\n                kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n            elif len(kbs)==2:\n                #print('in len 1')\n                caps = kbs[1].split('[CAPTION]')\n                kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n            elif len(kbs)==1:\n                kb = kbs[0].strip()\n                #print('int ', kb)\n\n\n\n            ids_.append(kb)\n\n        ids = ids_\n\n\n\n        #         print(ids)\n        texts = [id2text[i] for i in ids]\n        ids = [kb_fb[i] for i in ids]\n        if second_pass:\n            ids = llm_label\n        #print('ids', ids)\n        #print('text', texts)\n\n        #     prpmt = []\n        #     for i,j in zip(ids,texts):\n        #         prpmt.append(i+'. The meme text reads :'+j + '. Classifier thinks the meme is')\n\n\n\n        i = ii.float().to(device)\n        t = ti.float().to(device)\n        batch_size = i.shape[0]\n        #with torch.no_grad():\n        logits, m = tinymodel(i,t)\n        # print(m)\n        m = m.unsqueeze(dim=1)\n        all_labs_clf.append(logits.argmax(dim=-1)[0].item())\n        #         prmpt0, lab0 = get_tokens([tokenizer1.bos_token]*batch_size, begin=True)\n\n        #         print(prmpt0.shape)\n\n        gumbel_logits = F.gumbel_softmax(logits, tau=1, hard=True)\n        # print(gumbel_logits)\n        agmx = gumbel_logits.argmax(dim=1)\n\n        # print(agmx, logits.argmax(dim=1))\n        #         prpmt = ['model thinks the meme is ']*batch_size\n\n        #portion1,lab1, a1 = get_tokens(prpmt)\n\n        portion2,lab3, _ = get_tokens(['output of the classifier multimodal embedding is ']*batch_size)\n        lab4 = [tokenizer1.encode('-')[:] for i in range(batch_size)]\n        lab4 = torch.tensor(lab4)\n\n        # portion3 = get_tokens(['the meme is actually'])\n\n\n\n\n\n\n        kk = []\n        labs_verbalized = []\n        # batch_prompt = ['the model thinks the meme is ']*32\n        lab2 = []\n        for i in gumbel_logits:\n            agmx = i.argmax()\n            # print(agmx)\n            # print(dix[agmx.item()])\n            tokenized_ = tokenizer1.encode(dix[agmx.item()])[:]\n            labs_verbalized.append(dix[agmx.item()])\n            # print(tokenized_)\n            lab2.append(tokenized_)\n            embedding = E[tokenized_[0]]\n            one_hot = i.view(-1, 1)\n            # print(embedding.shape, one_hot, one_hot.shape)\n\n            e = torch.sum(one_hot*embedding.to(device), dim=0)\n            kk.append(e)\n        lab2 = torch.tensor(lab2)\n        prpmt = []\n        for i,j,z in zip(ids,texts,labs_verbalized):\n            prpmt.append(i+'. The meme text reads :'+j + '. Classifier thinks the meme is {}'.format(z))\n            #all_labs_clf.append(z)\n        portion1,lab1, a1 = get_tokens(prpmt)\n\n        string = ['the meme is actually']\n        #         if second_pass:\n        #             string[0] += '{} because of'.format(llm_label)\n        #             print(string)\n        portion3,lab5,_ = get_tokens(string)\n        inp_embed = torch.stack(kk).unsqueeze(dim=1)\n        # print(inp_embed)\n        # print(inp_embed.shape)\n        # print(portion1.shape,inp_embed.shape,portion2.shape,m.shape,portion3.shape)\n\n        final_embeds = torch.cat((portion1,inp_embed,portion2,m,portion3),dim=1)\n        # print(final_embeds.shape)\n        # print(lab1.shape, lab2.shape, lab3.shape, lab4.shape, lab5.shape)\n        labs_shape = torch.cat((lab2,lab3,lab4,lab5),dim=1).shape\n        remaining_mask = torch.ones(labs_shape[0], labs_shape[1]).long()\n        #print(a1)\n        #print(remaining_mask)\n\n        full_mask = torch.cat((a1,remaining_mask),dim=1)\n        #print('fm ', full_mask.shape)\n        labs = torch.cat((lab1,lab2,lab3,lab4,lab5),dim=1)\n        #print(full_mask)\n        #print(0/0)\n        #         print(final_embeds.shape, labs.shape)\n        #         print(0/0)\n        #with torch.no_grad():\n        if second_pass:\n            #model1.prepare_inputs_for_generation = prepare_inputs_for_generation\n            #input_ids = torch.LongTensor([[model1.config.bos_token_id]]).to(device)\n            #inputs_embdes = final_embeds.float().to(device)\n            #op = model1.sample(input_ids, inputs_embeds = inputs_embdes, pad_token_id=model1.config.eos_token_id)\n            #print(tokenizer1.batch_decode(op))\n            output2 = model1(inputs_embeds = final_embeds.float(), labels = labs.long().to('cuda'), attention_mask=full_mask.to('cuda'))\n            #print('SECOND PASS ',tokenizer1.batch_decode(output2.logits[:,-1,:].squeeze(dim=0).detach().cpu().topk(40).indices))\n            second_pass_lab = tokenizer1.batch_decode(output2.logits[:,-1,:].squeeze(dim=0).detach().cpu().topk(40).indices)[0].strip()\n            #print('pl', prev_lab)\n            #print('sl', second_pass_lab)\n            agmx_id = output2.logits.argmax(dim=-1)[0][-1].item()\n            log_likelihood = output2.logits[:,-1,:]\n            log_likelihood = torch.nn.functional.softmax(log_likelihood, dim=-1)[:,agmx_id][0].item()\n            prev_prob = prev_prob[0].item()\n            #print('current probability', log_likelihood)\n            #print('previous probability', prev_prob)\n            #             if (prev_lab==second_pass_lab) and (log_likelihood>=prev_prob):\n            #if (prev_lab==second_pass_lab) and (abs(log_likelihood-prev_prob)<=0.05):\n            #    return True\n\n            if OP_PRESERVE:\n                if prev_lab==second_pass_lab:\n                    return True, log_likelihood\n\n                else:\n                    return False, False\n            elif OP_PRESERVE==False:\n                return True, log_likelihood\n\n\n\n        else:\n            output2 = model1(inputs_embeds = final_embeds.float(), labels = labs.long().to('cuda'), attention_mask=full_mask.to('cuda'))\n        # print(output2.loss)\n        # print(0/0)\n        loss_lm = output2.loss\n        #print(tokenizer1.batch_decode(output2.logits.argmax(dim=-1)))\n\n        #print(loss_lm)\n        m.retain_grad()\n        model1.transformer.wte.weight.retain_grad()\n        #print(output2.logits.shape)\n        #print(output2.logits.argmax(dim=-1)[0].shape)\n        agmx_idx = output2.logits.argmax(dim=-1)[0][-1].item()\n        #print(agmx_idx)\n        #print(output2.logits[:,-1,:])\n        log_likelihood_ = output2.logits[:,-1,:]\n        log_likelihood = output2.logits[:,-1,agmx_idx]\n        #print(log_likelihood)\n        log_likelihood.backward()\n        grad_  = m.grad.data.cpu().squeeze(1)\n        #embedding_norm = model1.transformer.wte.weight.grad.data.cpu().norm(dim=-1)\n        #print('en ', embedding_norm,embedding_norm.shape)\n        #tokens_index = torch.mm(grad_, E.detach().cpu().T)[0]\n\n        #tokens_index /= model1.transformer.wte.weight.detach().cpu().norm(dim=-1)\n        #print(tokens_index)\n        #ct_index = tokens_index*output2.logits[:,-1,:].squeeze(dim=0).detach().cpu() # ct_index = cumulative token index\n\n        #print(tokens_index.topk(40).indices)\n        #print(tokenizer1.batch_decode(embedding_norm.topk(40).indices))\n        #print(tokenizer1.batch_decode(tokens_index.topk(40).indices))\n        #print(tokenizer1.batch_decode(ct_index.topk(40).indices))\n        #print(tokenizer1.batch_decode(output2.logits[:,-1,:].squeeze(dim=0).detach().cpu().topk(40).indices))\n        #print(tokens_index.shape)\n        #print(grad_.shape)\n        ti,op,tt,t_id = grad_, output2.logits[:,-1,:].squeeze(dim=0).detach().cpu(), texts, tmp_id\n        #print('****************************')\n        #print(t_id)\n        output_aware_token_idx = []\n        output_aware_tokens = []\n        for i in op.topk(TOPK).indices:\n            k = model1.transformer.wte(i.cuda()).detach().cpu().unsqueeze(1)\n\n            #output_aware_token_idx.append(ti.mm(k))\n            val = torch.nn.functional.cosine_similarity(ti,k.T)[0].item()\n\n            #if val>0:\n            output_aware_token_idx.append(val)\n            output_aware_tokens.append(tokenizer1.decode(i))\n            #     print('{} -> {}'.format(tokenizer1.decode(i), ti.mm(k).squeeze()))\n\n        median = np.median(output_aware_token_idx)\n\n\n\n        if EPSILON > 0 and EPSILON < 1:\n            p,q = [],[]\n            for i,j in zip(output_aware_token_idx, output_aware_tokens):\n                if i>-EPSILON and i<EPSILON:\n                    p.append(i)\n                    q.append(j)\n\n            output_aware_token_idx = p\n            output_aware_tokens = q\n\n        output_aware_tokens = list(map(lambda x: x.strip().lower(), output_aware_tokens))\n\n        image = preprocess(Image.open('./data/'+t_id)).unsqueeze(0).to(device)\n        text = clip.tokenize(output_aware_tokens).to(device)\n        # clip_feats = []\n        text_cand = clip.tokenize(tt).to(device)\n\n\n\n        with torch.no_grad():\n            if_ = model.encode_image(image)\n            tf_ = model.encode_text(text_cand)\n\n            #print(if_.shape, tf_.shape)\n            multimodal_features = if_\n            text_features = model.encode_text(text)\n\n            clip_feats = torch.nn.functional.cosine_similarity(multimodal_features, text_features, dim=1)\n\n\n        clip_feats = clip_feats.cpu().numpy().tolist()\n\n        combined_feats = []\n        for i,j in zip(output_aware_token_idx, clip_feats):\n            #tmp = 2*i*j/(i+j)\n            if CLIP_FILTER:\n                tmp = 1.0*j+0.00*i\n            else:\n                tmp = 0\n            #tmp = j\n            combined_feats.append(tmp)\n\n        final_tokens = []\n        for i in np.argsort(combined_feats)[-1:-20:-1]:\n            final_tokens.append(output_aware_tokens[i])\n            #print(output_aware_tokens[i])\n\n        final_tokens = list(dict.fromkeys(final_tokens))\n        #final_tokens = list(final_tokens)\n        s = ['when', 'why', 'our']\n        final_tokens = [i for i in final_tokens if (i not in s and len(i)>2)][:20]\n\n        op_preserving_kt = []\n\n        for i in final_tokens:\n            string = '[KB] {} are'.format(i)\n            op = tokenizer1.batch_decode(model1.generate(torch.tensor(tokenizer1.encode(string)).unsqueeze(0).to('cuda'), max_length=14, pad_token_id=tokenizer1.eos_token_id))\n            s = ''\n            for i in op[0]:\n                s += i\n                if i=='.':\n                    break\n            op_preserving_kt.append(s)\n\n        #print('op preserving ', op_preserving_kt)\n        #print(texts[0],labs_verbalized[0])\n        #print(ids[0])\n        caption = ids[0].split('[CAPTION]')[-1]\n        #print(caption)\n\n        kb = ''\n        for i in op_preserving_kt:\n            kb+=i+' '\n\n        #         kb1 += '[CAPTION] '+caption + 'output of the classifier multimodal embedding is '\n\n        #         kb2 = '. The meme text reads :'+tt[0] + '. Classifier thinks the meme is {}'.format(labs_verbalized[0]))\n\n        #print('****************************')\n\n\n\n\n        op_preserving_final_tokens = []\n        preservation_scores = []\n        llm_lab = tokenizer1.decode(output2.logits.argmax(dim=-1)[0][-1])\n        #print(llm_lab)\n        for i in op_preserving_kt:\n            kb = i+' '\n            prev_prob = torch.nn.functional.softmax(log_likelihood_, dim=-1)[:,agmx_idx]\n            #print(prev_prob)\n            #break\n            #[:,-1,agmx_idx]\n            is_op_preserved,likelihood = get_performance_test(second_pass=True, llm_label=[kb], prev_lab=llm_lab.strip(), prev_prob=prev_prob, counter=counter)\n            if is_op_preserved:\n                preservation_scores.append(likelihood)\n                op_preserving_final_tokens.append(i)\n\n\n        #print('OP PRESERVING FINAL TOKENS ',op_preserving_final_tokens)\n        #print('PRESERVATION SCORES ',preservation_scores)\n        toks = []\n        print(t_id, list(reversed(list(np.sort(preservation_scores))))[:4])\n        for idx in list(reversed(list(np.argsort(preservation_scores))))[:4]:\n            #print(idx)\n            tmp = op_preserving_final_tokens[idx].split('are')[0][4:].strip()\n            toks.append(tmp)\n\n        #print('OP PRESERVING FINAL TOKENS ',toks)\n\n        string = ''\n        for i in toks:\n            string+=i+'\\t'\n\n        #print(string)\n        #print(string.split('\\t'))\n\n        d_ids[t_id] = string\n\n        all_labs.append(llm_lab)\n        counter+=1\n\n        if counter==CUTOFF:\n            break\n\n\n\n    return all_labs, all_labs_clf, grad_, output2.logits[:,-1,:].squeeze(dim=0).detach().cpu(), texts, tmp_id\n","metadata":{"id":"oLaHgTTeYYHN","execution":{"iopub.status.busy":"2024-06-22T18:30:39.016620Z","iopub.execute_input":"2024-06-22T18:30:39.016994Z","iopub.status.idle":"2024-06-22T18:30:39.070442Z","shell.execute_reply.started":"2024-06-22T18:30:39.016967Z","shell.execute_reply":"2024-06-22T18:30:39.069469Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2024-06-22T18:30:40.350185Z","iopub.execute_input":"2024-06-22T18:30:40.350593Z","iopub.status.idle":"2024-06-22T18:30:40.355355Z","shell.execute_reply.started":"2024-06-22T18:30:40.350566Z","shell.execute_reply":"2024-06-22T18:30:40.354333Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"torch.__version__","metadata":{"execution":{"iopub.status.busy":"2024-06-22T18:30:40.689640Z","iopub.execute_input":"2024-06-22T18:30:40.690287Z","iopub.status.idle":"2024-06-22T18:30:40.696010Z","shell.execute_reply.started":"2024-06-22T18:30:40.690254Z","shell.execute_reply":"2024-06-22T18:30:40.695120Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"'2.0.1+cu117'"},"metadata":{}}]},{"cell_type":"code","source":"set_seed(42)\n\n\nCUTOFF = 10\n\n# al, alc,ti,op,tt,t_id = get_performance_test()\n\n# all_labs = []\n# for i in al:\n#     if i.strip()=='normal':\n#         all_labs.append(0)\n#     else:\n#         all_labs.append(1)\n\n# import pickle\n\n# list_of_dicts = [d_ids,all_labs]\n\n# print(list_of_dicts)\n\n\n\n\nfor TOPK in [500,1500,2500,3500]:\n    for EPSILON in [0.01,0.1,100]:\n        for OP_PRESERVE in [True,False]:\n            if OP_PRESERVE:\n                THIRD = 'on'\n                FOURTH = 'on'\n            else:\n                THIRD = 'on'\n                FOURTH = 'off'\n            print(TOPK, EPSILON, CLIP_FILTER, OP_PRESERVE)\n\n            if EPSILON==100:\n                file_path =  f'/kaggle/working/ijcai_ckpts/full_ops/ijcai_{TOPK}_ur_{THIRD}_{FOURTH}.pkl'\n            else:\n                file_path = f'/kaggle/working/ijcai_ckpts/full_ops/ijcai_{TOPK}_ball_{EPSILON}_{THIRD}_{FOURTH}.pkl'\n\n            try:\n                with open(file_path, 'rb') as f:\n                    to_be_compared = pickle.load(f)\n\n                    d_ids = {}\n                    all_labs = []\n                    counter = 0\n\n                    al, alc,ti,op,tt,t_id = get_performance_test()\n                    all_labs = []\n                    for i in al:\n                        if i.strip()=='normal':\n                            all_labs.append(0)\n                        else:\n                            all_labs.append(1)\n\n\n\n                    list_of_dicts = [d_ids,all_labs]\n\n\n\n                    THIRD = 'on' if CLIP_FILTER else 'off'\n                    FOURTH = 'on' if OP_PRESERVE else 'off'\n\n\n\n\n                    for i in list_of_dicts[0]:\n                        try:\n                            # this very slight mismatch between tokens sometimes are due to different GPU\n                            # runtime (P100 vs A100) and maybe different pytorch version\n                            assert list_of_dicts[0][i] == to_be_compared[0][i]\n                        except:\n                            print(i)\n                            print(list_of_dicts[0][i])\n                            print(to_be_compared[0][i])\n                            continue\n                    print(f'Assertion Complete: {file_path}')\n\n\n\n\n\n            except:\n                continue\n\n\n\n\n\n\n\n\n\n\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pvOhDWQHYYJM","outputId":"1ceb5632-a0cd-49cf-e8d8-136595cd842a","execution":{"iopub.status.busy":"2024-06-22T18:30:41.121373Z","iopub.execute_input":"2024-06-22T18:30:41.122234Z","iopub.status.idle":"2024-06-22T18:49:55.925490Z","shell.execute_reply.started":"2024-06-22T18:30:41.122199Z","shell.execute_reply":"2024-06-22T18:49:55.924524Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"500 0.01 True True\nUSING TopK 500, eps 0.01, CLIP Filter True, Output Filter True d_ids {}\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:03<00:28,  3.20s/it]","output_type":"stream"},{"name":"stdout","text":"img/57302.png [0.6113293170928955, 0.6112053990364075, 0.6039602160453796, 0.6031656861305237]\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:07<00:29,  3.69s/it]","output_type":"stream"},{"name":"stdout","text":"img/89540.png [0.8536316156387329, 0.853504478931427, 0.8518929481506348, 0.8457092642784119]\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:09<00:21,  3.03s/it]","output_type":"stream"},{"name":"stdout","text":"img/47609.png [0.8206233382225037, 0.8097295761108398, 0.80815190076828, 0.8056093454360962]\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:12<00:18,  3.10s/it]","output_type":"stream"},{"name":"stdout","text":"img/91563.png [0.7006956934928894, 0.6960192322731018, 0.6953125, 0.6951465010643005]\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:15<00:14,  2.87s/it]","output_type":"stream"},{"name":"stdout","text":"img/35708.png [0.6247488856315613, 0.60386723279953, 0.6002333760261536, 0.5875460505485535]\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [00:18<00:12,  3.07s/it]","output_type":"stream"},{"name":"stdout","text":"img/54190.png [0.915662944316864, 0.9131003022193909, 0.9129288196563721, 0.9122013449668884]\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [00:22<00:09,  3.23s/it]","output_type":"stream"},{"name":"stdout","text":"img/20497.png [0.786939263343811, 0.7824742794036865, 0.7799167037010193, 0.7730016112327576]\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [00:25<00:06,  3.20s/it]","output_type":"stream"},{"name":"stdout","text":"img/68753.png [0.8456326127052307, 0.84358149766922, 0.8404860496520996, 0.8378397822380066]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:27<00:02,  2.93s/it]","output_type":"stream"},{"name":"stdout","text":"img/01576.png [0.9167032837867737, 0.9161912798881531, 0.9131343960762024, 0.912078857421875]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:31<00:03,  3.49s/it]\n","output_type":"stream"},{"name":"stdout","text":"img/61459.png [0.9023940563201904, 0.8936102390289307, 0.8905022740364075, 0.8849347233772278]\nimg/35708.png\nkids\tadults\tchild\tday\t\nkids\tboy\tadults\tchild\t\nAssertion Complete: /kaggle/working/ijcai_ckpts/full_ops/ijcai_500_ball_0.01_on_on.pkl\n500 0.01 True False\n500 0.1 True True\nUSING TopK 500, eps 0.1, CLIP Filter True, Output Filter True d_ids {}\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:04<00:37,  4.12s/it]","output_type":"stream"},{"name":"stdout","text":"img/57302.png [0.6203932762145996, 0.6112053990364075, 0.6090622544288635, 0.6031656861305237]\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:08<00:32,  4.08s/it]","output_type":"stream"},{"name":"stdout","text":"img/89540.png [0.8695306181907654, 0.8639732003211975, 0.8555260300636292, 0.853504478931427]\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:11<00:26,  3.75s/it]","output_type":"stream"},{"name":"stdout","text":"img/47609.png [0.8196203708648682, 0.8189534544944763, 0.8186569809913635, 0.8121041655540466]\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:15<00:24,  4.02s/it]","output_type":"stream"},{"name":"stdout","text":"img/91563.png [0.7183058857917786, 0.7085598111152649, 0.7072886228561401, 0.7063813209533691]\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:19<00:18,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"img/35708.png [0.6247488856315613, 0.6150650382041931, 0.5879669785499573, 0.5860176682472229]\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [00:23<00:16,  4.04s/it]","output_type":"stream"},{"name":"stdout","text":"img/54190.png [0.915845513343811, 0.915662944316864, 0.9140856862068176, 0.9125596880912781]\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [00:27<00:12,  4.04s/it]","output_type":"stream"},{"name":"stdout","text":"img/20497.png [0.7824742794036865, 0.7765690684318542, 0.7742584347724915, 0.7730016112327576]\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [00:31<00:07,  3.94s/it]","output_type":"stream"},{"name":"stdout","text":"img/68753.png [0.9076982736587524, 0.8576380014419556, 0.8378397822380066, 0.8352718949317932]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:34<00:03,  3.61s/it]","output_type":"stream"},{"name":"stdout","text":"img/01576.png [0.9193486571311951, 0.9176457524299622, 0.9131547808647156, 0.9115132093429565]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:38<00:04,  4.25s/it]\n","output_type":"stream"},{"name":"stdout","text":"img/61459.png [0.8936102390289307, 0.8927823305130005, 0.8869062662124634, 0.8864221572875977]\nimg/01576.png\nfor\tsun\tabove\timages\t\nsun\tabove\timages\tsimilar\t\nAssertion Complete: /kaggle/working/ijcai_ckpts/full_ops/ijcai_500_ball_0.1_on_on.pkl\n500 0.1 True False\nUSING TopK 500, eps 0.1, CLIP Filter True, Output Filter False d_ids {}\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:04<00:37,  4.18s/it]","output_type":"stream"},{"name":"stdout","text":"img/57302.png [0.6479114890098572, 0.6203932762145996, 0.6112053990364075, 0.6090622544288635]\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:08<00:32,  4.11s/it]","output_type":"stream"},{"name":"stdout","text":"img/89540.png [0.8695306181907654, 0.8639732003211975, 0.8555260300636292, 0.853504478931427]\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:11<00:26,  3.74s/it]","output_type":"stream"},{"name":"stdout","text":"img/47609.png [0.8196203708648682, 0.8189534544944763, 0.8186569809913635, 0.8121041655540466]\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:16<00:24,  4.07s/it]","output_type":"stream"},{"name":"stdout","text":"img/91563.png [0.7183058857917786, 0.7085598111152649, 0.7072886228561401, 0.7063813209533691]\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:19<00:19,  3.81s/it]","output_type":"stream"},{"name":"stdout","text":"img/35708.png [0.6247488856315613, 0.6150650382041931, 0.5879669785499573, 0.5860176682472229]\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [00:23<00:16,  4.01s/it]","output_type":"stream"},{"name":"stdout","text":"img/54190.png [0.915845513343811, 0.915662944316864, 0.9140856862068176, 0.9125596880912781]\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [00:27<00:12,  4.01s/it]","output_type":"stream"},{"name":"stdout","text":"img/20497.png [0.7824742794036865, 0.7765690684318542, 0.7742584347724915, 0.7730016112327576]\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [00:31<00:07,  3.93s/it]","output_type":"stream"},{"name":"stdout","text":"img/68753.png [0.9076982736587524, 0.8576380014419556, 0.8378397822380066, 0.8352718949317932]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:34<00:03,  3.62s/it]","output_type":"stream"},{"name":"stdout","text":"img/01576.png [0.9193486571311951, 0.9176457524299622, 0.9131547808647156, 0.9115132093429565]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:38<00:04,  4.27s/it]\n","output_type":"stream"},{"name":"stdout","text":"img/61459.png [0.8936102390289307, 0.8927823305130005, 0.8869062662124634, 0.8864221572875977]\nimg/01576.png\nfor\tsun\tabove\timages\t\nsun\tabove\timages\tsimilar\t\nAssertion Complete: /kaggle/working/ijcai_ckpts/full_ops/ijcai_500_ball_0.1_on_off.pkl\n500 100 True True\nUSING TopK 500, eps 100, CLIP Filter True, Output Filter True d_ids {}\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:04<00:37,  4.20s/it]","output_type":"stream"},{"name":"stdout","text":"img/57302.png [0.6203932762145996, 0.6112053990364075, 0.6090622544288635, 0.6031656861305237]\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:08<00:33,  4.17s/it]","output_type":"stream"},{"name":"stdout","text":"img/89540.png [0.8695306181907654, 0.8639732003211975, 0.8555260300636292, 0.853504478931427]\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:11<00:26,  3.81s/it]","output_type":"stream"},{"name":"stdout","text":"img/47609.png [0.8196203708648682, 0.8189534544944763, 0.8186569809913635, 0.8121041655540466]\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:16<00:24,  4.07s/it]","output_type":"stream"},{"name":"stdout","text":"img/91563.png [0.7183058857917786, 0.7085598111152649, 0.7072886228561401, 0.7063813209533691]\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:19<00:19,  3.84s/it]","output_type":"stream"},{"name":"stdout","text":"img/35708.png [0.6247488856315613, 0.6150650382041931, 0.5879669785499573, 0.5860176682472229]\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [00:24<00:16,  4.05s/it]","output_type":"stream"},{"name":"stdout","text":"img/54190.png [0.915845513343811, 0.915662944316864, 0.9140856862068176, 0.9125596880912781]\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [00:28<00:12,  4.05s/it]","output_type":"stream"},{"name":"stdout","text":"img/20497.png [0.7824742794036865, 0.7765690684318542, 0.7742584347724915, 0.7730016112327576]\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [00:31<00:07,  3.97s/it]","output_type":"stream"},{"name":"stdout","text":"img/68753.png [0.9076982736587524, 0.8576380014419556, 0.8378397822380066, 0.8352718949317932]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:34<00:03,  3.64s/it]","output_type":"stream"},{"name":"stdout","text":"img/01576.png [0.9193486571311951, 0.9176457524299622, 0.9131547808647156, 0.9115132093429565]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:38<00:04,  4.33s/it]\n","output_type":"stream"},{"name":"stdout","text":"img/61459.png [0.8936102390289307, 0.8927823305130005, 0.8869062662124634, 0.8864221572875977]\nimg/01576.png\nfor\tsun\tabove\timages\t\nsun\tabove\timages\tsimilar\t\nAssertion Complete: /kaggle/working/ijcai_ckpts/full_ops/ijcai_500_ur_on_on.pkl\n500 100 True False\nUSING TopK 500, eps 100, CLIP Filter True, Output Filter False d_ids {}\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:04<00:38,  4.23s/it]","output_type":"stream"},{"name":"stdout","text":"img/57302.png [0.6479114890098572, 0.6203932762145996, 0.6112053990364075, 0.6090622544288635]\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:08<00:32,  4.08s/it]","output_type":"stream"},{"name":"stdout","text":"img/89540.png [0.8695306181907654, 0.8639732003211975, 0.8555260300636292, 0.853504478931427]\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:11<00:26,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"img/47609.png [0.8196203708648682, 0.8189534544944763, 0.8186569809913635, 0.8121041655540466]\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:16<00:24,  4.03s/it]","output_type":"stream"},{"name":"stdout","text":"img/91563.png [0.7183058857917786, 0.7085598111152649, 0.7072886228561401, 0.7063813209533691]\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:19<00:19,  3.81s/it]","output_type":"stream"},{"name":"stdout","text":"img/35708.png [0.6247488856315613, 0.6150650382041931, 0.5879669785499573, 0.5860176682472229]\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [00:23<00:16,  4.03s/it]","output_type":"stream"},{"name":"stdout","text":"img/54190.png [0.915845513343811, 0.915662944316864, 0.9140856862068176, 0.9125596880912781]\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [00:27<00:12,  4.04s/it]","output_type":"stream"},{"name":"stdout","text":"img/20497.png [0.7824742794036865, 0.7765690684318542, 0.7742584347724915, 0.7730016112327576]\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [00:31<00:07,  3.99s/it]","output_type":"stream"},{"name":"stdout","text":"img/68753.png [0.9076982736587524, 0.8576380014419556, 0.8378397822380066, 0.8352718949317932]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:34<00:03,  3.68s/it]","output_type":"stream"},{"name":"stdout","text":"img/01576.png [0.9193486571311951, 0.9176457524299622, 0.9131547808647156, 0.9115132093429565]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:38<00:04,  4.32s/it]\n","output_type":"stream"},{"name":"stdout","text":"img/61459.png [0.8936102390289307, 0.8927823305130005, 0.8869062662124634, 0.8864221572875977]\nimg/01576.png\nfor\tsun\tabove\timages\t\nsun\tabove\timages\tsimilar\t\nAssertion Complete: /kaggle/working/ijcai_ckpts/full_ops/ijcai_500_ur_on_off.pkl\n1500 0.01 True True\nUSING TopK 1500, eps 0.01, CLIP Filter True, Output Filter True d_ids {}\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:04<00:36,  4.01s/it]","output_type":"stream"},{"name":"stdout","text":"img/57302.png [0.6380589604377747, 0.6113293170928955, 0.6112053990364075, 0.6039602160453796]\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:08<00:32,  4.02s/it]","output_type":"stream"},{"name":"stdout","text":"img/89540.png [0.8536316156387329, 0.853504478931427, 0.8518929481506348, 0.8498094081878662]\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:10<00:22,  3.17s/it]","output_type":"stream"},{"name":"stdout","text":"img/47609.png [0.8386318683624268, 0.8228507041931152, 0.8120027780532837, 0.8048929572105408]\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:14<00:22,  3.68s/it]","output_type":"stream"},{"name":"stdout","text":"img/91563.png [0.7026292085647583, 0.7012501358985901, 0.6953125, 0.6934238076210022]\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:18<00:18,  3.71s/it]","output_type":"stream"},{"name":"stdout","text":"img/35708.png [0.6247488856315613, 0.6146259307861328, 0.6055295467376709, 0.5902539491653442]\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [00:22<00:15,  3.83s/it]","output_type":"stream"},{"name":"stdout","text":"img/54190.png [0.9181994795799255, 0.915662944316864, 0.9127838611602783, 0.9113764762878418]\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [00:26<00:11,  3.97s/it]","output_type":"stream"},{"name":"stdout","text":"img/20497.png [0.7824742794036865, 0.7730016112327576, 0.7712205648422241, 0.7707177400588989]\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [00:29<00:07,  3.65s/it]","output_type":"stream"},{"name":"stdout","text":"img/68753.png [0.9076982736587524, 0.8378397822380066, 0.8352718949317932, 0.8307809829711914]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:31<00:03,  3.14s/it]","output_type":"stream"},{"name":"stdout","text":"img/01576.png [0.9146486520767212, 0.9109274744987488, 0.9066484570503235, 0.9025411009788513]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:35<00:03,  3.99s/it]\n","output_type":"stream"},{"name":"stdout","text":"img/61459.png [0.8936102390289307, 0.8849347233772278, 0.8836680054664612, 0.8798805475234985]\nimg/01576.png\nlink\tchildren\tair\tfrom\t\ndangerous\tlink\tchildren\tair\t\nAssertion Complete: /kaggle/working/ijcai_ckpts/full_ops/ijcai_1500_ball_0.01_on_on.pkl\n1500 0.01 True False\n1500 0.1 True True\nUSING TopK 1500, eps 0.1, CLIP Filter True, Output Filter True d_ids {}\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:05<00:53,  5.95s/it]","output_type":"stream"},{"name":"stdout","text":"img/57302.png [0.6165052056312561, 0.6130991578102112, 0.6112053990364075, 0.6090622544288635]\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:11<00:46,  5.84s/it]","output_type":"stream"},{"name":"stdout","text":"img/89540.png [0.858553946018219, 0.8533595204353333, 0.8512409329414368, 0.846463143825531]\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:16<00:37,  5.42s/it]","output_type":"stream"},{"name":"stdout","text":"img/47609.png [0.8219111561775208, 0.8205922245979309, 0.8134915828704834, 0.8103071451187134]\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:22<00:34,  5.73s/it]","output_type":"stream"},{"name":"stdout","text":"img/91563.png [0.7107625007629395, 0.7063813209533691, 0.7000835537910461, 0.6998599171638489]\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:28<00:27,  5.59s/it]","output_type":"stream"},{"name":"stdout","text":"img/35708.png [0.6247488856315613, 0.597846508026123, 0.5861294269561768, 0.5860176682472229]\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [00:34<00:23,  5.79s/it]","output_type":"stream"},{"name":"stdout","text":"img/54190.png [0.9235149621963501, 0.9194338917732239, 0.9183349013328552, 0.9181994795799255]\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [00:40<00:17,  5.81s/it]","output_type":"stream"},{"name":"stdout","text":"img/20497.png [0.7870231866836548, 0.7854488492012024, 0.7824742794036865, 0.7799558043479919]\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [00:45<00:11,  5.60s/it]","output_type":"stream"},{"name":"stdout","text":"img/68753.png [0.8408502340316772, 0.8383787870407104, 0.8378397822380066, 0.8315660357475281]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:49<00:05,  5.29s/it]","output_type":"stream"},{"name":"stdout","text":"img/01576.png [0.9181744456291199, 0.9176457524299622, 0.9148082733154297, 0.9146486520767212]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:55<00:06,  6.20s/it]\n","output_type":"stream"},{"name":"stdout","text":"img/61459.png [0.8936102390289307, 0.8927823305130005, 0.8864221572875977, 0.8862998485565186]\nimg/47609.png\nson\tfather\tdad\thal\t\nson\tfather\tdad\tbro\t\nAssertion Complete: /kaggle/working/ijcai_ckpts/full_ops/ijcai_1500_ball_0.1_on_on.pkl\n1500 0.1 True False\nUSING TopK 1500, eps 0.1, CLIP Filter True, Output Filter False d_ids {}\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:05<00:53,  5.97s/it]","output_type":"stream"},{"name":"stdout","text":"img/57302.png [0.6479114890098572, 0.6165052056312561, 0.6130991578102112, 0.6112053990364075]\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:11<00:46,  5.84s/it]","output_type":"stream"},{"name":"stdout","text":"img/89540.png [0.858553946018219, 0.8533595204353333, 0.8512409329414368, 0.846463143825531]\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:16<00:37,  5.42s/it]","output_type":"stream"},{"name":"stdout","text":"img/47609.png [0.8219111561775208, 0.8205922245979309, 0.8134915828704834, 0.8103071451187134]\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:22<00:33,  5.64s/it]","output_type":"stream"},{"name":"stdout","text":"img/91563.png [0.7107625007629395, 0.7063813209533691, 0.7000835537910461, 0.6998599171638489]\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:28<00:27,  5.55s/it]","output_type":"stream"},{"name":"stdout","text":"img/35708.png [0.6247488856315613, 0.597846508026123, 0.5861294269561768, 0.5860176682472229]\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [00:34<00:23,  5.76s/it]","output_type":"stream"},{"name":"stdout","text":"img/54190.png [0.9235149621963501, 0.9194338917732239, 0.9183349013328552, 0.9181994795799255]\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [00:39<00:17,  5.74s/it]","output_type":"stream"},{"name":"stdout","text":"img/20497.png [0.7870231866836548, 0.7854488492012024, 0.7824742794036865, 0.7799558043479919]\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [00:45<00:11,  5.55s/it]","output_type":"stream"},{"name":"stdout","text":"img/68753.png [0.8408502340316772, 0.8383787870407104, 0.8378397822380066, 0.8315660357475281]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:49<00:05,  5.28s/it]","output_type":"stream"},{"name":"stdout","text":"img/01576.png [0.9181744456291199, 0.9176457524299622, 0.9148082733154297, 0.9146486520767212]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:55<00:06,  6.16s/it]\n","output_type":"stream"},{"name":"stdout","text":"img/61459.png [0.8936102390289307, 0.8927823305130005, 0.8864221572875977, 0.8862998485565186]\nimg/47609.png\nson\tfather\tdad\thal\t\nson\tfather\tdad\tbro\t\nAssertion Complete: /kaggle/working/ijcai_ckpts/full_ops/ijcai_1500_ball_0.1_on_off.pkl\n1500 100 True True\nUSING TopK 1500, eps 100, CLIP Filter True, Output Filter True d_ids {}\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:05<00:53,  5.97s/it]","output_type":"stream"},{"name":"stdout","text":"img/57302.png [0.6165052056312561, 0.6130991578102112, 0.6112053990364075, 0.6090622544288635]\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:11<00:46,  5.86s/it]","output_type":"stream"},{"name":"stdout","text":"img/89540.png [0.858553946018219, 0.8533595204353333, 0.8512409329414368, 0.846463143825531]\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:16<00:38,  5.43s/it]","output_type":"stream"},{"name":"stdout","text":"img/47609.png [0.8219111561775208, 0.8205922245979309, 0.8134915828704834, 0.8085587620735168]\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:22<00:34,  5.68s/it]","output_type":"stream"},{"name":"stdout","text":"img/91563.png [0.7107625007629395, 0.7063813209533691, 0.7000835537910461, 0.6998599171638489]\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:28<00:27,  5.57s/it]","output_type":"stream"},{"name":"stdout","text":"img/35708.png [0.6247488856315613, 0.597846508026123, 0.5861294269561768, 0.5860176682472229]\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [00:34<00:23,  5.84s/it]","output_type":"stream"},{"name":"stdout","text":"img/54190.png [0.9235149621963501, 0.9194338917732239, 0.9183349013328552, 0.9181994795799255]\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [00:40<00:17,  5.81s/it]","output_type":"stream"},{"name":"stdout","text":"img/20497.png [0.7870231866836548, 0.7854488492012024, 0.7824742794036865, 0.7799558043479919]\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [00:45<00:11,  5.62s/it]","output_type":"stream"},{"name":"stdout","text":"img/68753.png [0.8408502340316772, 0.8383787870407104, 0.8378397822380066, 0.8315660357475281]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:50<00:05,  5.36s/it]","output_type":"stream"},{"name":"stdout","text":"img/01576.png [0.9181744456291199, 0.9176457524299622, 0.9148082733154297, 0.9146486520767212]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:56<00:06,  6.23s/it]\n","output_type":"stream"},{"name":"stdout","text":"img/61459.png [0.8936102390289307, 0.8927823305130005, 0.8864221572875977, 0.8862998485565186]\nAssertion Complete: /kaggle/working/ijcai_ckpts/full_ops/ijcai_1500_ur_on_on.pkl\n1500 100 True False\nUSING TopK 1500, eps 100, CLIP Filter True, Output Filter False d_ids {}\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:06<00:54,  6.02s/it]","output_type":"stream"},{"name":"stdout","text":"img/57302.png [0.6479114890098572, 0.6165052056312561, 0.6130991578102112, 0.6112053990364075]\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:11<00:47,  5.94s/it]","output_type":"stream"},{"name":"stdout","text":"img/89540.png [0.858553946018219, 0.8533595204353333, 0.8512409329414368, 0.846463143825531]\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:16<00:38,  5.50s/it]","output_type":"stream"},{"name":"stdout","text":"img/47609.png [0.8219111561775208, 0.8205922245979309, 0.8134915828704834, 0.8085587620735168]\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:22<00:34,  5.71s/it]","output_type":"stream"},{"name":"stdout","text":"img/91563.png [0.7107625007629395, 0.7063813209533691, 0.7000835537910461, 0.6998599171638489]\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:28<00:28,  5.62s/it]","output_type":"stream"},{"name":"stdout","text":"img/35708.png [0.6247488856315613, 0.597846508026123, 0.5861294269561768, 0.5860176682472229]\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [00:34<00:23,  5.81s/it]","output_type":"stream"},{"name":"stdout","text":"img/54190.png [0.9235149621963501, 0.9194338917732239, 0.9183349013328552, 0.9181994795799255]\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [00:40<00:17,  5.86s/it]","output_type":"stream"},{"name":"stdout","text":"img/20497.png [0.7870231866836548, 0.7854488492012024, 0.7824742794036865, 0.7799558043479919]\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [00:45<00:11,  5.62s/it]","output_type":"stream"},{"name":"stdout","text":"img/68753.png [0.8408502340316772, 0.8383787870407104, 0.8378397822380066, 0.8315660357475281]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:50<00:05,  5.31s/it]","output_type":"stream"},{"name":"stdout","text":"img/01576.png [0.9181744456291199, 0.9176457524299622, 0.9148082733154297, 0.9146486520767212]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:56<00:06,  6.23s/it]\n","output_type":"stream"},{"name":"stdout","text":"img/61459.png [0.8936102390289307, 0.8927823305130005, 0.8864221572875977, 0.8862998485565186]\nAssertion Complete: /kaggle/working/ijcai_ckpts/full_ops/ijcai_1500_ur_on_off.pkl\n2500 0.01 True True\nUSING TopK 2500, eps 0.01, CLIP Filter True, Output Filter True d_ids {}\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:04<00:43,  4.87s/it]","output_type":"stream"},{"name":"stdout","text":"img/57302.png [0.6113293170928955, 0.6112053990364075, 0.6039602160453796, 0.6031656861305237]\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:10<00:40,  5.07s/it]","output_type":"stream"},{"name":"stdout","text":"img/89540.png [0.9035635590553284, 0.8644005656242371, 0.8614162802696228, 0.8582971096038818]\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:12<00:28,  4.08s/it]","output_type":"stream"},{"name":"stdout","text":"img/47609.png [0.8386318683624268, 0.8228507041931152, 0.8138546943664551, 0.8120027780532837]\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:18<00:27,  4.58s/it]","output_type":"stream"},{"name":"stdout","text":"img/91563.png [0.7214421033859253, 0.7104001045227051, 0.7100354433059692, 0.7026292085647583]\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:22<00:22,  4.48s/it]","output_type":"stream"},{"name":"stdout","text":"img/35708.png [0.6247488856315613, 0.6146259307861328, 0.6055295467376709, 0.5971552133560181]\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [00:27<00:19,  4.75s/it]","output_type":"stream"},{"name":"stdout","text":"img/54190.png [0.9181994795799255, 0.915662944316864, 0.9127838611602783, 0.9113764762878418]\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [00:32<00:13,  4.60s/it]","output_type":"stream"},{"name":"stdout","text":"img/20497.png [0.7824742794036865, 0.7781007885932922, 0.7735774517059326, 0.7730016112327576]\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [00:36<00:08,  4.44s/it]","output_type":"stream"},{"name":"stdout","text":"img/68753.png [0.9076982736587524, 0.8378397822380066, 0.8352718949317932, 0.8307809829711914]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:39<00:04,  4.11s/it]","output_type":"stream"},{"name":"stdout","text":"img/01576.png [0.921342134475708, 0.9193486571311951, 0.9146486520767212, 0.9127480387687683]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:44<00:04,  4.90s/it]\n","output_type":"stream"},{"name":"stdout","text":"img/61459.png [0.8936102390289307, 0.884804368019104, 0.8847116827964783, 0.8845619559288025]\nAssertion Complete: /kaggle/working/ijcai_ckpts/full_ops/ijcai_2500_ball_0.01_on_on.pkl\n2500 0.01 True False\n2500 0.1 True True\nUSING TopK 2500, eps 0.1, CLIP Filter True, Output Filter True d_ids {}\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:07<01:08,  7.62s/it]","output_type":"stream"},{"name":"stdout","text":"img/57302.png [0.6130991578102112, 0.6112053990364075, 0.6090622544288635, 0.60865318775177]\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:14<00:57,  7.23s/it]","output_type":"stream"},{"name":"stdout","text":"img/89540.png [0.8614162802696228, 0.8576489686965942, 0.8544756770133972, 0.8540835380554199]\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:19<00:43,  6.25s/it]","output_type":"stream"},{"name":"stdout","text":"img/47609.png [0.8219111561775208, 0.8205922245979309, 0.8134915828704834, 0.8106225728988647]\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:26<00:40,  6.67s/it]","output_type":"stream"},{"name":"stdout","text":"img/91563.png [0.7214421033859253, 0.7107625007629395, 0.7063813209533691, 0.70026034116745]\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:33<00:32,  6.52s/it]","output_type":"stream"},{"name":"stdout","text":"img/35708.png [0.6247488856315613, 0.5971552133560181, 0.5861294269561768, 0.5860176682472229]\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [00:40<00:27,  6.87s/it]","output_type":"stream"},{"name":"stdout","text":"img/54190.png [0.9273144602775574, 0.9235149621963501, 0.9194338917732239, 0.9183349013328552]\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [00:48<00:21,  7.09s/it]","output_type":"stream"},{"name":"stdout","text":"img/20497.png [0.7950285077095032, 0.7870231866836548, 0.7824742794036865, 0.7799558043479919]\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [00:55<00:14,  7.13s/it]","output_type":"stream"},{"name":"stdout","text":"img/68753.png [0.8650295734405518, 0.8379306197166443, 0.8378397822380066, 0.8375545740127563]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [01:01<00:06,  6.76s/it]","output_type":"stream"},{"name":"stdout","text":"img/01576.png [0.9181744456291199, 0.9154823422431946, 0.9148082733154297, 0.9131547808647156]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [01:08<00:07,  7.66s/it]\n","output_type":"stream"},{"name":"stdout","text":"img/61459.png [0.8936102390289307, 0.8927823305130005, 0.8864221572875977, 0.8852211833000183]\nAssertion Complete: /kaggle/working/ijcai_ckpts/full_ops/ijcai_2500_ball_0.1_on_on.pkl\n2500 0.1 True False\nUSING TopK 2500, eps 0.1, CLIP Filter True, Output Filter False d_ids {}\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:07<01:07,  7.50s/it]","output_type":"stream"},{"name":"stdout","text":"img/57302.png [0.6479114890098572, 0.6457480788230896, 0.6130991578102112, 0.6112053990364075]\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:14<00:57,  7.23s/it]","output_type":"stream"},{"name":"stdout","text":"img/89540.png [0.8614162802696228, 0.8576489686965942, 0.8544756770133972, 0.8540835380554199]\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:19<00:43,  6.25s/it]","output_type":"stream"},{"name":"stdout","text":"img/47609.png [0.8219111561775208, 0.8205922245979309, 0.8134915828704834, 0.8106225728988647]\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:26<00:40,  6.69s/it]","output_type":"stream"},{"name":"stdout","text":"img/91563.png [0.7214421033859253, 0.7107625007629395, 0.7063813209533691, 0.70026034116745]\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:33<00:32,  6.51s/it]","output_type":"stream"},{"name":"stdout","text":"img/35708.png [0.6247488856315613, 0.5971552133560181, 0.5861294269561768, 0.5860176682472229]\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [00:40<00:27,  6.86s/it]","output_type":"stream"},{"name":"stdout","text":"img/54190.png [0.9273144602775574, 0.9235149621963501, 0.9194338917732239, 0.9183349013328552]\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [00:48<00:21,  7.09s/it]","output_type":"stream"},{"name":"stdout","text":"img/20497.png [0.7950285077095032, 0.7870231866836548, 0.7824742794036865, 0.7799558043479919]\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [00:55<00:14,  7.08s/it]","output_type":"stream"},{"name":"stdout","text":"img/68753.png [0.8650295734405518, 0.8379306197166443, 0.8378397822380066, 0.8375545740127563]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [01:01<00:06,  6.73s/it]","output_type":"stream"},{"name":"stdout","text":"img/01576.png [0.9181744456291199, 0.9154823422431946, 0.9148082733154297, 0.9131547808647156]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [01:08<00:07,  7.64s/it]\n","output_type":"stream"},{"name":"stdout","text":"img/61459.png [0.8936102390289307, 0.8927823305130005, 0.8864221572875977, 0.8852211833000183]\nAssertion Complete: /kaggle/working/ijcai_ckpts/full_ops/ijcai_2500_ball_0.1_on_off.pkl\n2500 100 True True\nUSING TopK 2500, eps 100, CLIP Filter True, Output Filter True d_ids {}\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:07<01:07,  7.54s/it]","output_type":"stream"},{"name":"stdout","text":"img/57302.png [0.6130991578102112, 0.6112053990364075, 0.6090622544288635, 0.60865318775177]\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:14<00:58,  7.26s/it]","output_type":"stream"},{"name":"stdout","text":"img/89540.png [0.8614162802696228, 0.8576489686965942, 0.8544756770133972, 0.8540835380554199]\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:20<00:45,  6.56s/it]","output_type":"stream"},{"name":"stdout","text":"img/47609.png [0.8219111561775208, 0.8205922245979309, 0.8134915828704834, 0.8106225728988647]\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:27<00:41,  6.90s/it]","output_type":"stream"},{"name":"stdout","text":"img/91563.png [0.7214421033859253, 0.7107625007629395, 0.7089251279830933, 0.7063813209533691]\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:34<00:33,  6.70s/it]","output_type":"stream"},{"name":"stdout","text":"img/35708.png [0.6247488856315613, 0.5971552133560181, 0.5861294269561768, 0.5860176682472229]\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [00:41<00:28,  7.02s/it]","output_type":"stream"},{"name":"stdout","text":"img/54190.png [0.9273144602775574, 0.9235149621963501, 0.9194338917732239, 0.9183349013328552]\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [00:49<00:21,  7.23s/it]","output_type":"stream"},{"name":"stdout","text":"img/20497.png [0.7950285077095032, 0.7870231866836548, 0.7824742794036865, 0.7799558043479919]\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [00:56<00:14,  7.28s/it]","output_type":"stream"},{"name":"stdout","text":"img/68753.png [0.8650295734405518, 0.8379306197166443, 0.8378397822380066, 0.8375545740127563]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [01:02<00:06,  6.91s/it]","output_type":"stream"},{"name":"stdout","text":"img/01576.png [0.9181744456291199, 0.9154823422431946, 0.9148082733154297, 0.9131547808647156]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [01:10<00:07,  7.83s/it]\n","output_type":"stream"},{"name":"stdout","text":"img/61459.png [0.8936102390289307, 0.8927823305130005, 0.8864221572875977, 0.8852211833000183]\nAssertion Complete: /kaggle/working/ijcai_ckpts/full_ops/ijcai_2500_ur_on_on.pkl\n2500 100 True False\nUSING TopK 2500, eps 100, CLIP Filter True, Output Filter False d_ids {}\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:07<01:08,  7.60s/it]","output_type":"stream"},{"name":"stdout","text":"img/57302.png [0.6479114890098572, 0.6457480788230896, 0.6130991578102112, 0.6112053990364075]\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:14<00:59,  7.39s/it]","output_type":"stream"},{"name":"stdout","text":"img/89540.png [0.8614162802696228, 0.8576489686965942, 0.8544756770133972, 0.8540835380554199]\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:20<00:46,  6.62s/it]","output_type":"stream"},{"name":"stdout","text":"img/47609.png [0.8219111561775208, 0.8205922245979309, 0.8134915828704834, 0.8106225728988647]\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:28<00:41,  6.96s/it]","output_type":"stream"},{"name":"stdout","text":"img/91563.png [0.7214421033859253, 0.7107625007629395, 0.7089251279830933, 0.7063813209533691]\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:34<00:33,  6.74s/it]","output_type":"stream"},{"name":"stdout","text":"img/35708.png [0.6247488856315613, 0.5971552133560181, 0.5861294269561768, 0.5860176682472229]\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [00:41<00:28,  7.04s/it]","output_type":"stream"},{"name":"stdout","text":"img/54190.png [0.9273144602775574, 0.9235149621963501, 0.9194338917732239, 0.9183349013328552]\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [00:49<00:21,  7.24s/it]","output_type":"stream"},{"name":"stdout","text":"img/20497.png [0.7950285077095032, 0.7870231866836548, 0.7824742794036865, 0.7799558043479919]\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [00:57<00:14,  7.30s/it]","output_type":"stream"},{"name":"stdout","text":"img/68753.png [0.8650295734405518, 0.8379306197166443, 0.8378397822380066, 0.8375545740127563]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [01:03<00:06,  6.92s/it]","output_type":"stream"},{"name":"stdout","text":"img/01576.png [0.9181744456291199, 0.9154823422431946, 0.9148082733154297, 0.9131547808647156]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [01:10<00:07,  7.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"img/61459.png [0.8936102390289307, 0.8927823305130005, 0.8864221572875977, 0.8852211833000183]\nAssertion Complete: /kaggle/working/ijcai_ckpts/full_ops/ijcai_2500_ur_on_off.pkl\n3500 0.01 True True\nUSING TopK 3500, eps 0.01, CLIP Filter True, Output Filter True d_ids {}\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:05<00:53,  5.97s/it]","output_type":"stream"},{"name":"stdout","text":"img/57302.png [0.6112053990364075, 0.6048083901405334, 0.6031656861305237, 0.5913529992103577]\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:11<00:46,  5.86s/it]","output_type":"stream"},{"name":"stdout","text":"img/89540.png [0.9035635590553284, 0.8644005656242371, 0.8614162802696228, 0.8569494485855103]\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:14<00:32,  4.58s/it]","output_type":"stream"},{"name":"stdout","text":"img/47609.png [0.8386318683624268, 0.8228507041931152, 0.8106225728988647, 0.8082252740859985]\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:20<00:30,  5.05s/it]","output_type":"stream"},{"name":"stdout","text":"img/91563.png [0.7214421033859253, 0.7104001045227051, 0.7100354433059692, 0.7071306705474854]\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:25<00:25,  5.03s/it]","output_type":"stream"},{"name":"stdout","text":"img/35708.png [0.6247488856315613, 0.5971552133560181, 0.5927508473396301, 0.5835548639297485]\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [00:31<00:21,  5.33s/it]","output_type":"stream"},{"name":"stdout","text":"img/54190.png [0.9403120279312134, 0.9255397319793701, 0.9181994795799255, 0.915662944316864]\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [00:36<00:15,  5.25s/it]","output_type":"stream"},{"name":"stdout","text":"img/20497.png [0.786053478717804, 0.7824742794036865, 0.7781007885932922, 0.7773043513298035]\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [00:41<00:10,  5.03s/it]","output_type":"stream"},{"name":"stdout","text":"img/68753.png [0.9076982736587524, 0.8390617370605469, 0.8378397822380066, 0.8301408290863037]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:45<00:04,  4.67s/it]","output_type":"stream"},{"name":"stdout","text":"img/01576.png [0.921342134475708, 0.9176457524299622, 0.9158535599708557, 0.9146486520767212]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [00:50<00:05,  5.58s/it]\n","output_type":"stream"},{"name":"stdout","text":"img/61459.png [0.8936102390289307, 0.8865573406219482, 0.884804368019104, 0.8847116827964783]\nimg/68753.png\nrepublican\tmark\tbig\tlonger\t\nrepublican\tmark\tbig\tpolitical\t\nAssertion Complete: /kaggle/working/ijcai_ckpts/full_ops/ijcai_3500_ball_0.01_on_on.pkl\n3500 0.01 True False\n3500 0.1 True True\nUSING TopK 3500, eps 0.1, CLIP Filter True, Output Filter True d_ids {}\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:08<01:20,  8.90s/it]","output_type":"stream"},{"name":"stdout","text":"img/57302.png [0.6112053990364075, 0.6090622544288635, 0.60865318775177, 0.6050363183021545]\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:17<01:09,  8.67s/it]","output_type":"stream"},{"name":"stdout","text":"img/89540.png [0.8625510931015015, 0.8614162802696228, 0.8576489686965942, 0.856780469417572]\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:24<00:56,  8.05s/it]","output_type":"stream"},{"name":"stdout","text":"img/47609.png [0.8219111561775208, 0.8205922245979309, 0.8134915828704834, 0.8122594356536865]\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:33<00:49,  8.28s/it]","output_type":"stream"},{"name":"stdout","text":"img/91563.png [0.7214421033859253, 0.7107625007629395, 0.7071306705474854, 0.7063813209533691]\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:41<00:40,  8.09s/it]","output_type":"stream"},{"name":"stdout","text":"img/35708.png [0.6247488856315613, 0.5971552133560181, 0.5860176682472229, 0.5857759118080139]\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [00:50<00:33,  8.38s/it]","output_type":"stream"},{"name":"stdout","text":"img/54190.png [0.9273144602775574, 0.9260517358779907, 0.9235149621963501, 0.9194338917732239]\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [00:58<00:25,  8.51s/it]","output_type":"stream"},{"name":"stdout","text":"img/20497.png [0.7950285077095032, 0.7874304056167603, 0.7870231866836548, 0.786053478717804]\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [01:06<00:16,  8.37s/it]","output_type":"stream"},{"name":"stdout","text":"img/68753.png [0.8379306197166443, 0.8378397822380066, 0.8375545740127563, 0.8359151482582092]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [01:14<00:08,  8.24s/it]","output_type":"stream"},{"name":"stdout","text":"img/01576.png [0.9181744456291199, 0.9157878756523132, 0.9154823422431946, 0.9148082733154297]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [01:23<00:09,  9.28s/it]\n","output_type":"stream"},{"name":"stdout","text":"img/61459.png [0.8936102390289307, 0.8927823305130005, 0.8879587650299072, 0.8864221572875977]\nAssertion Complete: /kaggle/working/ijcai_ckpts/full_ops/ijcai_3500_ball_0.1_on_on.pkl\n3500 0.1 True False\nUSING TopK 3500, eps 0.1, CLIP Filter True, Output Filter False d_ids {}\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:08<01:19,  8.85s/it]","output_type":"stream"},{"name":"stdout","text":"img/57302.png [0.6479114890098572, 0.6457480788230896, 0.6447397470474243, 0.6112053990364075]\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:17<01:08,  8.61s/it]","output_type":"stream"},{"name":"stdout","text":"img/89540.png [0.8625510931015015, 0.8614162802696228, 0.8576489686965942, 0.856780469417572]\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:24<00:56,  8.00s/it]","output_type":"stream"},{"name":"stdout","text":"img/47609.png [0.8219111561775208, 0.8205922245979309, 0.8134915828704834, 0.8122594356536865]\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:33<00:49,  8.26s/it]","output_type":"stream"},{"name":"stdout","text":"img/91563.png [0.7214421033859253, 0.7107625007629395, 0.7071306705474854, 0.7063813209533691]\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:41<00:40,  8.09s/it]","output_type":"stream"},{"name":"stdout","text":"img/35708.png [0.6247488856315613, 0.5971552133560181, 0.5860176682472229, 0.5857759118080139]\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [00:49<00:33,  8.28s/it]","output_type":"stream"},{"name":"stdout","text":"img/54190.png [0.9273144602775574, 0.9260517358779907, 0.9235149621963501, 0.9194338917732239]\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [00:58<00:25,  8.43s/it]","output_type":"stream"},{"name":"stdout","text":"img/20497.png [0.7950285077095032, 0.7874304056167603, 0.7870231866836548, 0.786053478717804]\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [01:06<00:16,  8.36s/it]","output_type":"stream"},{"name":"stdout","text":"img/68753.png [0.8379306197166443, 0.8378397822380066, 0.8375545740127563, 0.8359151482582092]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [01:14<00:08,  8.24s/it]","output_type":"stream"},{"name":"stdout","text":"img/01576.png [0.9181744456291199, 0.9157878756523132, 0.9154823422431946, 0.9148082733154297]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [01:23<00:09,  9.25s/it]\n","output_type":"stream"},{"name":"stdout","text":"img/61459.png [0.8936102390289307, 0.8927823305130005, 0.8879587650299072, 0.8864221572875977]\nAssertion Complete: /kaggle/working/ijcai_ckpts/full_ops/ijcai_3500_ball_0.1_on_off.pkl\n3500 100 True True\nUSING TopK 3500, eps 100, CLIP Filter True, Output Filter True d_ids {}\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:09<01:22,  9.11s/it]","output_type":"stream"},{"name":"stdout","text":"img/57302.png [0.6112053990364075, 0.6090622544288635, 0.60865318775177, 0.6050363183021545]\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:17<01:10,  8.81s/it]","output_type":"stream"},{"name":"stdout","text":"img/89540.png [0.8625510931015015, 0.8614162802696228, 0.8576489686965942, 0.856780469417572]\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:25<00:57,  8.20s/it]","output_type":"stream"},{"name":"stdout","text":"img/47609.png [0.8219111561775208, 0.8205922245979309, 0.8134915828704834, 0.8122594356536865]\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:34<00:50,  8.45s/it]","output_type":"stream"},{"name":"stdout","text":"img/91563.png [0.7214421033859253, 0.7089251279830933, 0.7071306705474854, 0.7063813209533691]\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:42<00:41,  8.33s/it]","output_type":"stream"},{"name":"stdout","text":"img/35708.png [0.6247488856315613, 0.5971552133560181, 0.5860176682472229, 0.5857759118080139]\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [00:50<00:34,  8.50s/it]","output_type":"stream"},{"name":"stdout","text":"img/54190.png [0.9273144602775574, 0.9260517358779907, 0.9235149621963501, 0.9194338917732239]\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [00:59<00:25,  8.61s/it]","output_type":"stream"},{"name":"stdout","text":"img/20497.png [0.7950285077095032, 0.7874304056167603, 0.7870231866836548, 0.786053478717804]\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [01:07<00:16,  8.46s/it]","output_type":"stream"},{"name":"stdout","text":"img/68753.png [0.8379306197166443, 0.8378397822380066, 0.8375545740127563, 0.8359151482582092]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [01:16<00:08,  8.35s/it]","output_type":"stream"},{"name":"stdout","text":"img/01576.png [0.9181744456291199, 0.9157878756523132, 0.9154823422431946, 0.9148082733154297]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [01:24<00:09,  9.42s/it]\n","output_type":"stream"},{"name":"stdout","text":"img/61459.png [0.8936102390289307, 0.8927823305130005, 0.8879587650299072, 0.8864221572875977]\nAssertion Complete: /kaggle/working/ijcai_ckpts/full_ops/ijcai_3500_ur_on_on.pkl\n3500 100 True False\nUSING TopK 3500, eps 100, CLIP Filter True, Output Filter False d_ids {}\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:09<01:21,  9.05s/it]","output_type":"stream"},{"name":"stdout","text":"img/57302.png [0.6479114890098572, 0.6457480788230896, 0.6447397470474243, 0.6112053990364075]\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:17<01:11,  8.88s/it]","output_type":"stream"},{"name":"stdout","text":"img/89540.png [0.8625510931015015, 0.8614162802696228, 0.8576489686965942, 0.856780469417572]\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:25<00:57,  8.24s/it]","output_type":"stream"},{"name":"stdout","text":"img/47609.png [0.8219111561775208, 0.8205922245979309, 0.8134915828704834, 0.8122594356536865]\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:34<00:50,  8.47s/it]","output_type":"stream"},{"name":"stdout","text":"img/91563.png [0.7214421033859253, 0.7089251279830933, 0.7071306705474854, 0.7063813209533691]\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:42<00:41,  8.33s/it]","output_type":"stream"},{"name":"stdout","text":"img/35708.png [0.6247488856315613, 0.5971552133560181, 0.5860176682472229, 0.5857759118080139]\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [00:50<00:33,  8.48s/it]","output_type":"stream"},{"name":"stdout","text":"img/54190.png [0.9273144602775574, 0.9260517358779907, 0.9235149621963501, 0.9194338917732239]\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [00:59<00:25,  8.56s/it]","output_type":"stream"},{"name":"stdout","text":"img/20497.png [0.7950285077095032, 0.7874304056167603, 0.7870231866836548, 0.786053478717804]\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [01:07<00:16,  8.42s/it]","output_type":"stream"},{"name":"stdout","text":"img/68753.png [0.8379306197166443, 0.8378397822380066, 0.8375545740127563, 0.8359151482582092]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [01:15<00:08,  8.30s/it]","output_type":"stream"},{"name":"stdout","text":"img/01576.png [0.9181744456291199, 0.9157878756523132, 0.9154823422431946, 0.9148082733154297]\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [01:24<00:09,  9.39s/it]","output_type":"stream"},{"name":"stdout","text":"img/61459.png [0.8936102390289307, 0.8927823305130005, 0.8879587650299072, 0.8864221572875977]\nAssertion Complete: /kaggle/working/ijcai_ckpts/full_ops/ijcai_3500_ur_on_off.pkl\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"print('hi')","metadata":{"id":"kit0nOQZe0se","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('hi')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}