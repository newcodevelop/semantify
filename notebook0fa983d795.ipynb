{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e91d0da1f95e46a1bc2edebe483e768a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5d50e47072d3468483eebd6f150508d1","IPY_MODEL_4854b8b4452f495484c877c634cc8e68","IPY_MODEL_ddaaeb8493724026ab04895537bf1101"],"layout":"IPY_MODEL_0060eda838334a1ca2a5c2e506273ebf"}},"5d50e47072d3468483eebd6f150508d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5acdb7c0f7a4eceb287c4d67e03f7d9","placeholder":"​","style":"IPY_MODEL_d2aa5a0fdcaa4251b47bca659977d8a2","value":"Downloading (…)olve/main/vocab.json: 100%"}},"4854b8b4452f495484c877c634cc8e68":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a3143ceb1fa41c08b6b91fe7308646f","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_79f8bd08ffe3465d83098785a940f863","value":1042301}},"ddaaeb8493724026ab04895537bf1101":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2856d964bf4246bf8790e3ff904088a7","placeholder":"​","style":"IPY_MODEL_2f971e615b4641a5b560f59df08debbb","value":" 1.04M/1.04M [00:00&lt;00:00, 3.16MB/s]"}},"0060eda838334a1ca2a5c2e506273ebf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5acdb7c0f7a4eceb287c4d67e03f7d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2aa5a0fdcaa4251b47bca659977d8a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a3143ceb1fa41c08b6b91fe7308646f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79f8bd08ffe3465d83098785a940f863":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2856d964bf4246bf8790e3ff904088a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f971e615b4641a5b560f59df08debbb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72efeeebca5642b39fe525a40634049f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c252a3bc0484b68b453b68e7a8a68de","IPY_MODEL_0300ae01b9f3401da40b6e5112168a5f","IPY_MODEL_76a1ca306483490db9caa3f4eade44e1"],"layout":"IPY_MODEL_75d124632dd84b3c9ca4c79142e46de0"}},"2c252a3bc0484b68b453b68e7a8a68de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27043017b55d49d483ebf46ceb0100b3","placeholder":"​","style":"IPY_MODEL_e059c06b16ab48adb3e1172d0c34ba4c","value":"Downloading (…)olve/main/merges.txt: 100%"}},"0300ae01b9f3401da40b6e5112168a5f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa67818a2a464b5aa1b8dbd7c7aa88a1","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_23ec2eb908844bf88f5253573fc2edc9","value":456318}},"76a1ca306483490db9caa3f4eade44e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_700adc8771014fb3b3dfaa56ecb434c3","placeholder":"​","style":"IPY_MODEL_06a6ce6756c2484ebed94a25e7cef23d","value":" 456k/456k [00:00&lt;00:00, 23.8MB/s]"}},"75d124632dd84b3c9ca4c79142e46de0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27043017b55d49d483ebf46ceb0100b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e059c06b16ab48adb3e1172d0c34ba4c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa67818a2a464b5aa1b8dbd7c7aa88a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23ec2eb908844bf88f5253573fc2edc9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"700adc8771014fb3b3dfaa56ecb434c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06a6ce6756c2484ebed94a25e7cef23d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31a4ae58dac3488eac72f0fb74292183":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_949146025f07473981f2f41b5ffe310e","IPY_MODEL_eb7fcb8ed3c04797b79b862b4c5abfda","IPY_MODEL_9dc0f0881da8435aab584b19ba8838e7"],"layout":"IPY_MODEL_376a0fb025094c209cf3665bf6eeb218"}},"949146025f07473981f2f41b5ffe310e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7be8dcc0d13545469cf7cb88af0acf8d","placeholder":"​","style":"IPY_MODEL_b1516c0901704b68974e130147c3e5c3","value":"Downloading (…)lve/main/config.json: 100%"}},"eb7fcb8ed3c04797b79b862b4c5abfda":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8726461d45c14a74bd2a29dbf97672b9","max":666,"min":0,"orientation":"horizontal","style":"IPY_MODEL_68e57eae0787467a851ab67b2a61c50c","value":666}},"9dc0f0881da8435aab584b19ba8838e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6594974b6d4e4025bd5b6796061467e0","placeholder":"​","style":"IPY_MODEL_103f28058bf34a49a186ea7e9c48506c","value":" 666/666 [00:00&lt;00:00, 36.5kB/s]"}},"376a0fb025094c209cf3665bf6eeb218":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7be8dcc0d13545469cf7cb88af0acf8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1516c0901704b68974e130147c3e5c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8726461d45c14a74bd2a29dbf97672b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68e57eae0787467a851ab67b2a61c50c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6594974b6d4e4025bd5b6796061467e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"103f28058bf34a49a186ea7e9c48506c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1ba7a9090e441d38d126bfed7bf82b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ddb46d77b12840d4963b595c05b02db0","IPY_MODEL_c55c9a41cd3545739e76e082702f40df","IPY_MODEL_06eb07af56ef49cf912e765ced9fc993"],"layout":"IPY_MODEL_86ef0c6d830d45a3ac8b724a59c9fa8f"}},"ddb46d77b12840d4963b595c05b02db0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e91861763ba4f34855779b6ff7d6ca4","placeholder":"​","style":"IPY_MODEL_8117cc24dd5f42c6bfba1f0e4fd4ffc2","value":"Downloading model.safetensors: 100%"}},"c55c9a41cd3545739e76e082702f40df":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9611ed782b2e4c28a5eda4d717a35b59","max":3247159078,"min":0,"orientation":"horizontal","style":"IPY_MODEL_872cd9f2c7f5412aab366de714a072ce","value":3247159078}},"06eb07af56ef49cf912e765ced9fc993":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd71b411e43f4b1d93dd8a077b0bd740","placeholder":"​","style":"IPY_MODEL_0ef30449059a47db8a462fe15700b6ac","value":" 3.25G/3.25G [00:18&lt;00:00, 92.4MB/s]"}},"86ef0c6d830d45a3ac8b724a59c9fa8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e91861763ba4f34855779b6ff7d6ca4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8117cc24dd5f42c6bfba1f0e4fd4ffc2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9611ed782b2e4c28a5eda4d717a35b59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"872cd9f2c7f5412aab366de714a072ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cd71b411e43f4b1d93dd8a077b0bd740":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ef30449059a47db8a462fe15700b6ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f97972e5e734fc69d4d706e44e926c5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_020a0d68f59e4c38a610152bde9d4470","IPY_MODEL_c0b5ec0781524066bc925206cacc1f6a","IPY_MODEL_08cced3dd21e4b0290794a2ea182cd0e"],"layout":"IPY_MODEL_a057ac09316f4779a578922820cc1334"}},"020a0d68f59e4c38a610152bde9d4470":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d30cae506bd14224949f594454eb0125","placeholder":"​","style":"IPY_MODEL_376eb24811374b8682e17f09d3f32127","value":"Downloading (…)neration_config.json: 100%"}},"c0b5ec0781524066bc925206cacc1f6a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d49a1dcbb9c64a2594d67e53beebb5c5","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ab88f10006c483c99d0f448c4541913","value":124}},"08cced3dd21e4b0290794a2ea182cd0e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e158672b99643c685de77e8b6a266b1","placeholder":"​","style":"IPY_MODEL_dc2876232f294c8e8b40022ce0498b2c","value":" 124/124 [00:00&lt;00:00, 6.00kB/s]"}},"a057ac09316f4779a578922820cc1334":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d30cae506bd14224949f594454eb0125":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"376eb24811374b8682e17f09d3f32127":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d49a1dcbb9c64a2594d67e53beebb5c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ab88f10006c483c99d0f448c4541913":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7e158672b99643c685de77e8b6a266b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc2876232f294c8e8b40022ce0498b2c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a644db2a4cae43f1bef65d96a45d40e1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e4259468ef794eba846cf77b8661ec42","IPY_MODEL_e6295bf7936e4e7ca3ed9a4b6e64d1de","IPY_MODEL_8f0974c163e644afa43af7dda1423b30"],"layout":"IPY_MODEL_547792a7017f4a15aa2fb539b1ac77f5"}},"e4259468ef794eba846cf77b8661ec42":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f32d3af8fad4c1eb1a3e2c3f7ec35f2","placeholder":"​","style":"IPY_MODEL_e65111f094eb4da9b0ceb8e1cd1e7a94","value":"Downloading (…)okenizer_config.json: 100%"}},"e6295bf7936e4e7ca3ed9a4b6e64d1de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f624e97ca2843989e9db7c5462a5cf1","max":699,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b793fee79dad41e199f1fb4359a1edb3","value":699}},"8f0974c163e644afa43af7dda1423b30":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4db296d5614e42a5a57235a5b06bd5fd","placeholder":"​","style":"IPY_MODEL_59980600689c40e49b889915cc5725fd","value":" 699/699 [00:00&lt;00:00, 33.2kB/s]"}},"547792a7017f4a15aa2fb539b1ac77f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f32d3af8fad4c1eb1a3e2c3f7ec35f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e65111f094eb4da9b0ceb8e1cd1e7a94":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f624e97ca2843989e9db7c5462a5cf1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b793fee79dad41e199f1fb4359a1edb3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4db296d5614e42a5a57235a5b06bd5fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59980600689c40e49b889915cc5725fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"143ed48cfa5e46d4ac83218b12e27416":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2bb8563aa55e4a138dfb8e8cb783cb17","IPY_MODEL_7c68dfeddd7541d987ce611eabee3b3e","IPY_MODEL_be29651dc5814a4a975e67587b9b336b"],"layout":"IPY_MODEL_28fb7f835aed4414b51ab8267387ad5b"}},"2bb8563aa55e4a138dfb8e8cb783cb17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e0b436f48bc475fa2cab567e5bf45d9","placeholder":"​","style":"IPY_MODEL_01daa6bb633b4125a486def0d5d4abd5","value":"Downloading tokenizer.model: 100%"}},"7c68dfeddd7541d987ce611eabee3b3e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7658607382242dfadd70f3ca8d77d1d","max":499723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1ddff7cbe7af4231b29476a59bb6dc83","value":499723}},"be29651dc5814a4a975e67587b9b336b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_551590b365334ef2bb711c0ff7e0819f","placeholder":"​","style":"IPY_MODEL_3e9e04aeac34403e8afcbbae41b9ec08","value":" 500k/500k [00:00&lt;00:00, 14.3MB/s]"}},"28fb7f835aed4414b51ab8267387ad5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e0b436f48bc475fa2cab567e5bf45d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01daa6bb633b4125a486def0d5d4abd5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7658607382242dfadd70f3ca8d77d1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ddff7cbe7af4231b29476a59bb6dc83":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"551590b365334ef2bb711c0ff7e0819f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e9e04aeac34403e8afcbbae41b9ec08":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1ccc4ac3cc0429f936c438f00fb6922":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_404146ed7d1a41129c1b644569fe4b72","IPY_MODEL_e5141bbae9944248a394edab7471874a","IPY_MODEL_79e6528ee066419ca9aadcb10959d28d"],"layout":"IPY_MODEL_5b4c1cbc3f8548e1a1fc32a127a7016b"}},"404146ed7d1a41129c1b644569fe4b72":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65c51901788e4194849986f0bfdedd0f","placeholder":"​","style":"IPY_MODEL_11f08d99afea41638b596377444640f9","value":"Downloading (…)/main/tokenizer.json: 100%"}},"e5141bbae9944248a394edab7471874a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b981363799b14feda630d35a4adc8331","max":1842847,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ba288ff7a644c6cb4c692b9ffaf8f22","value":1842847}},"79e6528ee066419ca9aadcb10959d28d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b5ee9acaee24ce99ce2e389021ac2e4","placeholder":"​","style":"IPY_MODEL_937cd19db7da49b98f655e194286666f","value":" 1.84M/1.84M [00:00&lt;00:00, 4.49MB/s]"}},"5b4c1cbc3f8548e1a1fc32a127a7016b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65c51901788e4194849986f0bfdedd0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11f08d99afea41638b596377444640f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b981363799b14feda630d35a4adc8331":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ba288ff7a644c6cb4c692b9ffaf8f22":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9b5ee9acaee24ce99ce2e389021ac2e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"937cd19db7da49b98f655e194286666f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"689b73965b1f4e90a6824e24b22e1d75":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8d2471c03e08495699d7f7a602756894","IPY_MODEL_a815b52a3dcf4b6dad26c41b1ff2357f","IPY_MODEL_0f42ebe4034a4faab3839d5502c1eb02"],"layout":"IPY_MODEL_f2c9d48d76054372901f11055aab5bc2"}},"8d2471c03e08495699d7f7a602756894":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fe57ea0997a4231b8a3b8b8293c6215","placeholder":"​","style":"IPY_MODEL_c4e1edf1f1a54e389cc789b5bbce08a4","value":"Downloading (…)in/added_tokens.json: 100%"}},"a815b52a3dcf4b6dad26c41b1ff2357f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_327db79542fd4826a265bfa18376f5e5","max":21,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b948cf4619e24ddc9bd5854291892aea","value":21}},"0f42ebe4034a4faab3839d5502c1eb02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03c159db8eed43d3a0204101d22ebb16","placeholder":"​","style":"IPY_MODEL_eae24f60fb804721b2ef168f8c97a128","value":" 21.0/21.0 [00:00&lt;00:00, 1.47kB/s]"}},"f2c9d48d76054372901f11055aab5bc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fe57ea0997a4231b8a3b8b8293c6215":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4e1edf1f1a54e389cc789b5bbce08a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"327db79542fd4826a265bfa18376f5e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b948cf4619e24ddc9bd5854291892aea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"03c159db8eed43d3a0204101d22ebb16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eae24f60fb804721b2ef168f8c97a128":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b7dff792a6343219215f06c9dcda968":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9009072d4dbe4221bb19b55c0f757ebf","IPY_MODEL_98514e7a4f4a4d9a8e1b6c9f756cd96f","IPY_MODEL_e02c3f6f51a047a78277714d70f7e5ab"],"layout":"IPY_MODEL_a529121b43fc43f5b38eb70f9b0eedd3"}},"9009072d4dbe4221bb19b55c0f757ebf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28a71faecdf8434090e9c5e03f340d25","placeholder":"​","style":"IPY_MODEL_6870f8dc459f4a3b983604578cbdc0e0","value":"Downloading (…)cial_tokens_map.json: 100%"}},"98514e7a4f4a4d9a8e1b6c9f756cd96f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6419d23ad1c84ef0a7871b442bc55d5a","max":410,"min":0,"orientation":"horizontal","style":"IPY_MODEL_626f46efb9694db9bf0ed6a2cb563fa9","value":410}},"e02c3f6f51a047a78277714d70f7e5ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9af6c4bf04614f4cb127b79069968da2","placeholder":"​","style":"IPY_MODEL_5b08e08060204d81a52304779aff2d54","value":" 410/410 [00:00&lt;00:00, 25.3kB/s]"}},"a529121b43fc43f5b38eb70f9b0eedd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28a71faecdf8434090e9c5e03f340d25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6870f8dc459f4a3b983604578cbdc0e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6419d23ad1c84ef0a7871b442bc55d5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"626f46efb9694db9bf0ed6a2cb563fa9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9af6c4bf04614f4cb127b79069968da2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b08e08060204d81a52304779aff2d54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac85e700799a408b8803fe59fd54c6a5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4184d8271108424eb37e7c9643fc3b28","IPY_MODEL_88e2ecbca4f540ac8529471d71a9d9aa","IPY_MODEL_851537ed89614577b1ee2ebf235dd9ae"],"layout":"IPY_MODEL_7dd9325214cd411eb16428aa15a0ad2b"}},"4184d8271108424eb37e7c9643fc3b28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_86a2eebcb66a451ab3356e6ef5f905ae","placeholder":"​","style":"IPY_MODEL_617890a12e774645a3c48f344b22f9eb","value":"Downloading (…)lve/main/config.json: 100%"}},"88e2ecbca4f540ac8529471d71a9d9aa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f22047008aed4f53b2d5136d8bf77bc0","max":587,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef0b93ed162d4f98ab6872eaecaa3154","value":587}},"851537ed89614577b1ee2ebf235dd9ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50567cb26acf4c819a5978cba1d54785","placeholder":"​","style":"IPY_MODEL_ffb50594e67b45e5ba1ed81b6cc94f80","value":" 587/587 [00:00&lt;00:00, 29.4kB/s]"}},"7dd9325214cd411eb16428aa15a0ad2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86a2eebcb66a451ab3356e6ef5f905ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"617890a12e774645a3c48f344b22f9eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f22047008aed4f53b2d5136d8bf77bc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef0b93ed162d4f98ab6872eaecaa3154":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50567cb26acf4c819a5978cba1d54785":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffb50594e67b45e5ba1ed81b6cc94f80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d1b14b9907448d282f1b905357317cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_473650d5712c4b849ec71e6ce56afaa7","IPY_MODEL_9148417b8b704a65820da995a85d884a","IPY_MODEL_71b4116b2a7f40e88a79f9ef84b989d2"],"layout":"IPY_MODEL_d5ddca6dd8c04c0083c3d6c15743a0fd"}},"473650d5712c4b849ec71e6ce56afaa7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb5ea0456d7b4dcbbd8e6fce643e769e","placeholder":"​","style":"IPY_MODEL_47e3fb988eba478a9fe0b5a38b500a6f","value":"Downloading (…)ct-order.safetensors: 100%"}},"9148417b8b704a65820da995a85d884a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fae35eec7f94e5bb3625e4b01539781","max":7255179696,"min":0,"orientation":"horizontal","style":"IPY_MODEL_68f2f2f963f44539a235f5e56fb53816","value":7255179696}},"71b4116b2a7f40e88a79f9ef84b989d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5baca5a2bf3849bc84a6b524c83129b2","placeholder":"​","style":"IPY_MODEL_8cb482f6fd214c4da2d342b722ea2736","value":" 7.26G/7.26G [00:50&lt;00:00, 80.5MB/s]"}},"d5ddca6dd8c04c0083c3d6c15743a0fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb5ea0456d7b4dcbbd8e6fce643e769e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47e3fb988eba478a9fe0b5a38b500a6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7fae35eec7f94e5bb3625e4b01539781":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68f2f2f963f44539a235f5e56fb53816":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5baca5a2bf3849bc84a6b524c83129b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cb482f6fd214c4da2d342b722ea2736":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1246182,"sourceType":"datasetVersion","datasetId":715500},{"sourceId":6387462,"sourceType":"datasetVersion","datasetId":3681534},{"sourceId":6420616,"sourceType":"datasetVersion","datasetId":3703801},{"sourceId":6426697,"sourceType":"datasetVersion","datasetId":3707863},{"sourceId":6435720,"sourceType":"datasetVersion","datasetId":3713974},{"sourceId":6556297,"sourceType":"datasetVersion","datasetId":3732280}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install info-nce-pytorch","metadata":{"id":"7juYrJuNnHn-","execution":{"iopub.status.busy":"2023-09-13T07:26:34.230192Z","iopub.execute_input":"2023-09-13T07:26:34.230606Z","iopub.status.idle":"2023-09-13T07:26:34.235392Z","shell.execute_reply.started":"2023-09-13T07:26:34.230576Z","shell.execute_reply":"2023-09-13T07:26:34.234204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip","metadata":{"id":"mEsymC32nN6K","outputId":"cb1eecec-e38a-47b6-d4d7-6e9aa7f605cf","execution":{"iopub.status.busy":"2023-11-16T09:13:25.852571Z","iopub.execute_input":"2023-11-16T09:13:25.852878Z","iopub.status.idle":"2023-11-16T09:13:30.161247Z","shell.execute_reply.started":"2023-11-16T09:13:25.852852Z","shell.execute_reply":"2023-11-16T09:13:30.160150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"TAVjuJ6LnN8N","execution":{"iopub.status.busy":"2023-11-16T09:13:33.224679Z","iopub.execute_input":"2023-11-16T09:13:33.225057Z","iopub.status.idle":"2023-11-16T09:13:34.257974Z","shell.execute_reply.started":"2023-11-16T09:13:33.225023Z","shell.execute_reply":"2023-11-16T09:13:34.256363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip","metadata":{"id":"KgkleXN6nN-X","outputId":"19a711ad-1110-4cd8-baff-b8d7808b9cc5","execution":{"iopub.status.busy":"2023-11-16T09:13:35.628915Z","iopub.execute_input":"2023-11-16T09:13:35.629542Z","iopub.status.idle":"2023-11-16T09:13:36.919992Z","shell.execute_reply.started":"2023-11-16T09:13:35.629499Z","shell.execute_reply":"2023-11-16T09:13:36.919054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:13:37.082214Z","iopub.execute_input":"2023-11-16T09:13:37.082900Z","iopub.status.idle":"2023-11-16T09:13:38.026222Z","shell.execute_reply.started":"2023-11-16T09:13:37.082868Z","shell.execute_reply":"2023-11-16T09:13:38.025211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip -q ./Flickr8k_Dataset.zip","metadata":{"id":"2_r80dCmnOAx","execution":{"iopub.status.busy":"2023-11-16T09:13:39.754343Z","iopub.execute_input":"2023-11-16T09:13:39.755222Z","iopub.status.idle":"2023-11-16T09:13:48.827797Z","shell.execute_reply.started":"2023-11-16T09:13:39.755182Z","shell.execute_reply":"2023-11-16T09:13:48.826579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip -q ./Flickr8k_text.zip","metadata":{"id":"MD5bgblQnOC6","execution":{"iopub.status.busy":"2023-11-16T09:13:48.830100Z","iopub.execute_input":"2023-11-16T09:13:48.830487Z","iopub.status.idle":"2023-11-16T09:13:49.854052Z","shell.execute_reply.started":"2023-11-16T09:13:48.830450Z","shell.execute_reply":"2023-11-16T09:13:49.852756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\nimport random\nimport wandb\nimport torch\nimport numpy as np\nimport os\ntorch.use_deterministic_algorithms(True)\ndef set_seed(seed):\n\n    random.seed(seed)     # python random generator\n    np.random.seed(seed)  # numpy random generator\n\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:13:55.656957Z","iopub.execute_input":"2023-11-16T09:13:55.657628Z","iopub.status.idle":"2023-11-16T09:13:59.698117Z","shell.execute_reply.started":"2023-11-16T09:13:55.657582Z","shell.execute_reply":"2023-11-16T09:13:59.697326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom PIL import Image\n","metadata":{"id":"8XKkDx2cnOIl","execution":{"iopub.status.busy":"2023-11-16T09:13:59.699859Z","iopub.execute_input":"2023-11-16T09:13:59.700602Z","iopub.status.idle":"2023-11-16T09:13:59.705208Z","shell.execute_reply.started":"2023-11-16T09:13:59.700564Z","shell.execute_reply":"2023-11-16T09:13:59.704308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#raw_image = Image.open('./Flicker8k_Dataset/1001773457_577c3a7d70.jpg')","metadata":{"id":"0sv3mtn6nOK6","execution":{"iopub.status.busy":"2023-11-16T09:03:37.069949Z","iopub.execute_input":"2023-11-16T09:03:37.070266Z","iopub.status.idle":"2023-11-16T09:03:37.079680Z","shell.execute_reply.started":"2023-11-16T09:03:37.070229Z","shell.execute_reply":"2023-11-16T09:03:37.078867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#raw_image","metadata":{"id":"NGZL_BYrnOME","outputId":"2c793edb-b1e0-4137-a485-03bf707058cd","execution":{"iopub.status.busy":"2023-11-16T09:03:37.084051Z","iopub.execute_input":"2023-11-16T09:03:37.084443Z","iopub.status.idle":"2023-11-16T09:03:37.091011Z","shell.execute_reply.started":"2023-11-16T09:03:37.084418Z","shell.execute_reply":"2023-11-16T09:03:37.090119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/openai/CLIP.git\n    \n    ","metadata":{"id":"sPL9UgPzT8NE","outputId":"c66b37ec-12cd-47c5-fc2f-7ed5772775e6","execution":{"iopub.status.busy":"2023-11-16T09:14:00.036793Z","iopub.execute_input":"2023-11-16T09:14:00.037949Z","iopub.status.idle":"2023-11-16T09:14:16.265279Z","shell.execute_reply.started":"2023-11-16T09:14:00.037914Z","shell.execute_reply":"2023-11-16T09:14:16.264072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport clip\nfrom PIL import Image\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel, preprocess = clip.load(\"ViT-B/32\", device=device)\n\n# image = preprocess(Image.open('./Flicker8k_Dataset/1001773457_577c3a7d70.jpg')).unsqueeze(0).to(device)\n# text = clip.tokenize([\"a diagram\", \"a dog\", \"a cat\"]).to(device)\n\n# with torch.no_grad():\n#     image_features = model.encode_image(image)\n#     text_features = model.encode_text(text)\n\n#     logits_per_image, logits_per_text = model(image, text)\n#     probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n\n# print(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421068 0.00299572]]","metadata":{"id":"9r4o1jYNUAid","outputId":"59236727-868d-4094-bd9d-595e294cfea4","execution":{"iopub.status.busy":"2023-11-16T09:14:16.267381Z","iopub.execute_input":"2023-11-16T09:14:16.267722Z","iopub.status.idle":"2023-11-16T09:14:27.743535Z","shell.execute_reply.started":"2023-11-16T09:14:16.267691Z","shell.execute_reply":"2023-11-16T09:14:27.742726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.514897Z","iopub.status.idle":"2023-09-13T07:27:25.516072Z","shell.execute_reply.started":"2023-09-13T07:27:25.515707Z","shell.execute_reply":"2023-09-13T07:27:25.515742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_features.shape","metadata":{"id":"Xycy4xzqUAkp","outputId":"64c285e9-e17b-4c0f-8437-619336abd5d2","execution":{"iopub.status.busy":"2023-09-13T07:27:25.517450Z","iopub.status.idle":"2023-09-13T07:27:25.519549Z","shell.execute_reply.started":"2023-09-13T07:27:25.519129Z","shell.execute_reply":"2023-09-13T07:27:25.519166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_features.shape","metadata":{"id":"pJ2zWdXsUAm7","outputId":"041fbd35-73fc-412a-a14e-2566e85ec332","execution":{"iopub.status.busy":"2023-09-13T07:27:25.521375Z","iopub.status.idle":"2023-09-13T07:27:25.522891Z","shell.execute_reply.started":"2023-09-13T07:27:25.522343Z","shell.execute_reply":"2023-09-13T07:27:25.522367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"ybbY-eTaUArZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"AoPIUDQfUAts"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import torch\n# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n# from lavis.models import load_model_and_preprocess\n# model, vis_processors, txt_processors = load_model_and_preprocess(name=\"clip_feature_extractor\", model_type=\"base\", is_eval=True, device=device)","metadata":{"id":"LaXm-IjYnmGb","execution":{"iopub.status.busy":"2023-09-13T07:27:25.524726Z","iopub.status.idle":"2023-09-13T07:27:25.532286Z","shell.execute_reply.started":"2023-09-13T07:27:25.532044Z","shell.execute_reply":"2023-09-13T07:27:25.532068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def get_tensor(caption, raw_image):\n#     image = preprocess(raw_image).unsqueeze(0).to(device)\n#     text = clip.tokenize([caption]).to(device)\n\n#     with torch.no_grad():\n#         image_features = model.encode_image(image)\n#         text_features = model.encode_text(text)\n\n#     return image_features.squeeze(0).cpu(), text_features.squeeze(0).cpu()","metadata":{"id":"0w_86iJWnmIx","execution":{"iopub.status.busy":"2023-09-13T07:27:25.533760Z","iopub.status.idle":"2023-09-13T07:27:25.534232Z","shell.execute_reply.started":"2023-09-13T07:27:25.534004Z","shell.execute_reply":"2023-09-13T07:27:25.534026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with open('./Flickr8k.token.txt' , 'r') as f:\n#     kk = f.readlines()","metadata":{"id":"FMcCWwnInmK7","execution":{"iopub.status.busy":"2023-09-13T07:27:25.536390Z","iopub.status.idle":"2023-09-13T07:27:25.536842Z","shell.execute_reply.started":"2023-09-13T07:27:25.536605Z","shell.execute_reply":"2023-09-13T07:27:25.536626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"id":"_bbpvEmXtAx_","execution":{"iopub.status.busy":"2023-11-16T09:03:54.407547Z","iopub.execute_input":"2023-11-16T09:03:54.407858Z","iopub.status.idle":"2023-11-16T09:03:54.412731Z","shell.execute_reply.started":"2023-11-16T09:03:54.407828Z","shell.execute_reply":"2023-11-16T09:03:54.411876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"ROZXhhArWPX0","outputId":"fdb00a59-a567-4673-f33a-32db22772347","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_tensor = []\ntxt_tensor = []\nset_seed(42)\n#for i in tqdm(range(len(kk))):\nfor i in tqdm(range(800)):\n    nos = kk[i].split('\\t')[0].split('#')[1]\n    # print(nos)\n    if nos=='1':\n        img = kk[i].split('\\t')[0].split('#')[0]\n        txt = kk[i].split('\\t')[1].strip().lower()\n        try:\n            raw_image = Image.open('./Flicker8k_Dataset/'+img)\n        except:\n            print(1)\n            continue\n        it, tt = get_tensor(txt, raw_image)\n        img_tensor.append(it)\n        txt_tensor.append(tt)\n","metadata":{"id":"WwJ1vqUBnmNN","outputId":"e3b82fa8-245d-4672-83df-b4ba37c24d01","execution":{"iopub.status.busy":"2023-11-16T09:03:54.413830Z","iopub.execute_input":"2023-11-16T09:03:54.414124Z","iopub.status.idle":"2023-11-16T09:03:54.887410Z","shell.execute_reply.started":"2023-11-16T09:03:54.414100Z","shell.execute_reply":"2023-11-16T09:03:54.886070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_tensor = torch.stack(img_tensor)","metadata":{"id":"qWPCJGGrry5k","execution":{"iopub.status.busy":"2023-11-16T09:03:54.888290Z","iopub.status.idle":"2023-11-16T09:03:54.888620Z","shell.execute_reply.started":"2023-11-16T09:03:54.888460Z","shell.execute_reply":"2023-11-16T09:03:54.888475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_tensor.shape\n","metadata":{"id":"sl4-SPBaZAJU","outputId":"7c6271da-c385-449d-c152-5076aa8ec8eb","execution":{"iopub.status.busy":"2023-09-13T07:27:25.549902Z","iopub.status.idle":"2023-09-13T07:27:25.550392Z","shell.execute_reply.started":"2023-09-13T07:27:25.550160Z","shell.execute_reply":"2023-09-13T07:27:25.550183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"txt_tensor = torch.stack(txt_tensor)","metadata":{"id":"rMKURrauZXcs","execution":{"iopub.status.busy":"2023-09-13T07:27:25.555792Z","iopub.status.idle":"2023-09-13T07:27:25.556254Z","shell.execute_reply.started":"2023-09-13T07:27:25.556024Z","shell.execute_reply":"2023-09-13T07:27:25.556046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntxt_tensor.shape","metadata":{"id":"1gIgy2xVZbhb","outputId":"e28cbebb-aa8d-4797-fba4-3148b9e5eadd","execution":{"iopub.status.busy":"2023-09-13T07:27:25.558301Z","iopub.status.idle":"2023-09-13T07:27:25.558760Z","shell.execute_reply.started":"2023-09-13T07:27:25.558521Z","shell.execute_reply":"2023-09-13T07:27:25.558543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass CustomDataset(Dataset):\n    def __init__(self, tensor1, tensor2):\n        self.tensor1 = tensor1\n        self.tensor2 = tensor2\n\n    def __len__(self):\n        return len(self.tensor1)\n\n    def __getitem__(self, idx):\n        return self.tensor1[idx], self.tensor2[idx]\n\ndef collate_fn(batch):\n    tensor1_batch, tensor2_batch = zip(*batch)\n    return torch.stack(tensor1_batch), torch.stack(tensor2_batch)\n\n# Create your tensors\nN = 100  # Example number of samples\ntensor1 = img_tensor\ntensor2 = txt_tensor\n\n# Create a custom dataset\ncustom_dataset = CustomDataset(tensor1, tensor2)\n\n# Create a DataLoader with your collate_fn\nbatch_size = 32\ndataloader = DataLoader(custom_dataset, batch_size=batch_size, collate_fn=collate_fn)\n\n# # Iterate through the DataLoader\n# for batch_tensor1, batch_tensor2 in dataloader:\n#     print(\"Tensor 1 batch shape:\", batch_tensor1.shape)\n#     print(\"Tensor 2 batch shape:\", batch_tensor2.shape)\n#     print(\"-\" * 30)\n","metadata":{"id":"nbJ2Bls4nmPT","execution":{"iopub.status.busy":"2023-11-16T09:03:54.890124Z","iopub.status.idle":"2023-11-16T09:03:54.890453Z","shell.execute_reply.started":"2023-11-16T09:03:54.890291Z","shell.execute_reply":"2023-11-16T09:03:54.890307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Simulated batch sizes and vector dimensions\nbatch_size = 32\nvector_dim = 1024","metadata":{"id":"XFkaiCZCnmRY","execution":{"iopub.status.busy":"2023-11-16T09:14:27.745112Z","iopub.execute_input":"2023-11-16T09:14:27.745396Z","iopub.status.idle":"2023-11-16T09:14:27.750198Z","shell.execute_reply.started":"2023-11-16T09:14:27.745370Z","shell.execute_reply":"2023-11-16T09:14:27.749243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mdl = nn.Sequential(nn.Linear(vector_dim, 256), nn.ReLU(), nn.Linear(256, 512)).to(device)","metadata":{"id":"_lrdSJvxnmTc","execution":{"iopub.status.busy":"2023-11-16T09:14:27.751355Z","iopub.execute_input":"2023-11-16T09:14:27.751718Z","iopub.status.idle":"2023-11-16T09:14:29.167545Z","shell.execute_reply.started":"2023-11-16T09:14:27.751682Z","shell.execute_reply":"2023-11-16T09:14:29.166572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nclass fusion(nn.Module):\n    def __init__(self,img_feat_size, txt_feat_size, is_first, K, O, DROPOUT_R):\n        super(fusion, self).__init__()\n        #self.__C = __C\n        self.K = K\n        self.O = O\n        self.DROPOUT_R = DROPOUT_R\n\n        self.is_first = is_first\n        self.proj_i = nn.Linear(img_feat_size, K * O)\n        self.proj_t = nn.Linear(txt_feat_size, K * O)\n\n        self.dropout = nn.Dropout(DROPOUT_R)\n        self.pool = nn.AvgPool1d(K, stride = K)\n\n    def forward(self, img_feat, txt_feat, exp_in=1):\n\n        batch_size = img_feat.shape[0]\n        img_feat = self.proj_i(img_feat)\n        txt_feat = self.proj_t(txt_feat)\n\n        exp_out = img_feat * txt_feat\n        exp_out = self.dropout(exp_out) if self.is_first else self.dropout(exp_out * exp_in)\n        z = self.pool(exp_out) * self.K\n        z = F.normalize(z.view(batch_size, -1))\n        z = z.view(batch_size, -1, self.O)\n        return z","metadata":{"id":"-62EcJyJTfWT","execution":{"iopub.status.busy":"2023-11-16T09:14:29.170252Z","iopub.execute_input":"2023-11-16T09:14:29.171252Z","iopub.status.idle":"2023-11-16T09:14:29.180397Z","shell.execute_reply.started":"2023-11-16T09:14:29.171222Z","shell.execute_reply":"2023-11-16T09:14:29.179533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Jz2_TyGnTgOh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# optimizer = optim.Adam(mdl.parameters(), lr=1e-5)\n\n\n# # Training loop\n# num_epochs = 500\n# def transpose(x):\n#     return x.transpose(-2, -1)\n\n# for epoch in tqdm(range(num_epochs)):\n#     l=0\n#     cnt = 0\n#     for image_tensor, text_tensor in dataloader:\n#         # print(batch_model1, batch_model1)\n#         image_tensor = image_tensor.unsqueeze(1).float().to(device)\n#         text_tensor = text_tensor.unsqueeze(1).float().to(device)\n#         # joint_tensor = torch.cat((image_tensor, text_tensor), dim=1)\n#         # print(image_tensor)\n#         multimodal_tensor = mdl(image_tensor, text_tensor).squeeze(dim=1)\n\n#         #Normalizing both of the vectors to unit dimension\n#         p = torch.nn.functional.normalize(multimodal_tensor, dim=-1)\n#         q = torch.nn.functional.normalize(image_tensor.squeeze(dim=1), dim=-1)\n#         r = torch.nn.functional.normalize(text_tensor.squeeze(dim=1), dim=-1)\n\n\n#         labels = torch.arange(len(p)).to(device)\n\n\n#         logits = p @ transpose(q)\n#         temperature = 0.8\n#         loss_0 = torch.nn.functional.cross_entropy(logits / temperature, labels, reduction='mean')\n\n\n#         logits_1 = p @ transpose(r)\n#         temperature = 0.8\n#         loss_1 = torch.nn.functional.cross_entropy(logits_1 / temperature, labels, reduction='mean')\n\n\n#         loss = loss_0+loss_1\n\n\n#         loss.backward()\n#         optimizer.step()\n#         optimizer.zero_grad()\n\n#         l+=loss.detach().item()\n#         cnt+=1\n\n#     print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {l/cnt}\")\n\n# print(\"Training complete!\")\n","metadata":{"id":"_lSGMin_oOBS","outputId":"4b040225-9146-4758-e545-de7e07a1c35e","execution":{"iopub.status.busy":"2023-11-16T09:14:29.181433Z","iopub.execute_input":"2023-11-16T09:14:29.181683Z","iopub.status.idle":"2023-11-16T09:14:29.195312Z","shell.execute_reply.started":"2023-11-16T09:14:29.181661Z","shell.execute_reply":"2023-11-16T09:14:29.194530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls\n","metadata":{"id":"NSOgMDUSoOD2","execution":{"iopub.status.busy":"2023-11-16T09:14:29.196394Z","iopub.execute_input":"2023-11-16T09:14:29.196694Z","iopub.status.idle":"2023-11-16T09:14:30.186262Z","shell.execute_reply.started":"2023-11-16T09:14:29.196668Z","shell.execute_reply":"2023-11-16T09:14:30.185268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# {\"username\":\"newcodevelop\",\"key\":\"4ee1aba876485ad4ff02791b2959a664\"}\n# os.environ[\"KAGGLE_CONFIG_DIR\"] = \"/content/\"\nos.environ[\"KAGGLE_USERNAME\"]=\"newcodevelop\"\nos.environ[\"KAGGLE_KEY\"]=\"bcc404580ff37b2f37118ee42a7cc1fe4\"","metadata":{"id":"3P95KLBEoOGO","execution":{"iopub.status.busy":"2023-11-16T09:14:30.188030Z","iopub.execute_input":"2023-11-16T09:14:30.188831Z","iopub.status.idle":"2023-11-16T09:14:30.194096Z","shell.execute_reply.started":"2023-11-16T09:14:30.188788Z","shell.execute_reply":"2023-11-16T09:14:30.193171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!kaggle datasets download -d parthplc/facebook-hateful-meme-dataset","metadata":{"id":"ITxHk1DooOKt","outputId":"31344294-9f36-49ed-9ea9-e8f5fe8b12bd","execution":{"iopub.status.busy":"2023-11-16T09:14:30.195284Z","iopub.execute_input":"2023-11-16T09:14:30.195534Z","iopub.status.idle":"2023-11-16T09:14:31.609962Z","shell.execute_reply.started":"2023-11-16T09:14:30.195510Z","shell.execute_reply":"2023-11-16T09:14:31.608757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:04:12.250972Z","iopub.execute_input":"2023-11-16T09:04:12.251925Z","iopub.status.idle":"2023-11-16T09:04:13.202703Z","shell.execute_reply.started":"2023-11-16T09:04:12.251855Z","shell.execute_reply":"2023-11-16T09:04:13.201643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip -q ./facebook-hateful-meme-dataset.zip","metadata":{"id":"R12YVOCfoOMw","execution":{"iopub.status.busy":"2023-11-16T09:04:13.204600Z","iopub.execute_input":"2023-11-16T09:04:13.204933Z","iopub.status.idle":"2023-11-16T09:04:14.155755Z","shell.execute_reply.started":"2023-11-16T09:04:13.204892Z","shell.execute_reply":"2023-11-16T09:04:14.154535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %cd /kaggle/working/data","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:14:43.493744Z","iopub.execute_input":"2023-11-16T09:14:43.494810Z","iopub.status.idle":"2023-11-16T09:14:43.499467Z","shell.execute_reply.started":"2023-11-16T09:14:43.494761Z","shell.execute_reply":"2023-11-16T09:14:43.498556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !grep -r \"dick\"","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:14:51.004539Z","iopub.execute_input":"2023-11-16T09:14:51.005289Z","iopub.status.idle":"2023-11-16T09:14:51.009327Z","shell.execute_reply.started":"2023-11-16T09:14:51.005253Z","shell.execute_reply":"2023-11-16T09:14:51.008303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nim = Image.open(\"/kaggle/input/facebook-hateful-meme-dataset/data/img/05471.png\")","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:15:00.448290Z","iopub.execute_input":"2023-11-16T09:15:00.448682Z","iopub.status.idle":"2023-11-16T09:15:00.491194Z","shell.execute_reply.started":"2023-11-16T09:15:00.448650Z","shell.execute_reply":"2023-11-16T09:15:00.490486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im.save('picc.jpg')","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:15:01.841271Z","iopub.execute_input":"2023-11-16T09:15:01.841672Z","iopub.status.idle":"2023-11-16T09:15:01.857793Z","shell.execute_reply.started":"2023-11-16T09:15:01.841638Z","shell.execute_reply":"2023-11-16T09:15:01.857041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install jsonlines","metadata":{"id":"QpzBONG8vprZ","outputId":"775ec5bb-6980-4096-9434-e7ee8574e166","execution":{"iopub.status.busy":"2023-11-16T09:15:03.274042Z","iopub.execute_input":"2023-11-16T09:15:03.274415Z","iopub.status.idle":"2023-11-16T09:15:14.448811Z","shell.execute_reply.started":"2023-11-16T09:15:03.274385Z","shell.execute_reply":"2023-11-16T09:15:14.447561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import jsonlines","metadata":{"id":"okcH-0nFvrHh","execution":{"iopub.status.busy":"2023-11-16T09:15:14.451366Z","iopub.execute_input":"2023-11-16T09:15:14.452202Z","iopub.status.idle":"2023-11-16T09:15:14.473050Z","shell.execute_reply.started":"2023-11-16T09:15:14.452141Z","shell.execute_reply":"2023-11-16T09:15:14.472274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# im_tensor,tx_tensor = [],[]\n# gold_label = []\n# img_id = []\n# counter = 0\n# set_seed(42)\n# with jsonlines.open('/kaggle/input/facebook-hateful-meme-dataset/data/train.jsonl') as f:\n#       for line in tqdm(f):\n#         # print(line)\n\n#         hypo = line['text']\n\n#         raw_image = Image.open('./data/'+str(line['img']))\n#         try:\n#             it, tt = get_tensor(hypo, raw_image)\n#         except:\n#             continue\n#         im_tensor.append(it)\n#         tx_tensor.append(tt)\n#         gold_label.append(int(line['label']))\n#         img_id.append(str(line['img']))\n#         counter+=1\n#         if counter==8500:\n#             break\n","metadata":{"id":"VCi8oRpLnmVY","outputId":"3d1be9c4-1707-4074-9803-b5eee4b7001a","execution":{"iopub.status.busy":"2023-11-16T09:15:21.383693Z","iopub.execute_input":"2023-11-16T09:15:21.384074Z","iopub.status.idle":"2023-11-16T09:15:21.389183Z","shell.execute_reply.started":"2023-11-16T09:15:21.384047Z","shell.execute_reply":"2023-11-16T09:15:21.388249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# im_tensor_,tx_tensor_ = [],[]\n# img_id_ = []\n# gold_label_ = []\n# counter = 0\n# set_seed(42)\n# with jsonlines.open('/kaggle/input/facebook-hateful-meme-dataset/data/dev.jsonl') as f:\n#       for line in tqdm(f):\n\n#         hypo = line['text']\n#         gold_label_.append(int(line['label']))\n#         raw_image = Image.open('./data/'+str(line['img']))\n#         img_id_.append(str(line['img']))\n#         it, tt = get_tensor(hypo, raw_image)\n#         im_tensor_.append(it)\n#         tx_tensor_.append(tt)\n\n","metadata":{"id":"rquKed4Y8WMI","outputId":"de11ff53-9f2e-4387-ee55-778730ecd7db","execution":{"iopub.status.busy":"2023-11-16T09:15:26.215182Z","iopub.execute_input":"2023-11-16T09:15:26.216095Z","iopub.status.idle":"2023-11-16T09:15:26.220130Z","shell.execute_reply.started":"2023-11-16T09:15:26.216059Z","shell.execute_reply":"2023-11-16T09:15:26.219246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:15:27.570900Z","iopub.execute_input":"2023-11-16T09:15:27.571256Z","iopub.status.idle":"2023-11-16T09:15:27.575639Z","shell.execute_reply.started":"2023-11-16T09:15:27.571225Z","shell.execute_reply":"2023-11-16T09:15:27.574635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id2text = {}\nwith jsonlines.open('/kaggle/input/facebook-hateful-meme-dataset/data/dev.jsonl') as f:\n    for line in tqdm(f):\n\n        id2text[str(line['img']).split('/')[1]] = line['text']\n    \n        \n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:23:14.971517Z","iopub.execute_input":"2023-11-16T09:23:14.972467Z","iopub.status.idle":"2023-11-16T09:23:14.994725Z","shell.execute_reply.started":"2023-11-16T09:23:14.972432Z","shell.execute_reply":"2023-11-16T09:23:14.993780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:15:34.305265Z","iopub.execute_input":"2023-11-16T09:15:34.305960Z","iopub.status.idle":"2023-11-16T09:15:34.310573Z","shell.execute_reply.started":"2023-11-16T09:15:34.305926Z","shell.execute_reply":"2023-11-16T09:15:34.309629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id2text = {}\nwith jsonlines.open('/kaggle/input/facebook-hateful-meme-dataset/data/train.jsonl') as f:\n    for line in tqdm(f):\n\n        id2text[str(line['img']).split('/')[1]] = int(line['label'])\n    \n        \n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:20:45.176323Z","iopub.execute_input":"2023-11-16T09:20:45.176757Z","iopub.status.idle":"2023-11-16T09:20:45.222285Z","shell.execute_reply.started":"2023-11-16T09:20:45.176722Z","shell.execute_reply":"2023-11-16T09:20:45.221410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id2text","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:23:17.453273Z","iopub.execute_input":"2023-11-16T09:23:17.453643Z","iopub.status.idle":"2023-11-16T09:23:17.476225Z","shell.execute_reply.started":"2023-11-16T09:23:17.453606Z","shell.execute_reply":"2023-11-16T09:23:17.475129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(id2text)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:22:43.197212Z","iopub.execute_input":"2023-11-16T09:22:43.197622Z","iopub.status.idle":"2023-11-16T09:22:43.204227Z","shell.execute_reply.started":"2023-11-16T09:22:43.197577Z","shell.execute_reply":"2023-11-16T09:22:43.203275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.616748Z","iopub.status.idle":"2023-09-13T07:27:25.617592Z","shell.execute_reply.started":"2023-09-13T07:27:25.617357Z","shell.execute_reply":"2023-09-13T07:27:25.617380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import gdown","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.619569Z","iopub.status.idle":"2023-09-13T07:27:25.620039Z","shell.execute_reply.started":"2023-09-13T07:27:25.619785Z","shell.execute_reply":"2023-09-13T07:27:25.619806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# url = 'https://drive.google.com/u/0/uc?id=1JPQA1jcmfDYkEK_89U_UP-VtyUrTwJKi'\n# output = 'entity_json.zip'","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.625848Z","iopub.status.idle":"2023-09-13T07:27:25.626333Z","shell.execute_reply.started":"2023-09-13T07:27:25.626090Z","shell.execute_reply":"2023-09-13T07:27:25.626112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gdown.download(url, output, quiet=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.627636Z","iopub.status.idle":"2023-09-13T07:27:25.628095Z","shell.execute_reply.started":"2023-09-13T07:27:25.627838Z","shell.execute_reply":"2023-09-13T07:27:25.627860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !unzip -q ./entity_json.zip","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.630664Z","iopub.status.idle":"2023-09-13T07:27:25.631140Z","shell.execute_reply.started":"2023-09-13T07:27:25.630885Z","shell.execute_reply":"2023-09-13T07:27:25.630906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\nimport spacy\nimport pickle\nfrom tqdm import tqdm\nimport requests\nimport pandas as pd\n\n#nlp = spacy.load(\"en_core_web_sm\")","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:15:58.098960Z","iopub.execute_input":"2023-11-16T09:15:58.099370Z","iopub.status.idle":"2023-11-16T09:16:08.727739Z","shell.execute_reply.started":"2023-11-16T09:15:58.099337Z","shell.execute_reply":"2023-11-16T09:16:08.726657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# with open('./caption_fb_dataset.pickle', 'rb') as h:\n#      caption = pickle.load(h)\n\n# print(caption)\n\n# loef = os.listdir('./entity_json')\n# ll = []\n# for i in loef:\n#     candidate = i.split('.')\n#     if len(candidate)==3:\n#         ll.append(candidate[0]+'.0.json')\n#     else:\n#         ll.append(i)\n\n# loef = list(set(ll))\n\n# print(len(ll))\n# print(len(loef))","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:05:27.390133Z","iopub.execute_input":"2023-11-16T09:05:27.391098Z","iopub.status.idle":"2023-11-16T09:05:27.395856Z","shell.execute_reply.started":"2023-11-16T09:05:27.391061Z","shell.execute_reply":"2023-11-16T09:05:27.394825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\n# # exit(0)\n# TAGS = {}\n# cnt=0\n# bad_names = []\n# for i_ in tqdm(loef):\n#     f = open(os.path.join(os.getcwd(),'entity_json/'+i_))\n#     k = json.load(f)\n#     # print('*****************************')\n#     # print(caption[i_.split('.')[0]+'.png'])\n\n#     # print(k['bestGuessLabels'])\n\n#     try:\n\n#         ners = []\n#         for i in range(len(k['webEntities'])):\n\n#             try:\n#                 doc = nlp(k['webEntities'][i]['description'])\n#                 for ent in doc.ents:\n#                     # print(ent.text, ent.start_char, ent.end_char, ent.label_)\n#                     ners.append((ent.text, ent.label_))\n\n#             except:\n#                 break\n#         if len(i_.split('.'))==3:\n#             TAGS[i_.split('.')[0]+'.'+i_.split('.')[2]] = ners\n#         else:\n#             TAGS[i_.split('.')[0]+'.'+i_.split('.')[1]] = ners\n\n#         # print(TAGS)\n#     except:\n#         print('in except')\n#         if len(i_.split('.'))==3:\n#             bad_names.append(i_.split('.')[0]+'.'+i_.split('.')[2])\n#         else:\n#             bad_names.append(i_.split('.')[0]+'.'+i_.split('.')[1])\n\n\n#     f.close()\n#     # cnt+=1\n#     # if cnt==15:\n#     #     break\n\n# # print(TAGS)\n# print('total in except {}'.format(len(bad_names)))\n# print(bad_names)\n\n# PROMPTS = {}\n# for i_ in tqdm(caption):\n\n#     fname = i_.split('.')[0]+'.json'\n#     # print(fname)\n#     if fname in bad_names:\n#         continue\n\n\n#     tags = [i[0] for i in TAGS[fname]]\n#     tags_ = 'I have entities like'\n#     for i in tags:\n#         tags_+= ' '+i+','\n\n#     tags = tags_\n#     # print(tags)\n#     PROMPTS[i_] = tags","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:05:27.397194Z","iopub.execute_input":"2023-11-16T09:05:27.397768Z","iopub.status.idle":"2023-11-16T09:05:27.411513Z","shell.execute_reply.started":"2023-11-16T09:05:27.397715Z","shell.execute_reply":"2023-11-16T09:05:27.410700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:16:08.729631Z","iopub.execute_input":"2023-11-16T09:16:08.730830Z","iopub.status.idle":"2023-11-16T09:16:08.734781Z","shell.execute_reply.started":"2023-11-16T09:16:08.730790Z","shell.execute_reply":"2023-11-16T09:16:08.733855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kb_fb = torch.load('/kaggle/input/kb-fb-ds/kb_fb.pt')","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:16:08.735885Z","iopub.execute_input":"2023-11-16T09:16:08.736142Z","iopub.status.idle":"2023-11-16T09:16:08.806088Z","shell.execute_reply.started":"2023-11-16T09:16:08.736117Z","shell.execute_reply":"2023-11-16T09:16:08.805317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# kb_fb","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:16:08.808405Z","iopub.execute_input":"2023-11-16T09:16:08.808780Z","iopub.status.idle":"2023-11-16T09:16:08.812876Z","shell.execute_reply.started":"2023-11-16T09:16:08.808746Z","shell.execute_reply":"2023-11-16T09:16:08.811893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"n5XhVLNz8Wfl","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device1 = 'cuda:1'","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:16:08.813953Z","iopub.execute_input":"2023-11-16T09:16:08.814228Z","iopub.status.idle":"2023-11-16T09:16:08.825143Z","shell.execute_reply.started":"2023-11-16T09:16:08.814204Z","shell.execute_reply":"2023-11-16T09:16:08.824264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im_tensor = torch.stack(im_tensor)\ntx_tensor = torch.stack(tx_tensor)\ngl = gold_label","metadata":{"id":"tlPAoKnewOWG","execution":{"iopub.status.busy":"2023-11-16T09:16:08.826459Z","iopub.execute_input":"2023-11-16T09:16:08.827212Z","iopub.status.idle":"2023-11-16T09:16:09.657758Z","shell.execute_reply.started":"2023-11-16T09:16:08.827178Z","shell.execute_reply":"2023-11-16T09:16:09.656267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nim_tensor_ = torch.stack(im_tensor_)\ntx_tensor_ = torch.stack(tx_tensor_)\ngl_ = gold_label_","metadata":{"id":"7p-u1oJl9RRM","execution":{"iopub.status.busy":"2023-11-16T09:16:09.658713Z","iopub.status.idle":"2023-11-16T09:16:09.659039Z","shell.execute_reply.started":"2023-11-16T09:16:09.658876Z","shell.execute_reply":"2023-11-16T09:16:09.658891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save to file\n\n# torch.save(im_tensor, 'im_tensor.pt')\n# torch.save(im_tensor_, 'im_tensor_.pt')\n# torch.save(tx_tensor, 'tx_tensor.pt')\n# torch.save(tx_tensor_, 'tx_tensor_.pt')\n\n# torch.save(gl, 'gl.pt')\n# torch.save(gl_, 'gl_.pt')\n\n# torch.save(img_id, 'img_id.pt')\n# torch.save(img_id_, 'img_id_.pt')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.664799Z","iopub.status.idle":"2023-09-13T07:27:25.665268Z","shell.execute_reply.started":"2023-09-13T07:27:25.665036Z","shell.execute_reply":"2023-09-13T07:27:25.665058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prefix = '/kaggle/input/tensors/'\nim_tensor = torch.load(prefix+'im_tensor.pt')\nim_tensor_ = torch.load(prefix+'im_tensor_.pt')\ntx_tensor = torch.load(prefix+'tx_tensor.pt')\ntx_tensor_ = torch.load(prefix+'tx_tensor_.pt')\n\ngl = torch.load(prefix+'gl.pt')\ngl_ = torch.load(prefix+'gl_.pt')\n\nimg_id = torch.load(prefix+'img_id.pt')\nimg_id_ = torch.load(prefix+'img_id_.pt')","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:20:57.286842Z","iopub.execute_input":"2023-11-16T09:20:57.287227Z","iopub.status.idle":"2023-11-16T09:20:57.316041Z","shell.execute_reply.started":"2023-11-16T09:20:57.287197Z","shell.execute_reply":"2023-11-16T09:20:57.315211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im_tensor[0:2,:]","metadata":{"id":"7arTB6u8iYm9","outputId":"54f6c553-1656-49e7-f19c-ead941985644","execution":{"iopub.status.busy":"2023-11-16T09:20:57.604502Z","iopub.execute_input":"2023-11-16T09:20:57.605365Z","iopub.status.idle":"2023-11-16T09:20:57.612863Z","shell.execute_reply.started":"2023-11-16T09:20:57.605333Z","shell.execute_reply":"2023-11-16T09:20:57.611948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im_tensor_[0:2,:]","metadata":{"id":"XbNlbYzsicsE","outputId":"88e2e83a-c46a-4b6f-bccc-63a7849e247e","execution":{"iopub.status.busy":"2023-11-16T09:16:15.203166Z","iopub.execute_input":"2023-11-16T09:16:15.203527Z","iopub.status.idle":"2023-11-16T09:16:15.211022Z","shell.execute_reply.started":"2023-11-16T09:16:15.203498Z","shell.execute_reply":"2023-11-16T09:16:15.209950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im_tensor.shape, tx_tensor.shape\n","metadata":{"id":"7N0FpKeBxN1-","outputId":"31cea9e8-9c84-4e36-e155-81fe2215e752","execution":{"iopub.status.busy":"2023-11-16T09:16:15.630231Z","iopub.execute_input":"2023-11-16T09:16:15.630632Z","iopub.status.idle":"2023-11-16T09:16:15.636949Z","shell.execute_reply.started":"2023-11-16T09:16:15.630569Z","shell.execute_reply":"2023-11-16T09:16:15.635989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(gl)","metadata":{"id":"EISz10Gx_NrU","outputId":"eb21f787-92fe-475b-be2f-3e5b24cc0bf0","execution":{"iopub.status.busy":"2023-11-16T09:16:15.983870Z","iopub.execute_input":"2023-11-16T09:16:15.984243Z","iopub.status.idle":"2023-11-16T09:16:15.990313Z","shell.execute_reply.started":"2023-11-16T09:16:15.984212Z","shell.execute_reply":"2023-11-16T09:16:15.989303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nclass TinyModel(torch.nn.Module):\n\n    def __init__(self, mdl, mdl_rand, rand=False):\n        super(TinyModel, self).__init__()\n        if rand:\n            self.linear1 = nn.Sequential(nn.Linear(1024, 256), nn.ReLU(), nn.Linear(256, 512))\n        else:\n            self.linear1 = mdl_rand\n        self.activation = torch.nn.ReLU()\n        self.linear2 = torch.nn.Linear(512, 128)\n        self.linear3 = torch.nn.Linear(128, 2)\n        self.rand = rand\n        self.softmax = torch.nn.Softmax()\n        self.proj = torch.nn.Linear(512,768)\n        # self.proj = torch.nn.Linear(512,5120)\n\n    def forward(self, x, y):\n        joint_tensor = torch.cat((x, y), dim=1)\n        if self.rand:\n            m_ = self.linear1(joint_tensor)\n        else:\n            x = x.unsqueeze(1)\n            y = y.unsqueeze(1)\n            m_ = self.linear1(x, y).squeeze(dim=1)\n        m = self.activation(m_)\n        m = self.linear3(self.linear2(m))\n        # m = self.softmax(m)\n        return m, self.proj(m_)\n\n","metadata":{"id":"tkEKyB8-1phE","execution":{"iopub.status.busy":"2023-11-16T09:16:16.672229Z","iopub.execute_input":"2023-11-16T09:16:16.672653Z","iopub.status.idle":"2023-11-16T09:16:16.682336Z","shell.execute_reply.started":"2023-11-16T09:16:16.672614Z","shell.execute_reply":"2023-11-16T09:16:16.681427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(im_tensor.shape, tx_tensor.shape, len(gl), len(img_id))","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:16:18.371277Z","iopub.execute_input":"2023-11-16T09:16:18.371676Z","iopub.status.idle":"2023-11-16T09:16:18.377077Z","shell.execute_reply.started":"2023-11-16T09:16:18.371643Z","shell.execute_reply":"2023-11-16T09:16:18.376088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass CustomDataset(Dataset):\n    def __init__(self, tensor1, tensor2, gold_label, ids):\n        self.tensor1 = tensor1\n        self.tensor2 = tensor2\n        self.gl = gold_label\n        self.ids = ids\n\n    def __len__(self):\n        return len(self.tensor1)\n\n    def __getitem__(self, idx):\n        return self.tensor1[idx], self.tensor2[idx], self.gl[idx], self.ids[idx]\n\n# def collate_fn(batch):\n#     tensor1_batch, tensor2_batch = zip(*batch)\n#     return torch.stack(tensor1_batch), torch.stack(tensor2_batch)\n\n# Create your tensors\nN = 100  # Example number of samples\ntensor1 = im_tensor\ntensor2 = tx_tensor\n\n# Create a custom dataset\ncustom_dataset = CustomDataset(tensor1, tensor2, gl, img_id)\ntrain_size = int(0.8 * len(custom_dataset))\ntest_size = len(custom_dataset) - train_size\n# torch.manual_seed(42)\nset_seed(42)\ntrain_dataset, test_dataset = torch.utils.data.random_split(custom_dataset, [train_size, test_size], generator=torch.Generator().manual_seed(42))\n\n# Create a DataLoader with your collate_fn\nbatch_size = 4\nimport torch\ntorch.manual_seed(42)\n\n\ndef seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n\ng = torch.Generator()\ng.manual_seed(42)\n\nset_seed(42)\ndataloader = DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=2,\n    worker_init_fn=seed_worker,\n    generator=g,\n)\n\n\n\n# dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n\n# Iterate through the DataLoader\ncounter = 0\nfor batch_tensor1, batch_tensor2, b3, b4 in dataloader:\n    print(\"Tensor 1 batch shape:\", batch_tensor1.shape)\n    print(\"Tensor 2 batch shape:\", batch_tensor2.shape)\n    print(\"Tensor 3 batch shape:\", b3.shape)\n    print(\"Tensor 4 batch shape:\", b4)\n    print(\"-\" * 30)\n    counter+=1\n    if counter==10:\n        break\n","metadata":{"id":"RhH1fnrD1pjV","outputId":"25ada5eb-6156-4c20-b5c1-04cfce5a358d","execution":{"iopub.status.busy":"2023-11-16T09:21:00.551336Z","iopub.execute_input":"2023-11-16T09:21:00.551740Z","iopub.status.idle":"2023-11-16T09:21:00.719208Z","shell.execute_reply.started":"2023-11-16T09:21:00.551706Z","shell.execute_reply":"2023-11-16T09:21:00.717897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"id":"tX6_1QiHIJ6d","outputId":"133b11a8-62ef-4d8c-a989-66332c283681","execution":{"iopub.status.busy":"2023-11-16T09:21:03.727227Z","iopub.execute_input":"2023-11-16T09:21:03.727650Z","iopub.status.idle":"2023-11-16T09:21:14.783390Z","shell.execute_reply.started":"2023-11-16T09:21:03.727608Z","shell.execute_reply":"2023-11-16T09:21:14.782345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2LMHeadModel","metadata":{"id":"8PjmLKXtIOqW","execution":{"iopub.status.busy":"2023-11-16T09:16:35.284413Z","iopub.execute_input":"2023-11-16T09:16:35.284750Z","iopub.status.idle":"2023-11-16T09:16:36.073275Z","shell.execute_reply.started":"2023-11-16T09:16:35.284719Z","shell.execute_reply":"2023-11-16T09:16:36.072314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"B3MERP7XIQw_","outputId":"10a9ac06-8933-4e7c-9682-1b5066ab471d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install auto-gptq","metadata":{"id":"TJIeV_CLDqdf","outputId":"c25d4c8e-a8dd-4718-9d8e-0492bbac94ec","execution":{"iopub.status.busy":"2023-11-16T09:16:36.074437Z","iopub.execute_input":"2023-11-16T09:16:36.074738Z","iopub.status.idle":"2023-11-16T09:16:36.078853Z","shell.execute_reply.started":"2023-11-16T09:16:36.074711Z","shell.execute_reply":"2023-11-16T09:16:36.077790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1_name = 'gpt2'\ntokenizer1 = GPT2Tokenizer.from_pretrained(model1_name)\nmodel1 = GPT2LMHeadModel.from_pretrained(model1_name,output_hidden_states=True).to(device)\nmdl_rand = fusion(512,512,True,256,512,0.1).to(device)\ntinymodel = TinyModel(mdl,mdl_rand,rand=False).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:16:36.080952Z","iopub.execute_input":"2023-11-16T09:16:36.081210Z","iopub.status.idle":"2023-11-16T09:16:42.781818Z","shell.execute_reply.started":"2023-11-16T09:16:36.081186Z","shell.execute_reply":"2023-11-16T09:16:42.780526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:16:42.782523Z","iopub.status.idle":"2023-11-16T09:16:42.782996Z","shell.execute_reply.started":"2023-11-16T09:16:42.782804Z","shell.execute_reply":"2023-11-16T09:16:42.782825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from transformers import GPT2Tokenizer, GPT2LMHeadModel, AutoTokenizer\n# from auto_gptq import AutoGPTQForCausalLM, BaseQuantizeConfig\n# quantized_model_dir = \"TheBloke/stable-vicuna-13B-GPTQ\"\n\n# model_basename = \"stable-vicuna-13B-GPTQ-4bit.compat.no-act-order\"\n\n# use_triton = False\n\n# tokenizer1 = AutoTokenizer.from_pretrained(quantized_model_dir, use_fast=True, max_lengh=128)\n\n# quantize_config = BaseQuantizeConfig(\n# bits=4,\n# group_size=128,\n# desc_act=False\n# )\n\n# model1 = AutoGPTQForCausalLM.from_quantized(quantized_model_dir,\n# use_safetensors=True,\n# model_basename=model_basename,\n# device=device1,\n# use_triton=use_triton,\n# quantize_config=quantize_config)","metadata":{"id":"lY_d40RbDlSi","outputId":"d44583c1-2caa-4d17-dd65-584363ef2fee","execution":{"iopub.status.busy":"2023-09-13T07:27:25.720442Z","iopub.status.idle":"2023-09-13T07:27:25.720920Z","shell.execute_reply.started":"2023-09-13T07:27:25.720659Z","shell.execute_reply":"2023-09-13T07:27:25.720681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def get_tokens(prpmt,begin=False):\n#   if begin:\n#     prepended_inp = [tokenizer1.encode(i) for i in prpmt]\n#   else:\n#     prepended_inp = [tokenizer1.encode(i)[1:] for i in prpmt]\n#   fin = []\n#   for i in prepended_inp:\n#     inter = []\n#     for j in i:\n#       inter.append(E[j,:])\n#     fin.append(torch.stack(inter))\n#   return torch.stack(fin), torch.tensor(prepended_inp)\n","metadata":{"id":"Vu2qvvyF5a1D","execution":{"iopub.status.busy":"2023-09-13T07:27:25.721829Z","iopub.status.idle":"2023-09-13T07:27:25.722311Z","shell.execute_reply.started":"2023-09-13T07:27:25.722065Z","shell.execute_reply":"2023-09-13T07:27:25.722087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_tokens(prpmt,begin=False):\n    set_seed(42)\n    if begin:\n        prepended_inp = [tokenizer1.encode(i) for i in prpmt]\n    else:\n        prepended_inp = [tokenizer1.encode(i) for i in prpmt]\n    max_len = max([len(i) for i in prepended_inp])\n    #print(max_len)\n    attn_mask = []\n    bs = len(prpmt)\n    for i in range(bs):\n        tmp_len = max_len - len(prepended_inp[i])\n        tmp_mask = torch.tensor([1]* len(prepended_inp[i]) + [0]* tmp_len)\n        attn_mask.append(tmp_mask)\n        extra_tokens = tokenizer1.encode(tokenizer1.eos_token)*tmp_len\n        prepended_inp[i] = prepended_inp[i]+extra_tokens\n    \n    attn_mask = torch.stack(attn_mask)\n    #print(prepended_inp)\n    #print(attn_mask, attn_mask.shape)\n    fin = []\n    for i in prepended_inp:\n        inter = []\n        for j in i:\n            inter.append(E[j,:])\n        fin.append(torch.stack(inter))\n    \n    \n    \n    \n        \n   \n    return torch.stack(fin), torch.tensor(prepended_inp), attn_mask\n","metadata":{"id":"oWT4B11tZ2ON","execution":{"iopub.status.busy":"2023-11-16T09:21:14.785633Z","iopub.execute_input":"2023-11-16T09:21:14.785947Z","iopub.status.idle":"2023-11-16T09:21:14.795367Z","shell.execute_reply.started":"2023-11-16T09:21:14.785916Z","shell.execute_reply":"2023-11-16T09:21:14.794535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer1.encode(tokenizer1.bos_token)*7","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:21:14.796844Z","iopub.execute_input":"2023-11-16T09:21:14.797449Z","iopub.status.idle":"2023-11-16T09:21:14.816381Z","shell.execute_reply.started":"2023-11-16T09:21:14.797414Z","shell.execute_reply":"2023-11-16T09:21:14.815437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import *","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:21:14.818303Z","iopub.execute_input":"2023-11-16T09:21:14.818572Z","iopub.status.idle":"2023-11-16T09:21:14.829047Z","shell.execute_reply.started":"2023-11-16T09:21:14.818549Z","shell.execute_reply":"2023-11-16T09:21:14.828120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_performance_test():\n    torch.use_deterministic_algorithms(mode=True)\n    set_seed(42)\n    tinymodel.eval()\n    model1.eval()\n    #set_seed(42)\n    all_labs = []\n    all_labs_clf = []\n    counter = 0\n    for ii,ti, gol, ids in test_dataset:\n\n        #     print(0/0)\n        ti = ti.unsqueeze(0)\n        ii = ii.unsqueeze(0)\n        gol = [gol]\n        ids = [ids]\n        # print(batch_model1, batch_model1)\n\n        ids = list(map(lambda x: x.split('/')[1], ids))\n        #         ids_ = []\n        #         for i in range(len(ids)):\n        #             kbs = ids[i].split('[KB]')\n        #             caps = ids[i].split('[CAPTION]')[-1]\n        #             try:\n        #                 kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n        #             except IndexError as e:\n        #                 kb = '[CAPTION] '+ caps\n        #             ids_.append(kb)\n        #         ids = ids_\n        \n        ids_ = []\n        for i in range(len(ids)):\n            kbs = ids[i].split('[KB]')\n            #print('kbs ', kbs)\n            caps = ids[i].split('[CAPTION]')[-1]\n            #print(caps)\n            kb = ''\n            if len(kbs)>3:\n                kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n            elif len(kbs)==3:\n                #print('in len3')\n                kb = '[KB] '+kbs[1]\n                caps = kbs[2].split('[CAPTION]')\n                kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n            elif len(kbs)==2:\n                #print('in len 1')\n                caps = kbs[1].split('[CAPTION]')\n                kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n            elif len(kbs)==1:\n                kb = kbs[0].strip()\n                #print('int ', kb)\n\n\n\n            ids_.append(kb)\n        \n        ids = ids_\n        \n        \n        \n        #         print(ids)\n        texts = [id2text[i] for i in ids]\n        ids = [kb_fb[i] for i in ids]\n\n        #     prpmt = []\n        #     for i,j in zip(ids,texts):\n        #         prpmt.append(i+'. The meme text reads :'+j + '. Classifier thinks the meme is')\n\n\n\n        i = ii.float().to(device)\n        t = ti.float().to(device)\n        batch_size = i.shape[0]\n        with torch.no_grad():\n            logits, m = tinymodel(i,t)\n        # print(m)\n        m = m.unsqueeze(dim=1)\n        all_labs_clf.append(logits.argmax(dim=-1)[0].item())\n        #         prmpt0, lab0 = get_tokens([tokenizer1.bos_token]*batch_size, begin=True)\n\n        #         print(prmpt0.shape)\n\n        gumbel_logits = F.gumbel_softmax(logits, tau=1, hard=True)\n        # print(gumbel_logits)\n        agmx = gumbel_logits.argmax(dim=1)\n\n        # print(agmx, logits.argmax(dim=1))\n        #         prpmt = ['model thinks the meme is ']*batch_size\n\n        #portion1,lab1, a1 = get_tokens(prpmt)\n\n        portion2,lab3, _ = get_tokens(['output of the classifier multimodal embedding is ']*batch_size)\n        lab4 = [tokenizer1.encode('-')[:] for i in range(batch_size)]\n        lab4 = torch.tensor(lab4)\n\n        # portion3 = get_tokens(['the meme is actually'])\n\n\n\n\n\n\n        kk = []\n        labs_verbalized = []\n        # batch_prompt = ['the model thinks the meme is ']*32\n        lab2 = []\n        for i in gumbel_logits:\n            agmx = i.argmax()\n            # print(agmx)\n            # print(dix[agmx.item()])\n            tokenized_ = tokenizer1.encode(dix[agmx.item()])[:]\n            labs_verbalized.append(dix[agmx.item()])\n            # print(tokenized_)\n            lab2.append(tokenized_)\n            embedding = E[tokenized_[0]]\n            one_hot = i.view(-1, 1)\n            # print(embedding.shape, one_hot, one_hot.shape)\n\n            e = torch.sum(one_hot*embedding.to(device), dim=0)\n            kk.append(e)\n        lab2 = torch.tensor(lab2)\n        prpmt = []\n        for i,j,z in zip(ids,texts,labs_verbalized):\n            prpmt.append(i+'. The meme text reads :'+j + '. Classifier thinks the meme is {}'.format(z))\n            #all_labs_clf.append(z)\n        portion1,lab1, a1 = get_tokens(prpmt)\n        string = ['the meme is actually']\n        portion3,lab5,_ = get_tokens(string)\n        inp_embed = torch.stack(kk).unsqueeze(dim=1)\n        # print(inp_embed)\n        # print(inp_embed.shape)\n        # print(portion1.shape,inp_embed.shape,portion2.shape,m.shape,portion3.shape)\n\n        final_embeds = torch.cat((portion1,inp_embed,portion2,m,portion3),dim=1)\n        # print(final_embeds.shape)\n        # print(lab1.shape, lab2.shape, lab3.shape, lab4.shape, lab5.shape)\n        labs_shape = torch.cat((lab2,lab3,lab4,lab5),dim=1).shape\n        remaining_mask = torch.ones(labs_shape[0], labs_shape[1]).long()\n        #print(a1)\n        #print(remaining_mask)\n\n        full_mask = torch.cat((a1,remaining_mask),dim=1)\n        #print('fm ', full_mask.shape)\n        labs = torch.cat((lab1,lab2,lab3,lab4,lab5),dim=1)\n        #print(full_mask)\n        #print(0/0)\n        #         print(final_embeds.shape, labs.shape)\n        #         print(0/0)\n        with torch.no_grad():\n            output2 = model1(inputs_embeds = final_embeds.float(), labels = labs.long(), attention_mask=full_mask.to('cuda'))\n        # print(output2.loss)\n        # print(0/0)\n        loss_lm = output2.loss\n        #print(tokenizer1.batch_decode(output2.logits.argmax(dim=-1)))\n\n        #print(loss_lm)\n        llm_lab = tokenizer1.decode(output2.logits.argmax(dim=-1)[0][-1])\n        all_labs.append(llm_lab)\n        counter+=1\n        #if counter==10:\n        #    break\n        \n    return all_labs, all_labs_clf\n\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:23:38.773418Z","iopub.execute_input":"2023-11-16T09:23:38.773846Z","iopub.status.idle":"2023-11-16T09:23:38.798194Z","shell.execute_reply.started":"2023-11-16T09:23:38.773810Z","shell.execute_reply":"2023-11-16T09:23:38.797269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_performance_test_nm():\n    torch.use_deterministic_algorithms(mode=True)\n    set_seed(42)\n    tinymodel.eval()\n    model1.eval()\n    #set_seed(42)\n    all_labs = []\n    all_labs_clf = []\n    counter = 0\n    for ii,ti, gol, ids in test_dataset:\n\n        #     print(0/0)\n        ti = ti.unsqueeze(0)\n        ii = ii.unsqueeze(0)\n        gol = [gol]\n        ids = [ids]\n        # print(batch_model1, batch_model1)\n\n        ids = list(map(lambda x: x.split('/')[1], ids))\n        #         print(ids)\n        texts = [id2text[i] for i in ids]\n        ids = [kb_fb[i] for i in ids]\n        #         ids_ = []\n        #         for i in range(len(ids)):\n        #             kbs = ids[i].split('[KB]')\n        #             caps = ids[i].split('[CAPTION]')[-1]\n        #             try:\n        #                 kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n        #             except IndexError as e:\n        #                 kb = '[CAPTION] '+ caps\n        #             ids_.append(kb)\n        #         ids = ids_\n        \n        \n        ids_ = []\n        for i in range(len(ids)):\n            kbs = ids[i].split('[KB]')\n            #print('kbs ', kbs)\n            caps = ids[i].split('[CAPTION]')[-1]\n            #print(caps)\n            kb = ''\n            if len(kbs)>3:\n                kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n            elif len(kbs)==3:\n                #print('in len3')\n                kb = '[KB] '+kbs[1]\n                caps = kbs[2].split('[CAPTION]')\n                kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n            elif len(kbs)==2:\n                #print('in len 1')\n                caps = kbs[1].split('[CAPTION]')\n                kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n            elif len(kbs)==1:\n                kb = kbs[0].strip()\n                #print('int ', kb)\n\n\n\n            ids_.append(kb)\n        \n        ids = ids_\n\n        #     prpmt = []\n        #     for i,j in zip(ids,texts):\n        #         prpmt.append(i+'. The meme text reads :'+j + '. Classifier thinks the meme is')\n\n\n\n        i = ii.float().to(device)\n        t = ti.float().to(device)\n        batch_size = i.shape[0]\n        with torch.no_grad():\n            logits, m = tinymodel(i,t)\n        # print(m)\n        m = m.unsqueeze(dim=1)\n        #         prmpt0, lab0 = get_tokens([tokenizer1.bos_token]*batch_size, begin=True)\n\n        #         print(prmpt0.shape)\n\n        gumbel_logits = F.gumbel_softmax(logits, tau=1, hard=True)\n        # print(gumbel_logits)\n        agmx = gumbel_logits.argmax(dim=1)\n\n        # print(agmx, logits.argmax(dim=1))\n        #         prpmt = ['model thinks the meme is ']*batch_size\n\n        #portion1,lab1, a1 = get_tokens(prpmt)\n\n\n        # portion3 = get_tokens(['the meme is actually'])\n\n\n\n\n\n\n        kk = []\n        labs_verbalized = []\n        # batch_prompt = ['the model thinks the meme is ']*32\n        lab2 = []\n        for i in gumbel_logits:\n            agmx = i.argmax()\n            # print(agmx)\n            # print(dix[agmx.item()])\n            tokenized_ = tokenizer1.encode(dix[agmx.item()])[:]\n            labs_verbalized.append(dix[agmx.item()])\n            # print(tokenized_)\n            lab2.append(tokenized_)\n            embedding = E[tokenized_[0]]\n            one_hot = i.view(-1, 1)\n            # print(embedding.shape, one_hot, one_hot.shape)\n\n            e = torch.sum(one_hot*embedding.to(device), dim=0)\n            kk.append(e)\n        lab2 = torch.tensor(lab2)\n        prpmt = []\n        for i,j,z in zip(ids,texts,labs_verbalized):\n            prpmt.append(i+'. The meme text reads :'+j)\n            all_labs_clf.append(z)\n        portion1,lab1, a1 = get_tokens(prpmt)\n        string = ['the meme is actually']\n        portion3,lab5,_ = get_tokens(string)\n        inp_embed = torch.stack(kk).unsqueeze(dim=1)\n        # print(inp_embed)\n        # print(inp_embed.shape)\n        # print(portion1.shape,inp_embed.shape,portion2.shape,m.shape,portion3.shape)\n\n        final_embeds = torch.cat((portion1,portion3),dim=1)\n        # print(final_embeds.shape)\n        # print(lab1.shape, lab2.shape, lab3.shape, lab4.shape, lab5.shape)\n        labs_shape = lab5.shape\n        remaining_mask = torch.ones(labs_shape[0], labs_shape[1]).long()\n        #print(a1)\n        #print(remaining_mask)\n\n        full_mask = torch.cat((a1,remaining_mask),dim=1)\n        #print('fm ', full_mask.shape)\n        labs = torch.cat((lab1,lab5),dim=1)\n        #print(full_mask)\n        #print(0/0)\n        #         print(final_embeds.shape, labs.shape)\n        #         print(0/0)\n        with torch.no_grad():\n            output2 = model1(inputs_embeds = final_embeds.float(), labels = labs.long(), attention_mask=full_mask.to('cuda'))\n        # print(output2.loss)\n        # print(0/0)\n        loss_lm = output2.loss\n        #print(tokenizer1.batch_decode(output2.logits.argmax(dim=-1)))\n\n        #print(loss_lm)\n        llm_lab = tokenizer1.decode(output2.logits.argmax(dim=-1)[0][-1])\n        all_labs.append(llm_lab)\n        counter+=1\n        \n    return all_labs, all_labs_clf\n\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:23:39.563695Z","iopub.execute_input":"2023-11-16T09:23:39.564036Z","iopub.status.idle":"2023-11-16T09:23:39.585713Z","shell.execute_reply.started":"2023-11-16T09:23:39.564010Z","shell.execute_reply":"2023-11-16T09:23:39.584897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gl_test  = []\nfor _,_,g,_ in test_dataset:\n    gl_test.append(g)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:23:40.366988Z","iopub.execute_input":"2023-11-16T09:23:40.367781Z","iopub.status.idle":"2023-11-16T09:23:40.384494Z","shell.execute_reply.started":"2023-11-16T09:23:40.367745Z","shell.execute_reply":"2023-11-16T09:23:40.383385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# # kbs = ids[0].split('[KB]')\n# # print(kbs)\n# # caps = ids[0].split('[CAPTION]')[-1]\n# # print(caps)\n# # if len(kbs)>3:\n# #     kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n# # elif len(kbs)==3:\n# #     kb = '[KB] '+kbs[1]\n# #     caps = kb[2].split('[CAPTION]')[-1]\n# #     kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps\n# # elif len(kbs)==2:\n# #     caps = kb[1].split('[CAPTION]')[-1]\n# #     kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps\n# # elif len(kbs)==1:\n# #     print('int ', kb)\n    \n    \n# # print(kb)\n\n\n# for ii,ti, gol, ids in tqdm(dataloader):\n#     ids = list(map(lambda x: x.split('/')[1], ids))\n#     ids = [kb_fb[i] for i in ids]\n#     #print(ids)\n#     ids_ = []\n#     for i in range(len(ids)):\n#         kbs = ids[i].split('[KB]')\n#         #print('kbs ', kbs)\n#         caps = ids[i].split('[CAPTION]')[-1]\n#         #print(caps)\n#         kb = ''\n#         if len(kbs)>3:\n#             kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n#         elif len(kbs)==3:\n#             #print('in len3')\n#             kb = '[KB] '+kbs[1]\n#             caps = kbs[2].split('[CAPTION]')\n#             kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n#         elif len(kbs)==2:\n#             #print('in len 1')\n#             caps = kbs[1].split('[CAPTION]')\n#             kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n#         elif len(kbs)==1:\n#             kb = kbs[0].strip()\n#             #print('int ', kb)\n\n\n            \n#         ids_.append(kb)\n        \n#     break\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:18:07.752564Z","iopub.execute_input":"2023-11-16T09:18:07.753480Z","iopub.status.idle":"2023-11-16T09:18:07.758886Z","shell.execute_reply.started":"2023-11-16T09:18:07.753446Z","shell.execute_reply":"2023-11-16T09:18:07.757961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import *","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:23:43.707545Z","iopub.execute_input":"2023-11-16T09:23:43.707943Z","iopub.status.idle":"2023-11-16T09:23:43.712545Z","shell.execute_reply.started":"2023-11-16T09:23:43.707910Z","shell.execute_reply":"2023-11-16T09:23:43.711603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n#os.environ['CUBLAS_WORKSPACE_CONFIG']=:4096:8\ntorch.use_deterministic_algorithms(True)\nset_seed(42)\nimport numpy as np\nmodel1_name = 'gpt2'\ntokenizer1 = GPT2Tokenizer.from_pretrained(model1_name)\nmodel1 = GPT2LMHeadModel.from_pretrained(model1_name,output_hidden_states=True).to(device)\nmdl = fusion(512,512,True,256,512,0.1).to(device)\nmdl_rand = fusion(512,512,True,256,512,0.1).to(device)\ntinymodel = TinyModel(mdl,mdl_rand,rand=False).to(device)\nE = model1.transformer.wte.weight.detach()\n# E = model1.model.model.embed_tokens.weight.detach()\noptimizer = optim.Adam(tinymodel.parameters(), lr=0.0005)\noptimizer1 = optim.Adam(model1.parameters(), lr=0.0005)\ndix = {0:'normal', 1:'offensive'}\n\ntinymodel.train()\nmodel1.train()\n# Training loop\nnum_epochs = 2\ndef transpose(x):\n    return x.transpose(-2, -1)\n\nfor epoch in tqdm(range(num_epochs)):\n    #     set_seed(42)\n    l=0\n    cnt = 0\n    l_lm = 0\n    l_clf = 0\n    tinymodel.train()\n    model1.train()\n    for ii,ti, gol, ids in dataloader:\n        # print(batch_model1, batch_model1)\n       \n        ids = list(map(lambda x: x.split('/')[1], ids))\n        #         print(ids)\n        texts = [id2text[i] for i in ids]\n        ids = [kb_fb[i] for i in ids]\n        \n        #         ids_ = []\n        #         for i in range(len(ids)):\n        #             kbs = ids[i].split('[KB]')\n        #             caps = ids[i].split('[CAPTION]')[-1]\n        #             try:\n        #                 kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n        #             except IndexError as e:\n        #                 kb = '[CAPTION] '+ caps\n        #             ids_.append(kb)\n        #         ids = ids_\n\n        ids_ = []\n        for i in range(len(ids)):\n            kbs = ids[i].split('[KB]')\n            #print('kbs ', kbs)\n            caps = ids[i].split('[CAPTION]')[-1]\n            #print(caps)\n            kb = ''\n            if len(kbs)>3:\n                kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n            elif len(kbs)==3:\n                #print('in len3')\n                kb = '[KB] '+kbs[1]\n                caps = kbs[2].split('[CAPTION]')\n                kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n            elif len(kbs)==2:\n                #print('in len 1')\n                caps = kbs[1].split('[CAPTION]')\n                kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n            elif len(kbs)==1:\n                kb = kbs[0].strip()\n                #print('int ', kb)\n\n\n\n            ids_.append(kb)\n        \n        ids = ids_\n        \n        \n        \n       \n        \n        i = ii.float().to(device)\n        t = ti.float().to(device)\n        batch_size = i.shape[0]\n        optimizer.zero_grad()\n        optimizer1.zero_grad()\n        logits, m = tinymodel(i,t)\n        # print(m)\n        m = m.unsqueeze(dim=1)\n        #         prmpt0, lab0 = get_tokens([tokenizer1.bos_token]*batch_size, begin=True)\n       \n        #         print(prmpt0.shape)\n\n        gumbel_logits = F.gumbel_softmax(logits, tau=1, hard=True)\n        # print(gumbel_logits)\n        agmx = gumbel_logits.argmax(dim=1)\n\n        # print(agmx, logits.argmax(dim=1))\n        #         prpmt = ['model thinks the meme is ']*batch_size\n\n        \n      \n        portion2,lab3, _ = get_tokens(['output of the classifier multimodal embedding is ']*batch_size)\n        lab4 = [tokenizer1.encode('-')[:] for i in range(batch_size)]\n        lab4 = torch.tensor(lab4)\n\n        # portion3 = get_tokens(['the meme is actually'])\n\n\n\n\n\n\n        kk = []\n        labs_verbalized = []\n        # batch_prompt = ['the model thinks the meme is ']*32\n        lab2 = []\n        for i in gumbel_logits:\n            agmx = i.argmax()\n            # print(agmx)\n            # print(dix[agmx.item()])\n            tokenized_ = tokenizer1.encode(dix[agmx.item()])[:]\n            labs_verbalized.append(dix[agmx.item()])\n            # print(tokenized_)\n            lab2.append(tokenized_)\n            embedding = E[tokenized_[0]]\n            one_hot = i.view(-1, 1)\n            # print(embedding.shape, one_hot, one_hot.shape)\n\n            e = torch.sum(one_hot*embedding.to(device), dim=0)\n            kk.append(e)\n        lab2 = torch.tensor(lab2)\n        #string = ['the meme is actually {}'.format(i) for i in labs_verbalized] # why this fucking mistake??????\n        \n        prpmt = []\n        for i,j,z in zip(ids,texts,labs_verbalized):\n            prpmt.append(i+'. The meme text reads :'+j + '. Classifier thinks the meme is {}'.format(z))\n        portion1,lab1, a1 = get_tokens(prpmt)\n        \n        string = ['the meme is actually {}'.format(dix[int(i)]) for i in gol]\n        portion3,lab5,_ = get_tokens(string)\n        inp_embed = torch.stack(kk).unsqueeze(dim=1)\n        # print(inp_embed)\n        # print(inp_embed.shape)\n        # print(portion1.shape,inp_embed.shape,portion2.shape,m.shape,portion3.shape)\n       \n        final_embeds = torch.cat((portion1,inp_embed,portion2,m,portion3),dim=1)\n        # print(final_embeds.shape)\n        # print(lab1.shape, lab2.shape, lab3.shape, lab4.shape, lab5.shape)\n        labs_shape = torch.cat((lab2,lab3,lab4,lab5),dim=1).shape\n        remaining_mask = torch.ones(labs_shape[0], labs_shape[1]).long()\n        #print(a1)\n        #print(remaining_mask)\n        \n        full_mask = torch.cat((a1,remaining_mask),dim=1)\n        #print('fm ', full_mask.shape)\n        labs = torch.cat((lab1,lab2,lab3,lab4,lab5),dim=1)\n        #print(full_mask)\n        #print(0/0)\n        #         print(final_embeds.shape, labs.shape)\n        #         print(0/0)\n        output2 = model1(inputs_embeds = final_embeds.float(), labels = labs.long(), attention_mask=full_mask.to('cuda'))\n        # print(output2.loss)\n        # print(0/0)\n        loss_lm = output2.loss\n\n\n\n\n        loss_clf = torch.nn.functional.cross_entropy(logits, gol.to(device), reduction='mean')\n\n        #print(loss_lm, loss_clf)\n       \n        loss = loss_lm+loss_clf\n\n        loss.backward()\n        optimizer.step()\n        optimizer1.step()\n\n\n        l+=loss.detach().item()\n        l_clf+=loss_clf.detach().item()\n        l_lm+=loss_lm.detach().item()\n        cnt+=1\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {l/cnt}, Loss clf: {l_clf/cnt}, Loss llm: {l_lm/cnt}\")\n    tinymodel.eval()\n    pred,_ = tinymodel(im_tensor_.float().to(device),tx_tensor_.float().to(device))\n    pred = pred.argmax(dim=1).detach().cpu().numpy()\n    print(f1_score(gl_, pred, average='macro'), accuracy_score(gl_, pred))\n    al, alc = get_performance_test()\n    l2l = {'normal':0, 'offensive':1}\n    al_ = list(map(lambda x: l2l[x.strip()], al))\n    #alc_ = list(map(lambda x: l2l[x.strip()], alc))\n    print(f1_score(gl_test, al_, average='macro'), f1_score(gl_test, alc, average='macro'))\n    print(accuracy_score(gl_test, al_), accuracy_score(gl_test, alc))\n    \n    \nprint(\"Training complete!\")\n","metadata":{"id":"gqvImxQBZhwG","outputId":"ca4e53cb-b664-49ea-e3d1-accbd1da34fe","execution":{"iopub.status.busy":"2023-11-16T09:23:44.229126Z","iopub.execute_input":"2023-11-16T09:23:44.229537Z","iopub.status.idle":"2023-11-16T09:23:48.696989Z","shell.execute_reply.started":"2023-11-16T09:23:44.229503Z","shell.execute_reply":"2023-11-16T09:23:48.695478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#torch.save(model1.state_dict(), 'gpt2_backbone.pt')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.757671Z","iopub.status.idle":"2023-09-13T07:27:25.758141Z","shell.execute_reply.started":"2023-09-13T07:27:25.757889Z","shell.execute_reply":"2023-09-13T07:27:25.757910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#torch.save(tinymodel.state_dict(), 'classifier.pt')","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:18:13.709144Z","iopub.execute_input":"2023-11-16T09:18:13.709510Z","iopub.status.idle":"2023-11-16T09:18:13.714276Z","shell.execute_reply.started":"2023-11-16T09:18:13.709483Z","shell.execute_reply":"2023-11-16T09:18:13.712993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ndevice = 'cuda'\n#os.environ['CUBLAS_WORKSPACE_CONFIG']=:4096:8\ntorch.use_deterministic_algorithms(True)\nset_seed(42)\nimport numpy as np\nmodel1_name = 'gpt2'\ntokenizer1 = GPT2Tokenizer.from_pretrained(model1_name)\nmodel1 = GPT2LMHeadModel.from_pretrained(model1_name,output_hidden_states=True).to(device)\nmdl = fusion(512,512,True,256,512,0.1).to(device)\nmdl_rand = fusion(512,512,True,256,512,0.1).to(device)\ntinymodel = TinyModel(mdl,mdl_rand,rand=False).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:23:50.905169Z","iopub.execute_input":"2023-11-16T09:23:50.905618Z","iopub.status.idle":"2023-11-16T09:23:55.596907Z","shell.execute_reply.started":"2023-11-16T09:23:50.905567Z","shell.execute_reply":"2023-11-16T09:23:55.595981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"E = model1.transformer.wte.weight.detach()\nmodel1.eval()\ntinymodel.eval()\ndix = {0:'normal', 1:'offensive'}\nal, alc = get_performance_test()\nl2l = {'normal':0, 'offensive':1}\n\nal_ = list(map(lambda x: l2l[x.strip()], al))\nprint(f1_score(gl_test, al_, average='macro'), f1_score(gl_test, alc, average='macro'))\nprint(accuracy_score(gl_test, al_), accuracy_score(gl_test, alc))","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:23:55.598544Z","iopub.execute_input":"2023-11-16T09:23:55.598879Z","iopub.status.idle":"2023-11-16T09:23:55.804889Z","shell.execute_reply.started":"2023-11-16T09:23:55.598851Z","shell.execute_reply":"2023-11-16T09:23:55.803581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l2l = {'normal':0, 'a':1}\n\nal_ = list(map(lambda x: l2l[x.strip()], al))\nprint(f1_score(gl_test, al_, average='macro'), f1_score(gl_test, alc, average='macro'))\nprint(accuracy_score(gl_test, al_), accuracy_score(gl_test, alc))","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:20:05.360827Z","iopub.execute_input":"2023-11-16T09:20:05.361225Z","iopub.status.idle":"2023-11-16T09:20:05.385226Z","shell.execute_reply.started":"2023-11-16T09:20:05.361191Z","shell.execute_reply":"2023-11-16T09:20:05.384241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install captum","metadata":{"execution":{"iopub.status.busy":"2023-09-14T09:57:34.820484Z","iopub.execute_input":"2023-09-14T09:57:34.820913Z","iopub.status.idle":"2023-09-14T09:57:48.544802Z","shell.execute_reply.started":"2023-09-14T09:57:34.820861Z","shell.execute_reply":"2023-09-14T09:57:48.543571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PAD_IND = tokenizer1.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2023-09-14T10:14:58.715624Z","iopub.execute_input":"2023-09-14T10:14:58.716228Z","iopub.status.idle":"2023-09-14T10:14:58.721395Z","shell.execute_reply.started":"2023-09-14T10:14:58.716170Z","shell.execute_reply":"2023-09-14T10:14:58.720454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PAD_IND","metadata":{"execution":{"iopub.status.busy":"2023-09-14T10:14:59.970835Z","iopub.execute_input":"2023-09-14T10:14:59.971807Z","iopub.status.idle":"2023-09-14T10:14:59.978630Z","shell.execute_reply.started":"2023-09-14T10:14:59.971774Z","shell.execute_reply":"2023-09-14T10:14:59.977393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.transformer.wte","metadata":{"execution":{"iopub.status.busy":"2023-09-14T10:21:59.279759Z","iopub.execute_input":"2023-09-14T10:21:59.280545Z","iopub.status.idle":"2023-09-14T10:21:59.290260Z","shell.execute_reply.started":"2023-09-14T10:21:59.280506Z","shell.execute_reply":"2023-09-14T10:21:59.289164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom captum.attr import IntegratedGradients, TokenReferenceBase, LayerIntegratedGradients\n\n# Define the input text you want to analyze\ninput_text = \"Your input text here\"\ntoken_reference = TokenReferenceBase(reference_token_idx=PAD_IND)\n# Tokenize the input text and convert it to a tensor\ninput_ids = tokenizer1.encode(input_text, return_tensors=\"pt\").to(torch.int64).to('cuda')\nprint(input_ids)\n# Generate the output predictions\n\ndef squad_pos_forward_func(inputs):\n    pred = model1(inputs)\n    \n    pred = pred.logits[:,-1,:].max(1)\n    print(pred.values)\n    return pred.values\n\nsquad_pos_forward_func(input_ids)\n\n# with torch.no_grad():\n#     output = model1(input_ids)\n\n# Define a target position for attribution (e.g., the last token)\ntarget_position = -1  # Adjust this based on your use case\n\n# Initialize Integrated Gradients\n#ig = IntegratedGradients(model1)\n#ig = IntegratedGradients(model1.transformer.wte)\n#ig = LayerIntegratedGradients(model1, model1.transformer.wte)\nig = LayerIntegratedGradients(squad_pos_forward_func, model1.transformer.wte)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T12:58:20.893649Z","iopub.execute_input":"2023-09-14T12:58:20.894975Z","iopub.status.idle":"2023-09-14T12:58:20.929178Z","shell.execute_reply.started":"2023-09-14T12:58:20.894922Z","shell.execute_reply":"2023-09-14T12:58:20.928057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seq_length = 4\n# Compute feature attribution scores\nreference_indices = token_reference.generate_reference(seq_length, device=device).unsqueeze(0)\nattributions, delta = ig.attribute(inputs = input_ids.to(torch.int64), baselines = reference_indices.to(torch.int64), return_convergence_delta=True)\n\n# Convert attributions tensor to a numpy array\nattributions = attributions.sum(dim=-1).squeeze(0).cpu().numpy()\n\n# Normalize the attributions\nattributions = (attributions - attributions.min()) / (attributions.max() - attributions.min())\n\n# Map the attributions back to tokens\ntokens = tokenizer1.convert_ids_to_tokens(input_ids[0].tolist())\n\n# Display the feature attributions for each token\nfor token, attribution in zip(tokens, attributions):\n    print(f\"{token}: {attribution:.3f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T12:58:54.387678Z","iopub.execute_input":"2023-09-14T12:58:54.388410Z","iopub.status.idle":"2023-09-14T12:58:54.513809Z","shell.execute_reply.started":"2023-09-14T12:58:54.388365Z","shell.execute_reply":"2023-09-14T12:58:54.512679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fwd_model(inputs, labels, attention_mask):\n    #print(tokenizer1.batch_decode(labels))\n    #pred = model1(inputs_embeds = inputs, labels = labels, attention_mask=attention_mask)\n    pred = model1(input_ids = labels, labels = labels, attention_mask=attention_mask)\n    pred = pred.logits[:,-1,:].max(1)\n    #print(pred.values)\n    return pred.values","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:43:01.478992Z","iopub.execute_input":"2023-09-14T13:43:01.479386Z","iopub.status.idle":"2023-09-14T13:43:01.487247Z","shell.execute_reply.started":"2023-09-14T13:43:01.479353Z","shell.execute_reply":"2023-09-14T13:43:01.485982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:42:56.010121Z","iopub.execute_input":"2023-09-14T13:42:56.010567Z","iopub.status.idle":"2023-09-14T13:42:57.006861Z","shell.execute_reply.started":"2023-09-14T13:42:56.010534Z","shell.execute_reply":"2023-09-14T13:42:57.005783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_performance_test():\n    torch.use_deterministic_algorithms(mode=True)\n    set_seed(42)\n    tinymodel.eval()\n    model1.eval()\n    #set_seed(42)\n    all_labs = []\n    all_labs_clf = []\n    counter = 0\n    for ii,ti, gol, ids in test_dataset:\n\n        #     print(0/0)\n        ti = ti.unsqueeze(0)\n        ii = ii.unsqueeze(0)\n        gol = [gol]\n        ids = [ids]\n        # print(batch_model1, batch_model1)\n\n        ids = list(map(lambda x: x.split('/')[1], ids))\n        #         ids_ = []\n        #         for i in range(len(ids)):\n        #             kbs = ids[i].split('[KB]')\n        #             caps = ids[i].split('[CAPTION]')[-1]\n        #             try:\n        #                 kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n        #             except IndexError as e:\n        #                 kb = '[CAPTION] '+ caps\n        #             ids_.append(kb)\n        #         ids = ids_\n        \n        ids_ = []\n        texts = [id2text[i] for i in ids]\n        ids = [kb_fb[i] for i in ids]\n        for i in range(len(ids)):\n            kbs = ids[i].split('[KB]')\n            print('kbs ', kbs)\n            caps = ids[i].split('[CAPTION]')[-1]\n            #print(caps)\n            kb = ''\n            if len(kbs)>3:\n                print('in len >3')\n                kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n            elif len(kbs)==3:\n                print('in len3')\n                kb = '[KB] '+kbs[1]\n                caps = kbs[2].split('[CAPTION]')\n                kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n            elif len(kbs)==2:\n                print('in len 1')\n                caps = kbs[1].split('[CAPTION]')\n                kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n            elif len(kbs)==1:\n                print('in len1')\n                kb = kbs[0].strip()\n                #print('int ', kb)\n\n\n\n            ids_.append(kb)\n        \n        ids = ids_\n        \n        \n        \n        print('ids',ids)\n        \n        \n        \n        #     prpmt = []\n        #     for i,j in zip(ids,texts):\n        #         prpmt.append(i+'. The meme text reads :'+j + '. Classifier thinks the meme is')\n\n\n\n        i = ii.float().to(device)\n        t = ti.float().to(device)\n        batch_size = i.shape[0]\n        #with torch.no_grad():\n        logits, m = tinymodel(i,t)\n        # print(m)\n        m = m.unsqueeze(dim=1)\n        all_labs_clf.append(logits.argmax(dim=-1)[0].item())\n        #         prmpt0, lab0 = get_tokens([tokenizer1.bos_token]*batch_size, begin=True)\n\n        #         print(prmpt0.shape)\n\n        gumbel_logits = F.gumbel_softmax(logits, tau=1, hard=True)\n        # print(gumbel_logits)\n        agmx = gumbel_logits.argmax(dim=1)\n\n        # print(agmx, logits.argmax(dim=1))\n        #         prpmt = ['model thinks the meme is ']*batch_size\n\n        #portion1,lab1, a1 = get_tokens(prpmt)\n\n        portion2,lab3, _ = get_tokens(['output of the classifier multimodal embedding is ']*batch_size)\n        lab4 = [tokenizer1.encode('-')[:] for i in range(batch_size)]\n        lab4 = torch.tensor(lab4)\n\n        # portion3 = get_tokens(['the meme is actually'])\n\n\n\n\n\n\n        kk = []\n        labs_verbalized = []\n        # batch_prompt = ['the model thinks the meme is ']*32\n        lab2 = []\n        for i in gumbel_logits:\n            agmx = i.argmax()\n            # print(agmx)\n            # print(dix[agmx.item()])\n            tokenized_ = tokenizer1.encode(dix[agmx.item()])[:]\n            labs_verbalized.append(dix[agmx.item()])\n            # print(tokenized_)\n            lab2.append(tokenized_)\n            embedding = E[tokenized_[0]]\n            one_hot = i.view(-1, 1)\n            # print(embedding.shape, one_hot, one_hot.shape)\n\n            e = torch.sum(one_hot*embedding.to(device), dim=0)\n            kk.append(e)\n        lab2 = torch.tensor(lab2)\n        prpmt = []\n        for i,j,z in zip(ids,texts,labs_verbalized):\n            prpmt.append(i+'. The meme text reads :'+j + '. Classifier thinks the meme is {}'.format(z))\n            #all_labs_clf.append(z)\n        portion1,lab1, a1 = get_tokens(prpmt)\n        string = ['the meme is actually']\n        portion3,lab5,_ = get_tokens(string)\n        inp_embed = torch.stack(kk).unsqueeze(dim=1)\n        # print(inp_embed)\n        # print(inp_embed.shape)\n        # print(portion1.shape,inp_embed.shape,portion2.shape,m.shape,portion3.shape)\n\n        final_embeds = torch.cat((portion1,inp_embed,portion2,m,portion3),dim=1)\n        # print(final_embeds.shape)\n        # print(lab1.shape, lab2.shape, lab3.shape, lab4.shape, lab5.shape)\n        labs_shape = torch.cat((lab2,lab3,lab4,lab5),dim=1).shape\n        remaining_mask = torch.ones(labs_shape[0], labs_shape[1]).long()\n        #print(a1)\n        #print(remaining_mask)\n\n        full_mask = torch.cat((a1,remaining_mask),dim=1)\n        #print('fm ', full_mask.shape)\n        labs = torch.cat((lab1,lab2,lab3,lab4,lab5),dim=1)\n        #print(full_mask)\n        #print(0/0)\n        #         print(final_embeds.shape, labs.shape)\n        #         print(0/0)\n        ig = LayerIntegratedGradients(fwd_model, model1.transformer.wte)\n        attributions, delta_start = ig.attribute(inputs=labs.long().to('cuda'),\n                                  additional_forward_args=(labs.long().to('cuda'), full_mask.to('cuda')),\n                                  return_convergence_delta=True)\n        \n        attributions = attributions.sum(dim=-1).squeeze(0).cpu().numpy()\n        print(attributions)\n        print(attributions.max())\n        print(attributions.min())\n        # Normalize the attributions\n        attributions = (attributions - attributions.min()) / (attributions.max() - attributions.min())\n        print(attributions)\n        \n        print(0/0)\n            \n        with torch.no_grad():\n            output2 = model1(inputs_embeds = final_embeds.float(), labels = labs.long(), attention_mask=full_mask.to('cuda'))\n        # print(output2.loss)\n        # print(0/0)\n        loss_lm = output2.loss\n        #print(tokenizer1.batch_decode(output2.logits.argmax(dim=-1)))\n\n        #print(loss_lm)\n        llm_lab = tokenizer1.decode(output2.logits.argmax(dim=-1)[0][-1])\n        all_labs.append(llm_lab)\n        counter+=1\n        #if counter==10:\n        #    break\n        \n    return all_labs, all_labs_clf\n\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:43:04.621866Z","iopub.execute_input":"2023-09-14T13:43:04.622262Z","iopub.status.idle":"2023-09-14T13:43:04.651620Z","shell.execute_reply.started":"2023-09-14T13:43:04.622232Z","shell.execute_reply":"2023-09-14T13:43:04.650543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_performance_test()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:43:05.304018Z","iopub.execute_input":"2023-09-14T13:43:05.304612Z","iopub.status.idle":"2023-09-14T13:43:07.064394Z","shell.execute_reply.started":"2023-09-14T13:43:05.304579Z","shell.execute_reply":"2023-09-14T13:43:07.062944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"50257*4/2","metadata":{"execution":{"iopub.status.busy":"2023-09-14T12:53:19.942072Z","iopub.execute_input":"2023-09-14T12:53:19.942447Z","iopub.status.idle":"2023-09-14T12:53:19.952037Z","shell.execute_reply.started":"2023-09-14T12:53:19.942417Z","shell.execute_reply":"2023-09-14T12:53:19.950904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.load_state_dict(torch.load('/kaggle/input/models-explanation/gpt2_backbone.pt'))\ntinymodel.load_state_dict(torch.load('/kaggle/input/models-explanation/classifier (1).pt'))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T09:54:33.683881Z","iopub.execute_input":"2023-09-14T09:54:33.684293Z","iopub.status.idle":"2023-09-14T09:54:40.955667Z","shell.execute_reply.started":"2023-09-14T09:54:33.684260Z","shell.execute_reply":"2023-09-14T09:54:40.954656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp /kaggle/working/classifier.pt /kaggle/input/kb-fb-ds","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.774273Z","iopub.status.idle":"2023-09-13T07:27:25.774737Z","shell.execute_reply.started":"2023-09-13T07:27:25.774489Z","shell.execute_reply":"2023-09-13T07:27:25.774511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import torch\n# #os.environ['CUBLAS_WORKSPACE_CONFIG']=:4096:8\n# torch.use_deterministic_algorithms(True)\n# set_seed(42)\n# import numpy as np\n# model1_name = 'gpt2'\n# tokenizer1 = GPT2Tokenizer.from_pretrained(model1_name)\n# model1 = GPT2LMHeadModel.from_pretrained(model1_name,output_hidden_states=True).to(device)\n# mdl_rand = fusion(512,512,True,256,512,0.1).to(device)\n# tinymodel = TinyModel(mdl,mdl_rand,rand=False).to(device)\n# E = model1.transformer.wte.weight.detach()\n# # E = model1.model.model.embed_tokens.weight.detach()\n# optimizer = optim.Adam(tinymodel.parameters(), lr=0.0005)\n# optimizer1 = optim.Adam(model1.parameters(), lr=0.0005)\n# dix = {0:'normal', 1:'offensive'}\n\n# tinymodel.train()\n# model1.train()\n# # Training loop\n# num_epochs = 2\n# def transpose(x):\n#     return x.transpose(-2, -1)\n\n# for epoch in tqdm(range(num_epochs)):\n#     #     set_seed(42)\n#     l=0\n#     cnt = 0\n#     l_lm = 0\n#     l_clf = 0\n#     tinymodel.train()\n#     model1.train()\n#     for ii,ti, gol, ids in dataloader:\n#         # print(batch_model1, batch_model1)\n       \n#         ids = list(map(lambda x: x.split('/')[1], ids))\n#         #         print(ids)\n#         texts = [id2text[i] for i in ids]\n#         ids = [kb_fb[i] for i in ids]\n        \n#         #         ids_ = []\n#         #         for i in range(len(ids)):\n#         #             kbs = ids[i].split('[KB]')\n#         #             caps = ids[i].split('[CAPTION]')[-1]\n#         #             try:\n#         #                 kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n#         #             except IndexError as e:\n#         #                 kb = '[CAPTION] '+ caps\n#         #             ids_.append(kb)\n#         #         ids = ids_\n\n#         ids_ = []\n#         for i in range(len(ids)):\n#             kbs = ids[i].split('[KB]')\n#             #print('kbs ', kbs)\n#             caps = ids[i].split('[CAPTION]')[-1]\n#             #print(caps)\n#             kb = ''\n#             if len(kbs)>3:\n#                 kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n#             elif len(kbs)==3:\n#                 #print('in len3')\n#                 kb = '[KB] '+kbs[1]\n#                 caps = kbs[2].split('[CAPTION]')\n#                 kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n#             elif len(kbs)==2:\n#                 #print('in len 1')\n#                 caps = kbs[1].split('[CAPTION]')\n#                 kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n#             elif len(kbs)==1:\n#                 kb = kbs[0].strip()\n#                 #print('int ', kb)\n\n\n\n#             ids_.append(kb)\n        \n#         ids = ids_\n        \n        \n        \n       \n        \n#         i = ii.float().to(device)\n#         t = ti.float().to(device)\n#         batch_size = i.shape[0]\n#         optimizer.zero_grad()\n#         optimizer1.zero_grad()\n#         logits, m = tinymodel(i,t)\n#         # print(m)\n#         m = m.unsqueeze(dim=1)\n#         #         prmpt0, lab0 = get_tokens([tokenizer1.bos_token]*batch_size, begin=True)\n       \n#         #         print(prmpt0.shape)\n\n#         gumbel_logits = F.gumbel_softmax(logits, tau=1, hard=True)\n#         # print(gumbel_logits)\n#         agmx = gumbel_logits.argmax(dim=1)\n\n#         # print(agmx, logits.argmax(dim=1))\n#         #         prpmt = ['model thinks the meme is ']*batch_size\n\n        \n      \n#         portion2,lab3, _ = get_tokens(['output of the classifier multimodal embedding is ']*batch_size)\n#         lab4 = [tokenizer1.encode('-')[:] for i in range(batch_size)]\n#         lab4 = torch.tensor(lab4)\n\n#         # portion3 = get_tokens(['the meme is actually'])\n\n\n\n\n\n\n#         kk = []\n#         labs_verbalized = []\n#         # batch_prompt = ['the model thinks the meme is ']*32\n#         lab2 = []\n#         for i in gumbel_logits:\n#             agmx = i.argmax()\n#             # print(agmx)\n#             # print(dix[agmx.item()])\n#             tokenized_ = tokenizer1.encode(dix[agmx.item()])[:]\n#             labs_verbalized.append(dix[agmx.item()])\n#             # print(tokenized_)\n#             lab2.append(tokenized_)\n#             embedding = E[tokenized_[0]]\n#             one_hot = i.view(-1, 1)\n#             # print(embedding.shape, one_hot, one_hot.shape)\n\n#             e = torch.sum(one_hot*embedding.to(device), dim=0)\n#             kk.append(e)\n#         lab2 = torch.tensor(lab2)\n#         #string = ['the meme is actually {}'.format(i) for i in labs_verbalized] # why this fucking mistake??????\n        \n#         prpmt = []\n#         for i,j,z in zip(ids,texts,labs_verbalized):\n#             prpmt.append(i+'. The meme text reads :'+j + '. Classifier thinks the meme is {}'.format(z))\n#         portion1,lab1, a1 = get_tokens(prpmt)\n        \n#         string = ['the meme is actually {}'.format(dix[int(i)]) for i in gol]\n#         portion3,lab5,_ = get_tokens(string)\n#         inp_embed = torch.stack(kk).unsqueeze(dim=1)\n#         # print(inp_embed)\n#         # print(inp_embed.shape)\n#         # print(portion1.shape,inp_embed.shape,portion2.shape,m.shape,portion3.shape)\n       \n#         final_embeds = torch.cat((portion1,inp_embed,portion2,m,portion3),dim=1)\n#         # print(final_embeds.shape)\n#         # print(lab1.shape, lab2.shape, lab3.shape, lab4.shape, lab5.shape)\n#         labs_shape = torch.cat((lab2,lab3,lab4,lab5),dim=1).shape\n#         remaining_mask = torch.ones(labs_shape[0], labs_shape[1]).long()\n#         #print(a1)\n#         #print(remaining_mask)\n        \n#         full_mask = torch.cat((a1,remaining_mask),dim=1)\n#         #print('fm ', full_mask.shape)\n#         labs = torch.cat((lab1,lab2,lab3,lab4,lab5),dim=1)\n#         #print(full_mask)\n#         #print(0/0)\n#         #         print(final_embeds.shape, labs.shape)\n#         #         print(0/0)\n#         output2 = model1(inputs_embeds = final_embeds.float(), labels = labs.long(), attention_mask=full_mask.to('cuda'))\n#         # print(output2.loss)\n#         # print(0/0)\n#         loss_lm = output2.loss\n\n\n\n\n#         loss_clf = torch.nn.functional.cross_entropy(logits, gol.to(device), reduction='mean')\n\n#         #print(loss_lm, loss_clf)\n       \n#         loss = loss_lm+loss_clf\n\n#         loss.backward()\n#         optimizer.step()\n#         optimizer1.step()\n\n\n#         l+=loss.detach().item()\n#         l_clf+=loss_clf.detach().item()\n#         l_lm+=loss_lm.detach().item()\n#         cnt+=1\n\n#     print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {l/cnt}, Loss clf: {l_clf/cnt}, Loss llm: {l_lm/cnt}\")\n#     tinymodel.eval()\n#     pred,_ = tinymodel(im_tensor_.float().to(device),tx_tensor_.float().to(device))\n#     pred = pred.argmax(dim=1).detach().cpu().numpy()\n#     print(f1_score(gl_, pred, average='macro'), accuracy_score(gl_, pred))\n#     al, alc = get_performance_test()\n#     l2l = {'normal':0, 'offensive':1}\n#     al_ = list(map(lambda x: l2l[x.strip()], al))\n#     #alc_ = list(map(lambda x: l2l[x.strip()], alc))\n#     print(f1_score(gl_test, al_, average='macro'), f1_score(gl_test, alc, average='macro'))\n#     print(accuracy_score(gl_test, al_), accuracy_score(gl_test, alc))\n    \n    \n# print(\"Training complete!\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.776754Z","iopub.status.idle":"2023-09-13T07:27:25.777222Z","shell.execute_reply.started":"2023-09-13T07:27:25.776994Z","shell.execute_reply":"2023-09-13T07:27:25.777018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#E = model1.transformer.wte.weight.detach()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.783816Z","iopub.status.idle":"2023-09-13T07:27:25.784311Z","shell.execute_reply.started":"2023-09-13T07:27:25.784074Z","shell.execute_reply":"2023-09-13T07:27:25.784097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #all_labs\n# import torch\n# torch.manual_seed(42)\n# import random\n# random.seed(42)\n# import numpy as np\n# np.random.seed(42)\n# tinymodel = TinyModel(mdl,rand=False).to(device)\n# E = model1.transformer.wte.weight.detach()\n# # E = model1.model.model.embed_tokens.weight.detach()\n# optimizer = optim.Adam(tinymodel.parameters(), lr=0.0005)\n# optimizer1 = optim.Adam(model1.parameters(), lr=0.0005)\n# dix = {0:'normal', 1:'offensive'}\n\n# tinymodel.train()\n# model1.train()\n# # Training loop\n# num_epochs = 5\n# def transpose(x):\n#     return x.transpose(-2, -1)\n\n# for epoch in range(num_epochs):\n#     l=0\n#     cnt = 0\n#     l_lm = 0\n#     l_clf = 0\n#     tinymodel.train()\n#     model1.train()\n#     for ii,ti, gol, ids in tqdm(dataloader):\n#         # print(batch_model1, batch_model1)\n       \n#         ids = list(map(lambda x: x.split('/')[1], ids))\n#         #         print(ids)\n#         texts = [id2text[i] for i in ids]\n#         ids = [kb_fb[i] for i in ids]\n        \n#         ids_ = []\n#         for i in range(len(ids)):\n#             kbs = ids[i].split('[KB]')\n#             #print('kbs ', kbs)\n#             caps = ids[i].split('[CAPTION]')[-1]\n#             #print(caps)\n#             kb = ''\n#             if len(kbs)>3:\n#                 kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n#             elif len(kbs)==3:\n#                 #print('in len3')\n#                 kb = '[KB] '+kbs[1]\n#                 caps = kbs[2].split('[CAPTION]')\n#                 kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n#             elif len(kbs)==2:\n#                 #print('in len 1')\n#                 caps = kbs[1].split('[CAPTION]')\n#                 kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n#             elif len(kbs)==1:\n#                 kb = kbs[0].strip()\n#                 #print('int ', kb)\n\n\n\n#             ids_.append(kb)\n        \n#         ids = ids_\n        \n        \n        \n       \n        \n#         i = ii.float().to(device)\n#         t = ti.float().to(device)\n#         batch_size = i.shape[0]\n#         optimizer.zero_grad()\n#         optimizer1.zero_grad()\n#         logits, m = tinymodel(i,t)\n#         # print(m)\n#         m = m.unsqueeze(dim=1)\n#         #         prmpt0, lab0 = get_tokens([tokenizer1.bos_token]*batch_size, begin=True)\n       \n#         #         print(prmpt0.shape)\n\n#         gumbel_logits = F.gumbel_softmax(logits, tau=1, hard=True)\n#         # print(gumbel_logits)\n#         agmx = gumbel_logits.argmax(dim=1)\n\n#         # print(agmx, logits.argmax(dim=1))\n#         #         prpmt = ['model thinks the meme is ']*batch_size\n\n        \n      \n#         #         portion2,lab3, _ = get_tokens(['output of the classifier multimodal embedding is ']*batch_size)\n#         #         lab4 = [tokenizer1.encode('-')[:] for i in range(batch_size)]\n#         #         lab4 = torch.tensor(lab4)\n\n#         # portion3 = get_tokens(['the meme is actually'])\n\n\n\n\n\n\n#         kk = []\n#         labs_verbalized = []\n#         # batch_prompt = ['the model thinks the meme is ']*32\n#         lab2 = []\n#         for i in gumbel_logits:\n#             agmx = i.argmax()\n#             # print(agmx)\n#             # print(dix[agmx.item()])\n#             tokenized_ = tokenizer1.encode(dix[agmx.item()])[:]\n#             labs_verbalized.append(dix[agmx.item()])\n#             # print(tokenized_)\n#             lab2.append(tokenized_)\n#             embedding = E[tokenized_[0]]\n#             one_hot = i.view(-1, 1)\n#             # print(embedding.shape, one_hot, one_hot.shape)\n\n#             e = torch.sum(one_hot*embedding.to(device), dim=0)\n#             kk.append(e)\n#         #         lab2 = torch.tensor(lab2)\n#         #string = ['the meme is actually {}'.format(i) for i in labs_verbalized] # why this fucking mistake??????\n        \n#         prpmt = []\n#         for i,j,z in zip(ids,texts,labs_verbalized):\n#             prpmt.append(i+'. The meme text reads :'+j)\n#         portion1,lab1, a1 = get_tokens(prpmt)\n        \n#         string = ['the meme is actually {}'.format(dix[int(i)]) for i in gol]\n#         portion3,lab5,_ = get_tokens(string)\n#         inp_embed = torch.stack(kk).unsqueeze(dim=1)\n#         # print(inp_embed)\n#         # print(inp_embed.shape)\n#         # print(portion1.shape,inp_embed.shape,portion2.shape,m.shape,portion3.shape)\n       \n#         final_embeds = torch.cat((portion1,portion3),dim=1)\n#         # print(final_embeds.shape)\n#         # print(lab1.shape, lab2.shape, lab3.shape, lab4.shape, lab5.shape)\n#         labs_shape = lab5.shape\n#         remaining_mask = torch.ones(labs_shape[0], labs_shape[1]).long()\n#         #print(a1)\n#         #print(remaining_mask)\n        \n#         full_mask = torch.cat((a1,remaining_mask),dim=1)\n#         #print('fm ', full_mask.shape)\n#         labs = torch.cat((lab1,lab5),dim=1)\n#         #print(full_mask)\n#         #print(0/0)\n#         #         print(final_embeds.shape, labs.shape)\n#         #         print(0/0)\n#         output2 = model1(inputs_embeds = final_embeds.float(), labels = labs.long(), attention_mask=full_mask.to('cuda'))\n#         # print(output2.loss)\n#         # print(0/0)\n#         loss_lm = output2.loss\n\n\n\n\n#         loss_clf = torch.nn.functional.cross_entropy(logits, gol.to(device), reduction='mean')\n\n#         #print(loss_lm, loss_clf)\n       \n#         loss = loss_lm+loss_clf\n\n#         loss.backward()\n#         optimizer.step()\n#         optimizer1.step()\n\n\n#         l+=loss.detach().item()\n#         l_clf+=loss_clf.detach().item()\n#         l_lm+=loss_lm.detach().item()\n#         cnt+=1\n\n#     print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {l/cnt}, Loss clf: {l_clf/cnt}, Loss llm: {l_lm/cnt}\")\n#     tinymodel.eval()\n#     pred,_ = tinymodel(im_tensor_.float().to(device),tx_tensor_.float().to(device))\n#     pred = pred.argmax(dim=1).detach().cpu().numpy()\n#     print(f1_score(gl_, pred, average='macro'), accuracy_score(gl_, pred))\n#     al, alc = get_performance_test_nm()\n#     l2l = {'normal':0, 'offensive':1}\n#     al_ = list(map(lambda x: l2l[x.strip()], al))\n#     alc_ = list(map(lambda x: l2l[x.strip()], alc))\n#     print(f1_score(gl_test, al_, average='macro'), f1_score(gl_test, alc_, average='macro'))\n#     print(accuracy_score(gl_test, al_), accuracy_score(gl_test, alc_))\n    \n    \n# print(\"Training complete!\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.787393Z","iopub.status.idle":"2023-09-13T07:27:25.788152Z","shell.execute_reply.started":"2023-09-13T07:27:25.787883Z","shell.execute_reply":"2023-09-13T07:27:25.787906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from : https://github.com/huggingface/transformers/issues/6535\ndef prepare_inputs_for_generation(input_ids, past_key_values=None, **kwargs):\n    token_type_ids = kwargs.get(\"token_type_ids\", None)\n    # only last token for inputs_ids if past_key_values is defined in kwargs\n    if past_key_values:\n        input_ids = input_ids[:, -1].unsqueeze(-1)\n        if token_type_ids is not None:\n            token_type_ids = token_type_ids[:, -1].unsqueeze(-1)\n\n    attention_mask = kwargs.get(\"attention_mask\", None)\n    position_ids = kwargs.get(\"position_ids\", None)\n\n    if attention_mask is not None and position_ids is None:\n        # create position_ids on the fly for batch generation\n        position_ids = attention_mask.long().cumsum(-1) - 1\n        position_ids.masked_fill_(attention_mask == 0, 1)\n        if past_key_values:\n            position_ids = position_ids[:, -1].unsqueeze(-1)\n    else:\n        position_ids = None\n\n    # !!!!!!!!!!!!!!!!!!! start: modified vs original, to pass inputs_embeds when they are available\n    if \"inputs_embeds\" in kwargs and past_key_values is None:  # we only want to use them in the 1st generation step\n        model_inputs = {\"inputs_embeds\": inputs_embeds}\n    else:\n        model_inputs = {\"input_ids\": input_ids}\n    model_inputs.update({\n        \"past_key_values\": past_key_values,\n        \"use_cache\": kwargs.get(\"use_cache\"),\n        \"position_ids\": position_ids,\n        \"attention_mask\": attention_mask,\n        \"token_type_ids\": token_type_ids,\n    })\n    return model_inputs\n    # !!!!!!!!!!!!!!!!!!! end: modified vs original, to pass inputs_embeds when they are available","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.790476Z","iopub.status.idle":"2023-09-13T07:27:25.790936Z","shell.execute_reply.started":"2023-09-13T07:27:25.790696Z","shell.execute_reply":"2023-09-13T07:27:25.790719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs_embeds = model1.transformer.wte(torch.LongTensor([[787,32329,898]]).to(device))\nprint(inputs_embeds)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.792557Z","iopub.status.idle":"2023-09-13T07:27:25.798532Z","shell.execute_reply.started":"2023-09-13T07:27:25.798277Z","shell.execute_reply":"2023-09-13T07:27:25.798304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib.pyplot import imshow\nfrom IPython.display import display","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.800233Z","iopub.status.idle":"2023-09-13T07:27:25.800687Z","shell.execute_reply.started":"2023-09-13T07:27:25.800452Z","shell.execute_reply":"2023-09-13T07:27:25.800474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.802649Z","iopub.status.idle":"2023-09-13T07:27:25.803123Z","shell.execute_reply.started":"2023-09-13T07:27:25.802868Z","shell.execute_reply":"2023-09-13T07:27:25.802890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install shutup","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.805257Z","iopub.status.idle":"2023-09-13T07:27:25.805719Z","shell.execute_reply.started":"2023-09-13T07:27:25.805476Z","shell.execute_reply":"2023-09-13T07:27:25.805499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutup; shutup.please()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.807334Z","iopub.status.idle":"2023-09-13T07:27:25.812534Z","shell.execute_reply.started":"2023-09-13T07:27:25.812285Z","shell.execute_reply":"2023-09-13T07:27:25.812311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_ids","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.814208Z","iopub.status.idle":"2023-09-13T07:27:25.814651Z","shell.execute_reply.started":"2023-09-13T07:27:25.814423Z","shell.execute_reply":"2023-09-13T07:27:25.814445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seed(42)\nstart_index = 0\nend_index = len(test_dataset)\n\n# Specify how many random indices you want to select\nnum_indices_to_select = 100\n\n# Use random.sample() to select random indices without duplicates\nrandom_indices = random.sample(range(start_index, end_index + 1), num_indices_to_select)\n\nprint(random_indices)\n\ntest_dataset_1 = torch.utils.data.Subset(test_dataset, random_indices)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.816105Z","iopub.status.idle":"2023-09-13T07:27:25.816744Z","shell.execute_reply.started":"2023-09-13T07:27:25.816500Z","shell.execute_reply":"2023-09-13T07:27:25.816528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n\ng = torch.Generator()\ng.manual_seed(42)\nbatch_size = 32\nset_seed(42)\n\ndataloader_test = DataLoader(\n    torch.utils.data.Subset(test_dataset_1, [i for i in range(70)]),\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=2,\n    worker_init_fn=seed_worker,\n    generator=g,\n)\n\n\n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.819300Z","iopub.status.idle":"2023-09-13T07:27:25.819747Z","shell.execute_reply.started":"2023-09-13T07:27:25.819516Z","shell.execute_reply":"2023-09-13T07:27:25.819538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataloader_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.821341Z","iopub.status.idle":"2023-09-13T07:27:25.826545Z","shell.execute_reply.started":"2023-09-13T07:27:25.826270Z","shell.execute_reply":"2023-09-13T07:27:25.826297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_ids = {}\ndef get_performance_test(second_pass=False, llm_label='', prev_prob = 0, prev_lab = '', counter=0):\n    #print(test_dataset)\n    torch.use_deterministic_algorithms(True)\n    set_seed(42)\n    \n    if second_pass:\n        #print('IN SECOND PASS')\n        test_dataset_ = [test_dataset_1[counter]]\n        \n        \n    else:\n        test_dataset_ = test_dataset_1\n    \n    tinymodel.eval()\n    model1.eval()\n    all_labs = []\n    all_labs_clf = []\n    counter = 0\n    \n    for ii,ti, gol, ids in tqdm(test_dataset_,disable=second_pass):\n\n        #     print(0/0)\n        #print(ids)\n        tmp_id = ids\n        \n        #         raw_image = Image.open('./data/'+ids)\n        #         if not second_pass:\n        #             display(raw_image)\n        ti = ti.unsqueeze(0)\n        ii = ii.unsqueeze(0)\n        gol = [gol]\n        ids = [ids]\n        # print(batch_model1, batch_model1)\n\n        ids = list(map(lambda x: x.split('/')[1], ids))\n        #         ids_ = []\n        #         for i in range(len(ids)):\n        #             kbs = ids[i].split('[KB]')\n        #             caps = ids[i].split('[CAPTION]')[-1]\n        #             try:\n        #                 kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n        #             except IndexError as e:\n        #                 kb = '[CAPTION] '+ caps\n        #             ids_.append(kb)\n        #         ids = ids_\n        \n        ids_ = []\n        for i in range(len(ids)):\n            kbs = ids[i].split('[KB]')\n            #print('kbs ', kbs)\n            caps = ids[i].split('[CAPTION]')[-1]\n            #print(caps)\n            kb = ''\n            if len(kbs)>3:\n                kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n            elif len(kbs)==3:\n                #print('in len3')\n                kb = '[KB] '+kbs[1]\n                caps = kbs[2].split('[CAPTION]')\n                kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n            elif len(kbs)==2:\n                #print('in len 1')\n                caps = kbs[1].split('[CAPTION]')\n                kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n            elif len(kbs)==1:\n                kb = kbs[0].strip()\n                #print('int ', kb)\n\n\n\n            ids_.append(kb)\n        \n        ids = ids_\n        \n        \n        \n        #         print(ids)\n        texts = [id2text[i] for i in ids]\n        ids = [kb_fb[i] for i in ids]\n        if second_pass:\n            ids = llm_label\n        #print('ids', ids)\n        #print('text', texts)\n\n        #     prpmt = []\n        #     for i,j in zip(ids,texts):\n        #         prpmt.append(i+'. The meme text reads :'+j + '. Classifier thinks the meme is')\n\n\n\n        i = ii.float().to(device)\n        t = ti.float().to(device)\n        batch_size = i.shape[0]\n        #with torch.no_grad():\n        logits, m = tinymodel(i,t)\n        # print(m)\n        m = m.unsqueeze(dim=1)\n        all_labs_clf.append(logits.argmax(dim=-1)[0].item())\n        #         prmpt0, lab0 = get_tokens([tokenizer1.bos_token]*batch_size, begin=True)\n\n        #         print(prmpt0.shape)\n\n        gumbel_logits = F.gumbel_softmax(logits, tau=1, hard=True)\n        # print(gumbel_logits)\n        agmx = gumbel_logits.argmax(dim=1)\n\n        # print(agmx, logits.argmax(dim=1))\n        #         prpmt = ['model thinks the meme is ']*batch_size\n\n        #portion1,lab1, a1 = get_tokens(prpmt)\n\n        portion2,lab3, _ = get_tokens(['output of the classifier multimodal embedding is ']*batch_size)\n        lab4 = [tokenizer1.encode('-')[:] for i in range(batch_size)]\n        lab4 = torch.tensor(lab4)\n\n        # portion3 = get_tokens(['the meme is actually'])\n\n\n\n\n\n\n        kk = []\n        labs_verbalized = []\n        # batch_prompt = ['the model thinks the meme is ']*32\n        lab2 = []\n        for i in gumbel_logits:\n            agmx = i.argmax()\n            # print(agmx)\n            # print(dix[agmx.item()])\n            tokenized_ = tokenizer1.encode(dix[agmx.item()])[:]\n            labs_verbalized.append(dix[agmx.item()])\n            # print(tokenized_)\n            lab2.append(tokenized_)\n            embedding = E[tokenized_[0]]\n            one_hot = i.view(-1, 1)\n            # print(embedding.shape, one_hot, one_hot.shape)\n\n            e = torch.sum(one_hot*embedding.to(device), dim=0)\n            kk.append(e)\n        lab2 = torch.tensor(lab2)\n        prpmt = []\n        for i,j,z in zip(ids,texts,labs_verbalized):\n            prpmt.append(i+'. The meme text reads :'+j + '. Classifier thinks the meme is {}'.format(z))\n            #all_labs_clf.append(z)\n        portion1,lab1, a1 = get_tokens(prpmt)\n        \n        string = ['the meme is actually']\n        #         if second_pass:\n        #             string[0] += '{} because of'.format(llm_label)\n        #             print(string)\n        portion3,lab5,_ = get_tokens(string)\n        inp_embed = torch.stack(kk).unsqueeze(dim=1)\n        # print(inp_embed)\n        # print(inp_embed.shape)\n        # print(portion1.shape,inp_embed.shape,portion2.shape,m.shape,portion3.shape)\n\n        final_embeds = torch.cat((portion1,inp_embed,portion2,m,portion3),dim=1)\n        # print(final_embeds.shape)\n        # print(lab1.shape, lab2.shape, lab3.shape, lab4.shape, lab5.shape)\n        labs_shape = torch.cat((lab2,lab3,lab4,lab5),dim=1).shape\n        remaining_mask = torch.ones(labs_shape[0], labs_shape[1]).long()\n        #print(a1)\n        #print(remaining_mask)\n\n        full_mask = torch.cat((a1,remaining_mask),dim=1)\n        #print('fm ', full_mask.shape)\n        labs = torch.cat((lab1,lab2,lab3,lab4,lab5),dim=1)\n        #print(full_mask)\n        #print(0/0)\n        #         print(final_embeds.shape, labs.shape)\n        #         print(0/0)\n        #with torch.no_grad():\n        if second_pass:\n            #model1.prepare_inputs_for_generation = prepare_inputs_for_generation\n            #input_ids = torch.LongTensor([[model1.config.bos_token_id]]).to(device)\n            #inputs_embdes = final_embeds.float().to(device)\n            #op = model1.sample(input_ids, inputs_embeds = inputs_embdes, pad_token_id=model1.config.eos_token_id)\n            #print(tokenizer1.batch_decode(op))\n            output2 = model1(inputs_embeds = final_embeds.float(), labels = labs.long(), attention_mask=full_mask.to('cuda'))\n            #print('SECOND PASS ',tokenizer1.batch_decode(output2.logits[:,-1,:].squeeze(dim=0).detach().cpu().topk(40).indices))\n            second_pass_lab = tokenizer1.batch_decode(output2.logits[:,-1,:].squeeze(dim=0).detach().cpu().topk(40).indices)[0].strip()\n            #print('pl', prev_lab)\n            #print('sl', second_pass_lab)\n            agmx_id = output2.logits.argmax(dim=-1)[0][-1].item()\n            log_likelihood = output2.logits[:,-1,:]\n            log_likelihood = torch.nn.functional.softmax(log_likelihood, dim=-1)[:,agmx_id][0].item()\n            prev_prob = prev_prob[0].item()\n            #print('current probability', log_likelihood)\n            #print('previous probability', prev_prob)\n            #             if (prev_lab==second_pass_lab) and (log_likelihood>=prev_prob):\n            #if (prev_lab==second_pass_lab) and (abs(log_likelihood-prev_prob)<=0.05):\n            #    return True\n            \n            if prev_lab==second_pass_lab:\n                return True, log_likelihood\n            \n            else:\n                return False, False\n            \n            \n                                                      \n        else:\n            output2 = model1(inputs_embeds = final_embeds.float(), labels = labs.long(), attention_mask=full_mask.to('cuda'))\n        # print(output2.loss)\n        # print(0/0)\n        loss_lm = output2.loss\n        #print(tokenizer1.batch_decode(output2.logits.argmax(dim=-1)))\n\n        #print(loss_lm)\n        m.retain_grad()\n        model1.transformer.wte.weight.retain_grad()\n        #print(output2.logits.shape)\n        #print(output2.logits.argmax(dim=-1)[0].shape)\n        agmx_idx = output2.logits.argmax(dim=-1)[0][-1].item()\n        #print(agmx_idx)\n        #print(output2.logits[:,-1,:])\n        log_likelihood_ = output2.logits[:,-1,:]\n        log_likelihood = output2.logits[:,-1,agmx_idx]\n        #print(log_likelihood)\n        log_likelihood.backward()\n        grad_  = m.grad.data.cpu().squeeze(1)\n        #embedding_norm = model1.transformer.wte.weight.grad.data.cpu().norm(dim=-1)\n        #print('en ', embedding_norm,embedding_norm.shape)\n        #tokens_index = torch.mm(grad_, E.detach().cpu().T)[0]\n        \n        #tokens_index /= model1.transformer.wte.weight.detach().cpu().norm(dim=-1)\n        #print(tokens_index)\n        #ct_index = tokens_index*output2.logits[:,-1,:].squeeze(dim=0).detach().cpu() # ct_index = cumulative token index\n        \n        #print(tokens_index.topk(40).indices)\n        #print(tokenizer1.batch_decode(embedding_norm.topk(40).indices))\n        #print(tokenizer1.batch_decode(tokens_index.topk(40).indices))\n        #print(tokenizer1.batch_decode(ct_index.topk(40).indices))\n        #print(tokenizer1.batch_decode(output2.logits[:,-1,:].squeeze(dim=0).detach().cpu().topk(40).indices))\n        #print(tokens_index.shape)\n        #print(grad_.shape)\n        ti,op,tt,t_id = grad_, output2.logits[:,-1,:].squeeze(dim=0).detach().cpu(), texts, tmp_id\n        #print('****************************')\n        #print(t_id)\n        output_aware_token_idx = []\n        output_aware_tokens = []\n        for i in op.topk(3500).indices:\n            k = model1.transformer.wte(i.cuda()).detach().cpu().unsqueeze(1)\n\n            #output_aware_token_idx.append(ti.mm(k))\n            val = torch.nn.functional.cosine_similarity(ti,k.T)[0].item()\n             \n            #if val>0:\n            output_aware_token_idx.append(val)\n            output_aware_tokens.append(tokenizer1.decode(i))\n            #     print('{} -> {}'.format(tokenizer1.decode(i), ti.mm(k).squeeze()))\n        \n        median = np.median(output_aware_token_idx)\n        p,q = [],[]\n        #         for i,j in zip(output_aware_token_idx, output_aware_tokens):\n        #             if i>=median:\n        #                 p.append(i)\n        #                 q.append(j)\n                \n        #         for i,j in zip(output_aware_token_idx, output_aware_tokens):\n        #             if i>-0.1 and i<0.1:\n        #                 p.append(i)\n        #                 q.append(j)\n\n        #         output_aware_token_idx = p\n        #         output_aware_tokens = q\n        \n        output_aware_tokens = list(map(lambda x: x.strip().lower(), output_aware_tokens))\n        \n        image = preprocess(Image.open('./data/'+t_id)).unsqueeze(0).to(device)\n        text = clip.tokenize(output_aware_tokens).to(device)\n        # clip_feats = []\n        text_cand = clip.tokenize(tt).to(device)\n\n\n\n        with torch.no_grad():\n            if_ = model.encode_image(image)\n            tf_ = model.encode_text(text_cand)\n\n            #print(if_.shape, tf_.shape)\n            multimodal_features = if_\n            text_features = model.encode_text(text)\n\n            clip_feats = torch.nn.functional.cosine_similarity(multimodal_features, text_features, dim=1)\n\n\n        clip_feats = clip_feats.cpu().numpy().tolist()\n        \n        combined_feats = []\n        for i,j in zip(output_aware_token_idx, clip_feats):\n            #tmp = 2*i*j/(i+j)\n            tmp = 1.0*j+0.00*i\n            #tmp = j\n            combined_feats.append(tmp)\n            \n        final_tokens = []\n        for i in np.argsort(combined_feats)[-1:-20:-1]:\n            final_tokens.append(output_aware_tokens[i])\n            #print(output_aware_tokens[i])\n        \n        final_tokens = list(dict.fromkeys(final_tokens))\n        #final_tokens = list(final_tokens)\n        s = ['when', 'why', 'our']\n        final_tokens = [i for i in final_tokens if (i not in s and len(i)>2)][:20]\n        \n        op_preserving_kt = []\n        \n        for i in final_tokens:\n            string = '[KB] {} are'.format(i)\n            op = tokenizer1.batch_decode(model1.generate(torch.tensor(tokenizer1.encode(string)).unsqueeze(0).to('cuda'), max_length=14, pad_token_id=tokenizer1.eos_token_id))\n            s = ''\n            for i in op[0]:\n                s += i\n                if i=='.':\n                    break\n            op_preserving_kt.append(s)\n        \n        #print('op preserving ', op_preserving_kt)\n        #print(texts[0],labs_verbalized[0])\n        #print(ids[0])\n        caption = ids[0].split('[CAPTION]')[-1]\n        #print(caption)\n        \n        kb = ''\n        for i in op_preserving_kt:\n            kb+=i+' '\n            \n        #         kb1 += '[CAPTION] '+caption + 'output of the classifier multimodal embedding is '\n\n        #         kb2 = '. The meme text reads :'+tt[0] + '. Classifier thinks the meme is {}'.format(labs_verbalized[0]))\n        \n        #print('****************************')\n    \n        \n        \n        \n        op_preserving_final_tokens = []\n        preservation_scores = []\n        llm_lab = tokenizer1.decode(output2.logits.argmax(dim=-1)[0][-1])\n        #print(llm_lab)\n        for i in op_preserving_kt:\n            kb = i+' '\n            prev_prob = torch.nn.functional.softmax(log_likelihood_, dim=-1)[:,agmx_idx]\n            #print(prev_prob)\n            #break\n            #[:,-1,agmx_idx]\n            is_op_preserved,likelihood = get_performance_test(second_pass=True, llm_label=[kb], prev_lab=llm_lab.strip(), prev_prob=prev_prob, counter=counter)\n            if is_op_preserved:\n                preservation_scores.append(likelihood)\n                op_preserving_final_tokens.append(i)\n            \n                \n        #print('OP PRESERVING FINAL TOKENS ',op_preserving_final_tokens)      \n        #print('PRESERVATION SCORES ',preservation_scores)\n        toks = []\n        for idx in list(reversed(list(np.argsort(preservation_scores))))[:4]:\n            #print(idx)\n            tmp = op_preserving_final_tokens[idx].split('are')[0][4:].strip()\n            toks.append(tmp)\n        \n        #print('OP PRESERVING FINAL TOKENS ',toks)\n        \n        string = ''\n        for i in toks:\n            string+=i+'\\t'\n        \n        #print(string)\n        #print(string.split('\\t'))\n        \n        d_ids[t_id] = string\n        \n        all_labs.append(llm_lab)\n        counter+=1\n    \n        \n        \n    return all_labs, all_labs_clf, grad_, output2.logits[:,-1,:].squeeze(dim=0).detach().cpu(), texts, tmp_id\n\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.828423Z","iopub.status.idle":"2023-09-13T07:27:25.828867Z","shell.execute_reply.started":"2023-09-13T07:27:25.828638Z","shell.execute_reply":"2023-09-13T07:27:25.828660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seed(42)\nal, alc,ti,op,tt,t_id = get_performance_test()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.830766Z","iopub.status.idle":"2023-09-13T07:27:25.831235Z","shell.execute_reply.started":"2023-09-13T07:27:25.831004Z","shell.execute_reply":"2023-09-13T07:27:25.831028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"E.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.833450Z","iopub.status.idle":"2023-09-13T07:27:25.833897Z","shell.execute_reply.started":"2023-09-13T07:27:25.833666Z","shell.execute_reply":"2023-09-13T07:27:25.833688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_ids = {}\ndef get_performance_test(second_pass=False, llm_label='', prev_prob = 0, prev_lab = '', counter=0):\n    #print(test_dataset)\n    torch.use_deterministic_algorithms(True)\n    set_seed(42)\n    \n    if second_pass:\n        #print('IN SECOND PASS')\n        test_dataset_ = [test_dataset_1[counter]]\n        \n        \n    else:\n        test_dataset_ = test_dataset_1\n    \n    tinymodel.eval()\n    model1.eval()\n    all_labs = []\n    all_labs_clf = []\n    counter = 0\n    \n    for ii,ti, gol, ids in tqdm(test_dataset_,disable=second_pass):\n\n        #     print(0/0)\n        #print(ids)\n        tmp_id = ids\n        \n        #         raw_image = Image.open('./data/'+ids)\n        #         if not second_pass:\n        #             display(raw_image)\n        ti = ti.unsqueeze(0)\n        ii = ii.unsqueeze(0)\n        gol = [gol]\n        ids = [ids]\n        # print(batch_model1, batch_model1)\n\n        ids = list(map(lambda x: x.split('/')[1], ids))\n        #         ids_ = []\n        #         for i in range(len(ids)):\n        #             kbs = ids[i].split('[KB]')\n        #             caps = ids[i].split('[CAPTION]')[-1]\n        #             try:\n        #                 kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n        #             except IndexError as e:\n        #                 kb = '[CAPTION] '+ caps\n        #             ids_.append(kb)\n        #         ids = ids_\n        \n        ids_ = []\n        for i in range(len(ids)):\n            kbs = ids[i].split('[KB]')\n            #print('kbs ', kbs)\n            caps = ids[i].split('[CAPTION]')[-1]\n            #print(caps)\n            kb = ''\n            if len(kbs)>3:\n                kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n            elif len(kbs)==3:\n                #print('in len3')\n                kb = '[KB] '+kbs[1]\n                caps = kbs[2].split('[CAPTION]')\n                kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n            elif len(kbs)==2:\n                #print('in len 1')\n                caps = kbs[1].split('[CAPTION]')\n                kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n            elif len(kbs)==1:\n                kb = kbs[0].strip()\n                #print('int ', kb)\n\n\n\n            ids_.append(kb)\n        \n        ids = ids_\n        \n        \n        \n        #         print(ids)\n        texts = [id2text[i] for i in ids]\n        ids = [kb_fb[i] for i in ids]\n        if second_pass:\n            ids = llm_label\n        #print('ids', ids)\n        #print('text', texts)\n\n        #     prpmt = []\n        #     for i,j in zip(ids,texts):\n        #         prpmt.append(i+'. The meme text reads :'+j + '. Classifier thinks the meme is')\n\n\n\n        i = ii.float().to(device)\n        t = ti.float().to(device)\n        batch_size = i.shape[0]\n        #with torch.no_grad():\n        logits, m = tinymodel(i,t)\n        # print(m)\n        m = m.unsqueeze(dim=1)\n        all_labs_clf.append(logits.argmax(dim=-1)[0].item())\n        #         prmpt0, lab0 = get_tokens([tokenizer1.bos_token]*batch_size, begin=True)\n\n        #         print(prmpt0.shape)\n\n        gumbel_logits = F.gumbel_softmax(logits, tau=1, hard=True)\n        # print(gumbel_logits)\n        agmx = gumbel_logits.argmax(dim=1)\n\n        # print(agmx, logits.argmax(dim=1))\n        #         prpmt = ['model thinks the meme is ']*batch_size\n\n        #portion1,lab1, a1 = get_tokens(prpmt)\n\n        portion2,lab3, _ = get_tokens(['output of the classifier multimodal embedding is ']*batch_size)\n        lab4 = [tokenizer1.encode('-')[:] for i in range(batch_size)]\n        lab4 = torch.tensor(lab4)\n\n        # portion3 = get_tokens(['the meme is actually'])\n\n\n\n\n\n\n        kk = []\n        labs_verbalized = []\n        # batch_prompt = ['the model thinks the meme is ']*32\n        lab2 = []\n        for i in gumbel_logits:\n            agmx = i.argmax()\n            # print(agmx)\n            # print(dix[agmx.item()])\n            tokenized_ = tokenizer1.encode(dix[agmx.item()])[:]\n            labs_verbalized.append(dix[agmx.item()])\n            # print(tokenized_)\n            lab2.append(tokenized_)\n            embedding = E[tokenized_[0]]\n            one_hot = i.view(-1, 1)\n            # print(embedding.shape, one_hot, one_hot.shape)\n\n            e = torch.sum(one_hot*embedding.to(device), dim=0)\n            kk.append(e)\n        lab2 = torch.tensor(lab2)\n        prpmt = []\n        for i,j,z in zip(ids,texts,labs_verbalized):\n            prpmt.append(i+'. The meme text reads :'+j + '. Classifier thinks the meme is {}'.format(z))\n            #all_labs_clf.append(z)\n        portion1,lab1, a1 = get_tokens(prpmt)\n        \n        string = ['the meme is actually']\n        #         if second_pass:\n        #             string[0] += '{} because of'.format(llm_label)\n        #             print(string)\n        portion3,lab5,_ = get_tokens(string)\n        inp_embed = torch.stack(kk).unsqueeze(dim=1)\n        # print(inp_embed)\n        # print(inp_embed.shape)\n        # print(portion1.shape,inp_embed.shape,portion2.shape,m.shape,portion3.shape)\n\n        final_embeds = torch.cat((portion1,inp_embed,portion2,m,portion3),dim=1)\n        # print(final_embeds.shape)\n        # print(lab1.shape, lab2.shape, lab3.shape, lab4.shape, lab5.shape)\n        labs_shape = torch.cat((lab2,lab3,lab4,lab5),dim=1).shape\n        remaining_mask = torch.ones(labs_shape[0], labs_shape[1]).long()\n        #print(a1)\n        #print(remaining_mask)\n\n        full_mask = torch.cat((a1,remaining_mask),dim=1)\n        #print('fm ', full_mask.shape)\n        labs = torch.cat((lab1,lab2,lab3,lab4,lab5),dim=1)\n        #print(full_mask)\n        #print(0/0)\n        #         print(final_embeds.shape, labs.shape)\n        #         print(0/0)\n        #with torch.no_grad():\n        if second_pass:\n            #model1.prepare_inputs_for_generation = prepare_inputs_for_generation\n            #input_ids = torch.LongTensor([[model1.config.bos_token_id]]).to(device)\n            #inputs_embdes = final_embeds.float().to(device)\n            #op = model1.sample(input_ids, inputs_embeds = inputs_embdes, pad_token_id=model1.config.eos_token_id)\n            #print(tokenizer1.batch_decode(op))\n            output2 = model1(inputs_embeds = final_embeds.float(), labels = labs.long(), attention_mask=full_mask.to('cuda'))\n            #print('SECOND PASS ',tokenizer1.batch_decode(output2.logits[:,-1,:].squeeze(dim=0).detach().cpu().topk(40).indices))\n            second_pass_lab = tokenizer1.batch_decode(output2.logits[:,-1,:].squeeze(dim=0).detach().cpu().topk(40).indices)[0].strip()\n            #print('pl', prev_lab)\n            #print('sl', second_pass_lab)\n            agmx_id = output2.logits.argmax(dim=-1)[0][-1].item()\n            log_likelihood = output2.logits[:,-1,:]\n            log_likelihood = torch.nn.functional.softmax(log_likelihood, dim=-1)[:,agmx_id][0].item()\n            prev_prob = prev_prob[0].item()\n            #print('current probability', log_likelihood)\n            #print('previous probability', prev_prob)\n            #             if (prev_lab==second_pass_lab) and (log_likelihood>=prev_prob):\n            #if (prev_lab==second_pass_lab) and (abs(log_likelihood-prev_prob)<=0.05):\n            #    return True\n            \n            if prev_lab==second_pass_lab:\n                return True, log_likelihood\n            \n            else:\n                return False, False\n            \n            \n                                                      \n        else:\n            output2 = model1(inputs_embeds = final_embeds.float(), labels = labs.long(), attention_mask=full_mask.to('cuda'))\n        # print(output2.loss)\n        # print(0/0)\n        loss_lm = output2.loss\n        #print(tokenizer1.batch_decode(output2.logits.argmax(dim=-1)))\n\n        #print(loss_lm)\n        m.retain_grad()\n        model1.transformer.wte.weight.retain_grad()\n        #print(output2.logits.shape)\n        #print(output2.logits.argmax(dim=-1)[0].shape)\n        agmx_idx = output2.logits.argmax(dim=-1)[0][-1].item()\n        #print(agmx_idx)\n        #print(output2.logits[:,-1,:])\n        log_likelihood_ = output2.logits[:,-1,:]\n        log_likelihood = output2.logits[:,-1,agmx_idx]\n        #print(log_likelihood)\n        log_likelihood.backward()\n        grad_  = m.grad.data.cpu().squeeze(1)\n        #embedding_norm = model1.transformer.wte.weight.grad.data.cpu().norm(dim=-1)\n        #print('en ', embedding_norm,embedding_norm.shape)\n        #tokens_index = torch.mm(grad_, E.detach().cpu().T)[0]\n        \n        #tokens_index /= model1.transformer.wte.weight.detach().cpu().norm(dim=-1)\n        #print(tokens_index)\n        #ct_index = tokens_index*output2.logits[:,-1,:].squeeze(dim=0).detach().cpu() # ct_index = cumulative token index\n        \n        #print(tokens_index.topk(40).indices)\n        #print(tokenizer1.batch_decode(embedding_norm.topk(40).indices))\n        #print(tokenizer1.batch_decode(tokens_index.topk(40).indices))\n        #print(tokenizer1.batch_decode(ct_index.topk(40).indices))\n        #print(tokenizer1.batch_decode(output2.logits[:,-1,:].squeeze(dim=0).detach().cpu().topk(40).indices))\n        #print(tokens_index.shape)\n        #print(grad_.shape)\n        ti,op,tt,t_id = grad_, output2.logits[:,-1,:].squeeze(dim=0).detach().cpu(), texts, tmp_id\n        #print('****************************')\n        #print(t_id)\n        output_aware_token_idx = []\n        output_aware_tokens = []\n        cc = 0\n        for i in op.topk(50257).indices:\n            cc+=1\n            k = model1.transformer.wte(i.cuda()).detach().cpu().unsqueeze(1).detach().cpu()\n\n            #output_aware_token_idx.append(ti.mm(k))\n            val = torch.nn.functional.cosine_similarity(ti.detach().cpu(),k.T)[0].item()\n            \n             \n          \n            output_aware_token_idx.append(val)\n            output_aware_tokens.append(tokenizer1.decode(i))\n            \n            \n        \n        #print(output_aware_tokens)\n        \n        #p = list(reversed(np.argsort(output_aware_token_idx)))\n        \n        a,b = [],[]\n        \n        for i in range(len(output_aware_token_idx)):\n            if output_aware_token_idx[i]>-0.1 and output_aware_token_idx[i]<0.1:\n                a.append(abs(output_aware_token_idx[i]))\n                b.append(output_aware_tokens[i])\n            \n        #print(len(a))\n        \n        c = np.argsort(a)\n        print(len(c))\n            \n        d,e = [],[]\n        \n        for i in c:\n            d.append(output_aware_token_idx[i])\n            e.append(b[i])\n            if len(d)==3500:\n                break\n            \n        \n        output_aware_token_idx = d\n        output_aware_tokens = e\n        \n        \n        print(len(output_aware_tokens))\n        #print(0/0)\n        \n        #print('cc', cc)\n                \n           \n        #         median = np.median(output_aware_token_idx)\n        #         p,q = [],[]\n        #         #         for i,j in zip(output_aware_token_idx, output_aware_tokens):\n        #         #             if i>=median:\n        #         #                 p.append(i)\n        #         #                 q.append(j)\n\n        #         for i,j in zip(output_aware_token_idx, output_aware_tokens):\n        #             if i>0.5 and i<.7:\n        #                 p.append(i)\n        #                 q.append(j)\n\n        #         output_aware_token_idx = p\n        #         output_aware_tokens = q\n        \n        output_aware_tokens = list(map(lambda x: x.strip().lower(), output_aware_tokens))\n        \n        image = preprocess(Image.open('./data/'+t_id)).unsqueeze(0).to(device)\n        text = clip.tokenize(output_aware_tokens).to(device)\n        # clip_feats = []\n        #text_cand = clip.tokenize(tt).to(device)\n\n\n\n        with torch.no_grad():\n            if_ = model.encode_image(image)\n            #tf_ = model.encode_text(text_cand)\n\n            #print(if_.shape, tf_.shape)\n            multimodal_features = if_\n            text_features = model.encode_text(text)\n\n            clip_feats = torch.nn.functional.cosine_similarity(multimodal_features, text_features, dim=1)\n\n\n        clip_feats = clip_feats.cpu().numpy().tolist()\n        \n        combined_feats = []\n        for i,j in zip(output_aware_token_idx, clip_feats):\n            #tmp = 2*i*j/(i+j)\n            tmp = 1.0*j+0.00*i\n            #tmp = j\n            combined_feats.append(tmp)\n            \n        final_tokens = []\n        for i in np.argsort(combined_feats)[-1:-20:-1]:\n            final_tokens.append(output_aware_tokens[i])\n            #print(output_aware_tokens[i])\n        \n        final_tokens = list(dict.fromkeys(final_tokens))\n        #final_tokens = list(final_tokens)\n        s = ['when', 'why', 'our']\n        final_tokens = [i for i in final_tokens if (i not in s and len(i)>2)][:20]\n        \n        op_preserving_kt = []\n        \n        for i in final_tokens:\n            string = '[KB] {} are'.format(i)\n            op = tokenizer1.batch_decode(model1.generate(torch.tensor(tokenizer1.encode(string)).unsqueeze(0).to('cuda'), max_length=14, pad_token_id=tokenizer1.eos_token_id))\n            s = ''\n            for i in op[0]:\n                s += i\n                if i=='.':\n                    break\n            op_preserving_kt.append(s)\n        \n        #print('op preserving ', op_preserving_kt)\n        #print(texts[0],labs_verbalized[0])\n        #print(ids[0])\n        caption = ids[0].split('[CAPTION]')[-1]\n        #print(caption)\n        \n        kb = ''\n        for i in op_preserving_kt:\n            kb+=i+' '\n            \n        #         kb1 += '[CAPTION] '+caption + 'output of the classifier multimodal embedding is '\n\n        #         kb2 = '. The meme text reads :'+tt[0] + '. Classifier thinks the meme is {}'.format(labs_verbalized[0]))\n        \n        #print('****************************')\n    \n        \n        \n        \n        op_preserving_final_tokens = []\n        preservation_scores = []\n        llm_lab = tokenizer1.decode(output2.logits.argmax(dim=-1)[0][-1])\n        #print(llm_lab)\n        for i in op_preserving_kt:\n            kb = i+' '\n            prev_prob = torch.nn.functional.softmax(log_likelihood_, dim=-1)[:,agmx_idx]\n            #print(prev_prob)\n            #break\n            #[:,-1,agmx_idx]\n            is_op_preserved,likelihood = get_performance_test(second_pass=True, llm_label=[kb], prev_lab=llm_lab.strip(), prev_prob=prev_prob, counter=counter)\n            if is_op_preserved:\n                preservation_scores.append(likelihood)\n                op_preserving_final_tokens.append(i)\n            \n                \n        #print('OP PRESERVING FINAL TOKENS ',op_preserving_final_tokens)      \n        #print('PRESERVATION SCORES ',preservation_scores)\n        toks = []\n        for idx in list(reversed(list(np.argsort(preservation_scores))))[:4]:\n            #print(idx)\n            tmp = op_preserving_final_tokens[idx].split('are')[0][4:].strip()\n            toks.append(tmp)\n        \n        #print('OP PRESERVING FINAL TOKENS ',toks)\n        \n        string = ''\n        for i in toks:\n            string+=i+'\\t'\n        \n        #print(string)\n        #print(string.split('\\t'))\n        \n        d_ids[t_id] = string\n        \n        all_labs.append(llm_lab)\n        counter+=1\n        \n        \n    \n        \n        \n    return all_labs, all_labs_clf, grad_, output2.logits[:,-1,:].squeeze(dim=0).detach().cpu(), texts, tmp_id\n\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.836014Z","iopub.status.idle":"2023-09-13T07:27:25.836460Z","shell.execute_reply.started":"2023-09-13T07:27:25.836231Z","shell.execute_reply":"2023-09-13T07:27:25.836253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seed(42)\nal, alc,ti,op,tt,t_id = get_performance_test()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.842840Z","iopub.status.idle":"2023-09-13T07:27:25.843312Z","shell.execute_reply.started":"2023-09-13T07:27:25.843082Z","shell.execute_reply":"2023-09-13T07:27:25.843104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_ids = {}\ndef get_performance_test(second_pass=False, llm_label='', prev_prob = 0, prev_lab = '', counter=0):\n    #print(test_dataset)\n    torch.use_deterministic_algorithms(True)\n    set_seed(42)\n    \n    if second_pass:\n        #print('IN SECOND PASS')\n        test_dataset_ = [test_dataset_1[counter]]\n        \n        \n    else:\n        test_dataset_ = test_dataset_1\n    \n    tinymodel.eval()\n    model1.eval()\n    all_labs = []\n    all_labs_clf = []\n    counter = 0\n    \n    for ii,ti, gol, ids in tqdm(test_dataset_,disable=second_pass):\n\n        #     print(0/0)\n        #print(ids)\n        tmp_id = ids\n        \n        #         raw_image = Image.open('./data/'+ids)\n        #         if not second_pass:\n        #             display(raw_image)\n        ti = ti.unsqueeze(0)\n        ii = ii.unsqueeze(0)\n        gol = [gol]\n        ids = [ids]\n        # print(batch_model1, batch_model1)\n\n        ids = list(map(lambda x: x.split('/')[1], ids))\n        #         ids_ = []\n        #         for i in range(len(ids)):\n        #             kbs = ids[i].split('[KB]')\n        #             caps = ids[i].split('[CAPTION]')[-1]\n        #             try:\n        #                 kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n        #             except IndexError as e:\n        #                 kb = '[CAPTION] '+ caps\n        #             ids_.append(kb)\n        #         ids = ids_\n        \n        ids_ = []\n        for i in range(len(ids)):\n            kbs = ids[i].split('[KB]')\n            #print('kbs ', kbs)\n            caps = ids[i].split('[CAPTION]')[-1]\n            #print(caps)\n            kb = ''\n            if len(kbs)>3:\n                kb = '[KB] '+kbs[1]+'[KB] '+kbs[2] + '[CAPTION] '+ caps\n            elif len(kbs)==3:\n                #print('in len3')\n                kb = '[KB] '+kbs[1]\n                caps = kbs[2].split('[CAPTION]')\n                kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n            elif len(kbs)==2:\n                #print('in len 1')\n                caps = kbs[1].split('[CAPTION]')\n                kb += '[KB] '+ caps[0]+ ' [CAPTION] '+caps[1]\n            elif len(kbs)==1:\n                kb = kbs[0].strip()\n                #print('int ', kb)\n\n\n\n            ids_.append(kb)\n        \n        ids = ids_\n        \n        \n        \n        #         print(ids)\n        texts = [id2text[i] for i in ids]\n        ids = [kb_fb[i] for i in ids]\n        if second_pass:\n            ids = llm_label\n        #print('ids', ids)\n        #print('text', texts)\n\n        #     prpmt = []\n        #     for i,j in zip(ids,texts):\n        #         prpmt.append(i+'. The meme text reads :'+j + '. Classifier thinks the meme is')\n\n\n\n        i = ii.float().to(device)\n        t = ti.float().to(device)\n        batch_size = i.shape[0]\n        #with torch.no_grad():\n        logits, m = tinymodel(i,t)\n        # print(m)\n        m = m.unsqueeze(dim=1)\n        all_labs_clf.append(logits.argmax(dim=-1)[0].item())\n        #         prmpt0, lab0 = get_tokens([tokenizer1.bos_token]*batch_size, begin=True)\n\n        #         print(prmpt0.shape)\n\n        gumbel_logits = F.gumbel_softmax(logits, tau=1, hard=True)\n        # print(gumbel_logits)\n        agmx = gumbel_logits.argmax(dim=1)\n\n        # print(agmx, logits.argmax(dim=1))\n        #         prpmt = ['model thinks the meme is ']*batch_size\n\n        #portion1,lab1, a1 = get_tokens(prpmt)\n\n        portion2,lab3, _ = get_tokens(['output of the classifier multimodal embedding is ']*batch_size)\n        lab4 = [tokenizer1.encode('-')[:] for i in range(batch_size)]\n        lab4 = torch.tensor(lab4)\n\n        # portion3 = get_tokens(['the meme is actually'])\n\n\n\n\n\n\n        kk = []\n        labs_verbalized = []\n        # batch_prompt = ['the model thinks the meme is ']*32\n        lab2 = []\n        for i in gumbel_logits:\n            agmx = i.argmax()\n            # print(agmx)\n            # print(dix[agmx.item()])\n            tokenized_ = tokenizer1.encode(dix[agmx.item()])[:]\n            labs_verbalized.append(dix[agmx.item()])\n            # print(tokenized_)\n            lab2.append(tokenized_)\n            embedding = E[tokenized_[0]]\n            one_hot = i.view(-1, 1)\n            # print(embedding.shape, one_hot, one_hot.shape)\n\n            e = torch.sum(one_hot*embedding.to(device), dim=0)\n            kk.append(e)\n        lab2 = torch.tensor(lab2)\n        prpmt = []\n        for i,j,z in zip(ids,texts,labs_verbalized):\n            prpmt.append(i+'. The meme text reads :'+j + '. Classifier thinks the meme is {}'.format(z))\n            #all_labs_clf.append(z)\n        portion1,lab1, a1 = get_tokens(prpmt)\n        \n        string = ['the meme is actually']\n        #         if second_pass:\n        #             string[0] += '{} because of'.format(llm_label)\n        #             print(string)\n        portion3,lab5,_ = get_tokens(string)\n        inp_embed = torch.stack(kk).unsqueeze(dim=1)\n        # print(inp_embed)\n        # print(inp_embed.shape)\n        # print(portion1.shape,inp_embed.shape,portion2.shape,m.shape,portion3.shape)\n\n        final_embeds = torch.cat((portion1,inp_embed,portion2,m,portion3),dim=1)\n        # print(final_embeds.shape)\n        # print(lab1.shape, lab2.shape, lab3.shape, lab4.shape, lab5.shape)\n        labs_shape = torch.cat((lab2,lab3,lab4,lab5),dim=1).shape\n        remaining_mask = torch.ones(labs_shape[0], labs_shape[1]).long()\n        #print(a1)\n        #print(remaining_mask)\n\n        full_mask = torch.cat((a1,remaining_mask),dim=1)\n        #print('fm ', full_mask.shape)\n        labs = torch.cat((lab1,lab2,lab3,lab4,lab5),dim=1)\n        #print(full_mask)\n        #print(0/0)\n        #         print(final_embeds.shape, labs.shape)\n        #         print(0/0)\n        #with torch.no_grad():\n        if second_pass:\n            #model1.prepare_inputs_for_generation = prepare_inputs_for_generation\n            #input_ids = torch.LongTensor([[model1.config.bos_token_id]]).to(device)\n            #inputs_embdes = final_embeds.float().to(device)\n            #op = model1.sample(input_ids, inputs_embeds = inputs_embdes, pad_token_id=model1.config.eos_token_id)\n            #print(tokenizer1.batch_decode(op))\n            output2 = model1(inputs_embeds = final_embeds.float(), labels = labs.long(), attention_mask=full_mask.to('cuda'))\n            #print('SECOND PASS ',tokenizer1.batch_decode(output2.logits[:,-1,:].squeeze(dim=0).detach().cpu().topk(40).indices))\n            second_pass_lab = tokenizer1.batch_decode(output2.logits[:,-1,:].squeeze(dim=0).detach().cpu().topk(40).indices)[0].strip()\n            #print('pl', prev_lab)\n            #print('sl', second_pass_lab)\n            agmx_id = output2.logits.argmax(dim=-1)[0][-1].item()\n            log_likelihood = output2.logits[:,-1,:]\n            log_likelihood = torch.nn.functional.softmax(log_likelihood, dim=-1)[:,agmx_id][0].item()\n            prev_prob = prev_prob[0].item()\n            #print('current probability', log_likelihood)\n            #print('previous probability', prev_prob)\n            #             if (prev_lab==second_pass_lab) and (log_likelihood>=prev_prob):\n            #if (prev_lab==second_pass_lab) and (abs(log_likelihood-prev_prob)<=0.05):\n            #    return True\n            \n            if prev_lab==second_pass_lab:\n                return True, log_likelihood\n            \n            else:\n                return False, False\n            \n            \n                                                      \n        else:\n            output2 = model1(inputs_embeds = final_embeds.float(), labels = labs.long(), attention_mask=full_mask.to('cuda'))\n        # print(output2.loss)\n        # print(0/0)\n        loss_lm = output2.loss\n        #print(tokenizer1.batch_decode(output2.logits.argmax(dim=-1)))\n\n        #print(loss_lm)\n        m.retain_grad()\n        model1.transformer.wte.weight.retain_grad()\n        #print(output2.logits.shape)\n        #print(output2.logits.argmax(dim=-1)[0].shape)\n        agmx_idx = output2.logits.argmax(dim=-1)[0][-1].item()\n        #print(agmx_idx)\n        #print(output2.logits[:,-1,:])\n        log_likelihood_ = output2.logits[:,-1,:]\n        log_likelihood = output2.logits[:,-1,agmx_idx]\n        #print(log_likelihood)\n        log_likelihood.backward()\n        grad_  = m.grad.data.cpu().squeeze(1)\n        #embedding_norm = model1.transformer.wte.weight.grad.data.cpu().norm(dim=-1)\n        #print('en ', embedding_norm,embedding_norm.shape)\n        #tokens_index = torch.mm(grad_, E.detach().cpu().T)[0]\n        \n        #tokens_index /= model1.transformer.wte.weight.detach().cpu().norm(dim=-1)\n        #print(tokens_index)\n        #ct_index = tokens_index*output2.logits[:,-1,:].squeeze(dim=0).detach().cpu() # ct_index = cumulative token index\n        \n        #print(tokens_index.topk(40).indices)\n        #print(tokenizer1.batch_decode(embedding_norm.topk(40).indices))\n        #print(tokenizer1.batch_decode(tokens_index.topk(40).indices))\n        #print(tokenizer1.batch_decode(ct_index.topk(40).indices))\n        #print(tokenizer1.batch_decode(output2.logits[:,-1,:].squeeze(dim=0).detach().cpu().topk(40).indices))\n        #print(tokens_index.shape)\n        #print(grad_.shape)\n        ti,op,tt,t_id = grad_, output2.logits[:,-1,:].squeeze(dim=0).detach().cpu(), texts, tmp_id\n        #print('****************************')\n        #print(t_id)\n        #         output_aware_token_idx = []\n        #         output_aware_tokens = []\n        #         cc = 0\n        #         for i in op.topk(50257).indices:\n        #             cc+=1\n        #             k = model1.transformer.wte(i.cuda()).detach().cpu().unsqueeze(1).detach().cpu()\n\n        #             #output_aware_token_idx.append(ti.mm(k))\n        #             val = torch.nn.functional.cosine_similarity(ti.detach().cpu(),k.T)[0].item()\n\n\n\n        #             output_aware_token_idx.append(val)\n        #             output_aware_tokens.append(tokenizer1.decode(i))\n\n            \n       \n            \n        \n        \n        image = preprocess(Image.open('./data/'+t_id)).unsqueeze(0).to(device)\n        \n        full = op.topk(50257).indices\n        \n        \n        ot = []\n        ot_idx = []\n        \n        for i in range(17):\n        \n            \n\n            #for i in tqdm(full[i*0:(i+1)*1000]):\n            output_aware_tokens = tokenizer1.batch_decode(full[i*3000:(i+1)*3000])\n            ot.extend(output_aware_tokens)\n            \n            #print(output_aware_tokens[0:10])\n\n            text = clip.tokenize(output_aware_tokens).to(device)\n\n\n            with torch.no_grad():\n                if_ = model.encode_image(image)\n\n                multimodal_features = if_\n                text_features = model.encode_text(text)\n\n                clip_feats = torch.nn.functional.cosine_similarity(multimodal_features, text_features, dim=1)\n\n\n            clip_feats = clip_feats.cpu().numpy().tolist()\n            #print(clip_feats)\n            ot_idx.extend(clip_feats)\n            #print(0/0)\n        \n        output_aware_tokens = ot\n        clip_feats = ot_idx\n        print(len(output_aware_tokens), len(clip_feats))\n        combined_feats = []\n        \n        for j in clip_feats:\n            #tmp = 2*i*j/(i+j)\n            tmp = 1.0*j\n            #tmp = j\n            combined_feats.append(tmp)\n            \n        final_tokens = []\n        for i in np.argsort(combined_feats)[-1:-20:-1]:\n            final_tokens.append(output_aware_tokens[i])\n            #print(output_aware_tokens[i])\n        \n        final_tokens = list(dict.fromkeys(final_tokens))\n        #final_tokens = list(final_tokens)\n        s = ['when', 'why', 'our']\n        final_tokens = [i for i in final_tokens if (i not in s and len(i)>2)][:20]\n        \n        op_preserving_kt = []\n        \n        for i in final_tokens:\n            string = '[KB] {} are'.format(i)\n            op = tokenizer1.batch_decode(model1.generate(torch.tensor(tokenizer1.encode(string)).unsqueeze(0).to('cuda'), max_length=14, pad_token_id=tokenizer1.eos_token_id))\n            s = ''\n            for i in op[0]:\n                s += i\n                if i=='.':\n                    break\n            op_preserving_kt.append(s)\n        \n        #print('op preserving ', op_preserving_kt)\n        #print(texts[0],labs_verbalized[0])\n        #print(ids[0])\n        caption = ids[0].split('[CAPTION]')[-1]\n        #print(caption)\n        \n        kb = ''\n        for i in op_preserving_kt:\n            kb+=i+' '\n            \n        #         kb1 += '[CAPTION] '+caption + 'output of the classifier multimodal embedding is '\n\n        #         kb2 = '. The meme text reads :'+tt[0] + '. Classifier thinks the meme is {}'.format(labs_verbalized[0]))\n        \n        #print('****************************')\n    \n        \n        \n        \n        op_preserving_final_tokens = []\n        preservation_scores = []\n        llm_lab = tokenizer1.decode(output2.logits.argmax(dim=-1)[0][-1])\n        #print(llm_lab)\n        for i in op_preserving_kt:\n            kb = i+' '\n            prev_prob = torch.nn.functional.softmax(log_likelihood_, dim=-1)[:,agmx_idx]\n            #print(prev_prob)\n            #break\n            #[:,-1,agmx_idx]\n            is_op_preserved,likelihood = get_performance_test(second_pass=True, llm_label=[kb], prev_lab=llm_lab.strip(), prev_prob=prev_prob, counter=counter)\n            if is_op_preserved:\n                preservation_scores.append(likelihood)\n                op_preserving_final_tokens.append(i)\n            \n                \n        #print('OP PRESERVING FINAL TOKENS ',op_preserving_final_tokens)      \n        #print('PRESERVATION SCORES ',preservation_scores)\n        toks = []\n        for idx in list(reversed(list(np.argsort(preservation_scores))))[:4]:\n            #print(idx)\n            tmp = op_preserving_final_tokens[idx].split('are')[0][4:].strip()\n            toks.append(tmp)\n        \n        #print('OP PRESERVING FINAL TOKENS ',toks)\n        \n        string = ''\n        for i in toks:\n            string+=i+'\\t'\n        \n        #print(string)\n        #print(string.split('\\t'))\n        \n        d_ids[t_id] = string\n        \n        all_labs.append(llm_lab)\n        counter+=1\n        \n        \n    \n        \n        \n    return all_labs, all_labs_clf, grad_, output2.logits[:,-1,:].squeeze(dim=0).detach().cpu(), texts, tmp_id\n\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.845431Z","iopub.status.idle":"2023-09-13T07:27:25.845880Z","shell.execute_reply.started":"2023-09-13T07:27:25.845648Z","shell.execute_reply":"2023-09-13T07:27:25.845671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('ok')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.847504Z","iopub.status.idle":"2023-09-13T07:27:25.848343Z","shell.execute_reply.started":"2023-09-13T07:27:25.848108Z","shell.execute_reply":"2023-09-13T07:27:25.848131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seed(42)\nal, alc,ti,op,tt,t_id = get_performance_test()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.850327Z","iopub.status.idle":"2023-09-13T07:27:25.850776Z","shell.execute_reply.started":"2023-09-13T07:27:25.850546Z","shell.execute_reply":"2023-09-13T07:27:25.850568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seed(42)\nal, alc,ti,op,tt,t_id = get_performance_test()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.856833Z","iopub.status.idle":"2023-09-13T07:27:25.857308Z","shell.execute_reply.started":"2023-09-13T07:27:25.857076Z","shell.execute_reply":"2023-09-13T07:27:25.857097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_ids","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.859285Z","iopub.status.idle":"2023-09-13T07:27:25.859735Z","shell.execute_reply.started":"2023-09-13T07:27:25.859502Z","shell.execute_reply":"2023-09-13T07:27:25.859524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_ids","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.861127Z","iopub.status.idle":"2023-09-13T07:27:25.861807Z","shell.execute_reply.started":"2023-09-13T07:27:25.861567Z","shell.execute_reply":"2023-09-13T07:27:25.861593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport pickle\n\n# open a file, where you stored the pickled data\nfile = open('/kaggle/input/extras/iclr_2500_-0.1_0.1_3500ex_on_on.pkl', 'rb')\n\n# dump information to that file\ndata = pickle.load(file)\n\n# close the file\nfile.close()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.864249Z","iopub.status.idle":"2023-09-13T07:27:25.864701Z","shell.execute_reply.started":"2023-09-13T07:27:25.864468Z","shell.execute_reply":"2023-09-13T07:27:25.864492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.866274Z","iopub.status.idle":"2023-09-13T07:27:25.874082Z","shell.execute_reply.started":"2023-09-13T07:27:25.873706Z","shell.execute_reply":"2023-09-13T07:27:25.873742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_image = Image.open('./data/'+'img/39862.png')\ndisplay(raw_image)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.875818Z","iopub.status.idle":"2023-09-13T07:27:25.877209Z","shell.execute_reply.started":"2023-09-13T07:27:25.876840Z","shell.execute_reply":"2023-09-13T07:27:25.876876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_ids","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.878961Z","iopub.status.idle":"2023-09-13T07:27:25.886449Z","shell.execute_reply.started":"2023-09-13T07:27:25.886067Z","shell.execute_reply":"2023-09-13T07:27:25.886104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_ids","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.888270Z","iopub.status.idle":"2023-09-13T07:27:25.889460Z","shell.execute_reply.started":"2023-09-13T07:27:25.889112Z","shell.execute_reply":"2023-09-13T07:27:25.889147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_image = Image.open('./data/'+'img/63784.png')\ndisplay(raw_image)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.891799Z","iopub.status.idle":"2023-09-13T07:27:25.893193Z","shell.execute_reply.started":"2023-09-13T07:27:25.892823Z","shell.execute_reply":"2023-09-13T07:27:25.892859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"al","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.894981Z","iopub.status.idle":"2023-09-13T07:27:25.896355Z","shell.execute_reply.started":"2023-09-13T07:27:25.895995Z","shell.execute_reply":"2023-09-13T07:27:25.896030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_labs = []\nfor i in al:\n    if i.strip()=='normal':\n        all_labs.append(0)\n    else:\n        all_labs.append(1)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.905177Z","iopub.status.idle":"2023-09-13T07:27:25.905989Z","shell.execute_reply.started":"2023-09-13T07:27:25.905634Z","shell.execute_reply":"2023-09-13T07:27:25.905667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_labs","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.908229Z","iopub.status.idle":"2023-09-13T07:27:25.909625Z","shell.execute_reply.started":"2023-09-13T07:27:25.909265Z","shell.execute_reply":"2023-09-13T07:27:25.909300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"al_dict = {}\nfor i,j in zip(d_ids,range(100)):\n    al_dict[i] = all_labs[j]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.911373Z","iopub.status.idle":"2023-09-13T07:27:25.912747Z","shell.execute_reply.started":"2023-09-13T07:27:25.912386Z","shell.execute_reply":"2023-09-13T07:27:25.912421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_ids","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.914505Z","iopub.status.idle":"2023-09-13T07:27:25.922435Z","shell.execute_reply.started":"2023-09-13T07:27:25.922066Z","shell.execute_reply":"2023-09-13T07:27:25.922102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"al_dict","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.924274Z","iopub.status.idle":"2023-09-13T07:27:25.925852Z","shell.execute_reply.started":"2023-09-13T07:27:25.925498Z","shell.execute_reply":"2023-09-13T07:27:25.925534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_ids","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.927659Z","iopub.status.idle":"2023-09-13T07:27:25.929046Z","shell.execute_reply.started":"2023-09-13T07:27:25.928680Z","shell.execute_reply":"2023-09-13T07:27:25.928715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_ids","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.930797Z","iopub.status.idle":"2023-09-13T07:27:25.932187Z","shell.execute_reply.started":"2023-09-13T07:27:25.931820Z","shell.execute_reply":"2023-09-13T07:27:25.931855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\nlist_of_dicts = [d_ids,all_labs]\n\nwith open('iclr_3500_ur_on_on.pkl', 'wb') as f:\n    pickle.dump(list_of_dicts, f)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.935956Z","iopub.status.idle":"2023-09-13T07:27:25.937388Z","shell.execute_reply.started":"2023-09-13T07:27:25.937037Z","shell.execute_reply":"2023-09-13T07:27:25.937073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('iclr_ur_ur_on_on.pkl', 'rb') as f:\n    lod = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.946182Z","iopub.status.idle":"2023-09-13T07:27:25.947605Z","shell.execute_reply.started":"2023-09-13T07:27:25.947246Z","shell.execute_reply":"2023-09-13T07:27:25.947282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lod","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.948812Z","iopub.status.idle":"2023-09-13T07:27:25.949905Z","shell.execute_reply.started":"2023-09-13T07:27:25.949543Z","shell.execute_reply":"2023-09-13T07:27:25.949578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nclass TinyModel_(torch.nn.Module):\n\n    def __init__(self, mdl, mdl_rand, rand=False):\n        super(TinyModel_, self).__init__()\n       \n        self.linear11 = nn.Sequential(nn.Linear(25, 512), nn.ReLU(), nn.Linear(512, 768))\n        \n        self.linear1 = mdl_rand\n        self.activation = torch.nn.ReLU()\n        self.linear2 = torch.nn.Linear(768, 128)\n        self.linear3 = torch.nn.Linear(128, 2)\n        self.rand = rand\n        self.softmax = torch.nn.Softmax()\n        self.proj = torch.nn.Linear(512,768)\n        # self.proj = torch.nn.Linear(512,5120)\n\n    def forward(self, x, y, z,p=0,train=True, no_exp=False, only_exp=False, all_exp=False):\n        joint_tensor = torch.cat((x, y), dim=1)\n        z = self.activation(z)\n        if self.rand:\n            m_ = self.linear1(joint_tensor)\n        else:\n            x = x.unsqueeze(1)\n            y = y.unsqueeze(1)\n            m_ = self.linear1(x, y).squeeze(dim=1)\n            \n        \n        m_ = self.activation(m_)\n        if train:\n            #print(p)\n            a1,a2,a3 = [],[],[]\n            for i in p:\n                if i==0:\n                    a1.append(1)\n                    a2.append(0)\n                    #a3.append(0)\n                elif i==1:\n                    a1.append(0)\n                    a2.append(1)\n                    #a3.append(0)\n                #                 elif i==2:\n                #                     a1.append(0)\n                #                     a2.append(0)\n                #                     a3.append(1)\n            #print('a1',a1)\n            #print('proj', self.proj(m_.to(dtype=torch.float32)))\n            \n            a1 = torch.tensor(a1).view(-1,1).to(device)\n            a2 = torch.tensor(a2).view(-1,1).to(device)\n            #a3 = torch.tensor(a3).view(-1,1).to(device)\n            #print(a1*self.proj(m_.to(dtype=torch.float32)))\n            #m = a1*self.proj(m_.to(dtype=torch.float32)) + a2*self.linear11(z.to(dtype=torch.float32)) + a3*(self.proj(m_.to(dtype=torch.float32))+self.linear11(z.to(dtype=torch.float32)))\n            #m = a1*self.proj(m_.to(dtype=torch.float32)) + a2*self.linear11(z.to(dtype=torch.float32)) \n            m = (self.proj(m_.to(dtype=torch.float32))*self.linear11(z.to(dtype=torch.float32)))\n        if not train:\n            if no_exp:\n                #print('a')\n                m = self.proj(m_.to(dtype=torch.float32))\n                \n            if only_exp:\n                #print('b')\n                m = self.linear11(z.to(dtype=torch.float32))\n\n            if all_exp:\n                #print('c')\n                m = (self.proj(m_.to(dtype=torch.float32))*self.linear11(z.to(dtype=torch.float32)))\n\n        m = self.linear3(self.linear2(m))\n        # m = self.softmax(m)\n        return m, m_\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.952508Z","iopub.status.idle":"2023-09-13T07:27:25.953895Z","shell.execute_reply.started":"2023-09-13T07:27:25.953545Z","shell.execute_reply":"2023-09-13T07:27:25.953581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.955669Z","iopub.status.idle":"2023-09-13T07:27:25.962359Z","shell.execute_reply.started":"2023-09-13T07:27:25.961855Z","shell.execute_reply":"2023-09-13T07:27:25.961890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !gdown https://drive.google.com/u/0/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.964448Z","iopub.status.idle":"2023-09-13T07:27:25.965871Z","shell.execute_reply.started":"2023-09-13T07:27:25.965519Z","shell.execute_reply":"2023-09-13T07:27:25.965554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gensim.downloader as api\n\nglove_vectors = api.load('glove-twitter-25')","metadata":{"execution":{"iopub.status.busy":"2023-09-27T16:41:18.839268Z","iopub.execute_input":"2023-09-27T16:41:18.839665Z","iopub.status.idle":"2023-09-27T16:42:02.992629Z","shell.execute_reply.started":"2023-09-27T16:41:18.839633Z","shell.execute_reply":"2023-09-27T16:42:02.991572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('ok')","metadata":{"execution":{"iopub.status.busy":"2023-09-27T16:42:13.294219Z","iopub.execute_input":"2023-09-27T16:42:13.294593Z","iopub.status.idle":"2023-09-27T16:42:13.300406Z","shell.execute_reply.started":"2023-09-27T16:42:13.294565Z","shell.execute_reply":"2023-09-27T16:42:13.299316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a,b = 0,0\np = []\nc\n    p.append(k\n    if k==0:\n        a+=1\n    elif k==1:\n        b+=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"va,b = 0,0\n\nrandom.seed(123)\nk = random.randint(0,1)\nk","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.983143Z","iopub.status.idle":"2023-09-13T07:27:25.984531Z","shell.execute_reply.started":"2023-09-13T07:27:25.984167Z","shell.execute_reply":"2023-09-13T07:27:25.984202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.986303Z","iopub.status.idle":"2023-09-13T07:27:25.994435Z","shell.execute_reply.started":"2023-09-13T07:27:25.994068Z","shell.execute_reply":"2023-09-13T07:27:25.994104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataloader_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:25.996223Z","iopub.status.idle":"2023-09-13T07:27:25.997584Z","shell.execute_reply.started":"2023-09-13T07:27:25.997229Z","shell.execute_reply":"2023-09-13T07:27:25.997263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.listdir('/kaggle/input/tensors-models')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.003018Z","iopub.status.idle":"2023-09-13T07:27:26.004072Z","shell.execute_reply.started":"2023-09-13T07:27:26.003763Z","shell.execute_reply":"2023-09-13T07:27:26.003797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seed(42)\nrnd = np.random.randn(25)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.005438Z","iopub.status.idle":"2023-09-13T07:27:26.006189Z","shell.execute_reply.started":"2023-09-13T07:27:26.005936Z","shell.execute_reply":"2023-09-13T07:27:26.005973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rnd","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.007615Z","iopub.status.idle":"2023-09-13T07:27:26.008366Z","shell.execute_reply.started":"2023-09-13T07:27:26.008126Z","shell.execute_reply":"2023-09-13T07:27:26.008148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n#os.environ['CUBLAS_WORKSPACE_CONFIG']=:4096:8\n#/kaggle/input/extras/iclr_2500_-0.1_0.1_on_on.pkl\n\nfor i in os.listdir('/kaggle/input/tensors-models'):\n    print(i)\n    with open('/kaggle/input/tensors-models/'+i, 'rb') as f:\n        lod = pickle.load(f)\n    test_dataset = torch.utils.data.Subset(test_dataset_1, [i for i in range(71,100)])\n    d_ids = lod[0]\n    all_labs = lod[1]\n    torch.use_deterministic_algorithms(True)\n    mean = []\n    std = []\n    for i in range(10):\n        set_seed(i*13)\n        p = []\n        for i in range(100):\n            p.append(random.randint(0,1))\n        import numpy as np\n\n        mdl_rand = fusion(512,512,True,256,512,0.1).to(device)\n        tinymodel_ = TinyModel_(mdl,mdl_rand,rand=False).to(device)\n\n\n        optimizer = optim.Adam(tinymodel_.parameters(), lr=0.0005)\n\n        dix = {0:'normal', 1:'offensive'}\n\n        tinymodel_.train()\n\n        # Training loop\n        num_epochs = 30\n        def transpose(x):\n            return x.transpose(-2, -1)\n\n        for epoch in tqdm(range(num_epochs)):\n            #     set_seed(42)\n            l=0\n            cnt = 0\n            l_lm = 0\n            l_clf = 0\n            counter = 0\n            for ii,ti, gol, ids in dataloader_test:\n                # print(batch_model1, batch_model1)\n\n                #         print(ii.shape)\n                #         print(ti.shape)\n                #         print(gol)\n                #         print(ids)\n\n                explanations = []\n                gold_label = []\n                for id_ in ids:\n                    gold_label.append(al_dict[id_])\n\n                gold_label = torch.tensor(gold_label)\n\n\n\n\n\n\n\n\n                #ids = list(map(lambda x: x.split('/')[1], ids))\n                #         print(ids)\n\n\n                we = []\n\n                for id_ in ids: \n                    tokens = [i for i in d_ids[id_].split('\\t') if i!='']\n                    #print(tokens)\n\n                    word_embeddings = []\n\n                    for token in tokens:\n                        if token in glove_vectors.index_to_key:\n                            word_embeddings.append(glove_vectors[token])\n\n                    # Calculate the average embedding\n                    if word_embeddings:\n                        avg_embedding = np.mean(word_embeddings, axis=0)\n                    else:\n                        # Handle the case where none of the words were found in the vocabulary\n                        avg_embedding = rnd  # You can use a zero vector or other defaults\n\n                    we.append(avg_embedding)\n\n                we = np.asarray(we)\n\n\n                #print(we.shape)\n\n\n\n\n\n                i = ii.float().to(device)\n                t = ti.float().to(device)\n                #print(counter)\n                batch_size = i.shape[0]\n                indices = p[counter*batch_size:(counter+1)*batch_size]\n                #print(indices)\n\n                optimizer.zero_grad()\n\n                logits, m = tinymodel_(i,t, torch.tensor(we).to(device),p=indices, train=True)\n\n                #print(0/0)\n\n\n\n                #print(logits)\n\n                gol = torch.tensor(all_labs[counter*batch_size:(counter+1)*batch_size])\n                loss_clf = torch.nn.functional.cross_entropy(logits, gold_label.to(device), reduction='mean')\n\n\n\n                loss_clf.backward()\n                optimizer.step()\n\n\n\n\n                l_clf+=loss_clf.detach().item()\n\n                cnt+=1\n                counter+=1\n            #if epoch%5==0:\n            #print(f\"Epoch [{epoch+1}/{num_epochs}], Loss clf: {l_clf/cnt}\")\n\n\n\n        print(\"Training complete!\")\n        leakage = []\n        non_leakage = []\n        global_dict = {}\n        tinymodel_.eval()\n        counter=0\n        for ii,ti, gol, ids in tqdm(test_dataset):\n            we = []\n            ii = ii.unsqueeze(dim=0)\n            ti = ti.unsqueeze(dim=0)\n            gol = [al_dict[ids]]\n            ids = [ids]\n\n            for id_ in ids: \n                tokens = [i for i in d_ids[id_].split('\\t') if i!='']\n                #print(tokens)\n\n                word_embeddings = []\n\n                for token in tokens:\n                    if token in glove_vectors.index_to_key:\n                        word_embeddings.append(glove_vectors[token])\n\n                # Calculate the average embedding\n                if word_embeddings:\n                    avg_embedding = np.mean(word_embeddings, axis=0)\n                else:\n                    # Handle the case where none of the words were found in the vocabulary\n                    avg_embedding = np.zeros(25)  # You can use a zero vector or other defaults\n\n                we.append(avg_embedding)\n\n            we = np.asarray(we)\n\n\n            #print(we.shape)\n\n\n\n\n\n            i = ii.float().to(device)\n            t = ti.float().to(device)\n\n\n            batch_size = i.shape[0]\n            optimizer.zero_grad()\n\n            logits, m = tinymodel_(i,t, torch.tensor(we).to(device), train=False, all_exp=True)\n            logits_no_exp,_ = tinymodel_(i,t, torch.tensor(we).to(device), train=False, no_exp=True)\n            logits_only_exp,_ = tinymodel_(i,t, torch.tensor(we).to(device), train=False,only_exp=True)\n\n\n\n            #print(gol)\n            #print(logits_only_exp.argmax(dim=-1).item(), logits.argmax(dim=-1).item(), logits_no_exp.argmax(dim=-1).item())\n\n            if gol[0]==logits_only_exp.argmax(dim=-1).item():\n                leakage.append(ids[0])\n            elif gol[0]!=logits_only_exp.argmax(dim=-1).item():\n                non_leakage.append(ids[0]) \n\n            l = int(gol[0]==logits.argmax(dim=-1).item()) - int(gol[0]==logits_no_exp.argmax(dim=-1).item())\n\n            global_dict[ids[0]] = l\n            counter+=1\n\n\n            #print(0/0)\n        l1,l2 = 0,0\n        for i in leakage:\n            l1+=global_dict[i]\n        l1 = l1/len(leakage)\n\n        for i in non_leakage:\n            l2+=global_dict[i]\n        l2 = l2/len(non_leakage)\n\n        print(l1,l2,len(leakage),len(non_leakage),0.5*l1+0.5*l2)\n        mean.append(0.5*l1+0.5*l2)\n    \n    print(np.mean(mean), np.std(mean))\n\n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.009834Z","iopub.status.idle":"2023-09-13T07:27:26.010613Z","shell.execute_reply.started":"2023-09-13T07:27:26.010358Z","shell.execute_reply":"2023-09-13T07:27:26.010381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n#os.environ['CUBLAS_WORKSPACE_CONFIG']=:4096:8\n#/kaggle/input/extras/iclr_2500_-0.1_0.1_on_on.pkl\n\nfor i in os.listdir('/kaggle/input/extras'):\n    print(i)\n    with open('/kaggle/input/extras/'+i, 'rb') as f:\n        lod = pickle.load(f)\n    test_dataset = torch.utils.data.Subset(test_dataset_1, [i for i in range(71,100)])\n    d_ids = lod[0]\n    all_labs = lod[1]\n    torch.use_deterministic_algorithms(True)\n    mean = []\n    std = []\n    for i in range(10):\n        set_seed(i*13)\n        p = []\n        for i in range(100):\n            p.append(random.randint(0,1))\n        import numpy as np\n\n        mdl_rand = fusion(512,512,True,256,512,0.1).to(device)\n        tinymodel_ = TinyModel_(mdl,mdl_rand,rand=False).to(device)\n\n\n        optimizer = optim.Adam(tinymodel_.parameters(), lr=0.0005)\n\n        dix = {0:'normal', 1:'offensive'}\n\n        tinymodel_.train()\n\n        # Training loop\n        num_epochs = 30\n        def transpose(x):\n            return x.transpose(-2, -1)\n\n        for epoch in tqdm(range(num_epochs)):\n            #     set_seed(42)\n            l=0\n            cnt = 0\n            l_lm = 0\n            l_clf = 0\n            counter = 0\n            for ii,ti, gol, ids in dataloader_test:\n                # print(batch_model1, batch_model1)\n\n                #         print(ii.shape)\n                #         print(ti.shape)\n                #         print(gol)\n                #         print(ids)\n\n                explanations = []\n                gold_label = []\n                for id_ in ids:\n                    gold_label.append(al_dict[id_])\n\n                gold_label = torch.tensor(gold_label)\n\n\n\n\n\n\n\n\n                #ids = list(map(lambda x: x.split('/')[1], ids))\n                #         print(ids)\n\n\n                we = []\n\n                for id_ in ids: \n                    tokens = [i for i in d_ids[id_].split('\\t') if i!='']\n                    #print(tokens)\n\n                    word_embeddings = []\n\n                    for token in tokens:\n                        if token in glove_vectors.index_to_key:\n                            word_embeddings.append(glove_vectors[token])\n\n                    # Calculate the average embedding\n                    if word_embeddings:\n                        avg_embedding = np.mean(word_embeddings, axis=0)\n                    else:\n                        # Handle the case where none of the words were found in the vocabulary\n                        avg_embedding = rnd  # You can use a zero vector or other defaults\n\n                    we.append(avg_embedding)\n\n                we = np.asarray(we)\n\n\n                #print(we.shape)\n\n\n\n\n\n                i = ii.float().to(device)\n                t = ti.float().to(device)\n                #print(counter)\n                batch_size = i.shape[0]\n                indices = p[counter*batch_size:(counter+1)*batch_size]\n                #print(indices)\n\n                optimizer.zero_grad()\n\n                logits, m = tinymodel_(i,t, torch.tensor(we).to(device),p=indices, train=True)\n\n                #print(0/0)\n\n\n\n                #print(logits)\n\n                gol = torch.tensor(all_labs[counter*batch_size:(counter+1)*batch_size])\n                loss_clf = torch.nn.functional.cross_entropy(logits, gold_label.to(device), reduction='mean')\n\n\n\n                loss_clf.backward()\n                optimizer.step()\n\n\n\n\n                l_clf+=loss_clf.detach().item()\n\n                cnt+=1\n                counter+=1\n            #if epoch%5==0:\n            #print(f\"Epoch [{epoch+1}/{num_epochs}], Loss clf: {l_clf/cnt}\")\n\n\n\n        print(\"Training complete!\")\n        leakage = []\n        non_leakage = []\n        global_dict = {}\n        tinymodel_.eval()\n        counter=0\n        for ii,ti, gol, ids in tqdm(test_dataset):\n            we = []\n            ii = ii.unsqueeze(dim=0)\n            ti = ti.unsqueeze(dim=0)\n            gol = [al_dict[ids]]\n            ids = [ids]\n\n            for id_ in ids: \n                tokens = [i for i in d_ids[id_].split('\\t') if i!='']\n                #print(tokens)\n\n                word_embeddings = []\n\n                for token in tokens:\n                    if token in glove_vectors.index_to_key:\n                        word_embeddings.append(glove_vectors[token])\n\n                # Calculate the average embedding\n                if word_embeddings:\n                    avg_embedding = np.mean(word_embeddings, axis=0)\n                else:\n                    # Handle the case where none of the words were found in the vocabulary\n                    avg_embedding = np.zeros(25)  # You can use a zero vector or other defaults\n\n                we.append(avg_embedding)\n\n            we = np.asarray(we)\n\n\n            #print(we.shape)\n\n\n\n\n\n            i = ii.float().to(device)\n            t = ti.float().to(device)\n\n\n            batch_size = i.shape[0]\n            optimizer.zero_grad()\n\n            logits, m = tinymodel_(i,t, torch.tensor(we).to(device), train=False, all_exp=True)\n            logits_no_exp,_ = tinymodel_(i,t, torch.tensor(we).to(device), train=False, no_exp=True)\n            logits_only_exp,_ = tinymodel_(i,t, torch.tensor(we).to(device), train=False,only_exp=True)\n\n\n\n            #print(gol)\n            #print(logits_only_exp.argmax(dim=-1).item(), logits.argmax(dim=-1).item(), logits_no_exp.argmax(dim=-1).item())\n\n            if gol[0]==logits_only_exp.argmax(dim=-1).item():\n                leakage.append(ids[0])\n            elif gol[0]!=logits_only_exp.argmax(dim=-1).item():\n                non_leakage.append(ids[0]) \n\n            l = int(gol[0]==logits.argmax(dim=-1).item()) - int(gol[0]==logits_no_exp.argmax(dim=-1).item())\n\n            global_dict[ids[0]] = l\n            counter+=1\n\n\n            #print(0/0)\n        l1,l2 = 0,0\n        for i in leakage:\n            l1+=global_dict[i]\n        l1 = l1/len(leakage)\n\n        for i in non_leakage:\n            l2+=global_dict[i]\n        l2 = l2/len(non_leakage)\n\n        print(l1,l2,len(leakage),len(non_leakage),0.5*l1+0.5*l2)\n        mean.append(0.5*l1+0.5*l2)\n    \n    print(np.mean(mean), np.std(mean))\n\n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.012650Z","iopub.status.idle":"2023-09-13T07:27:26.013780Z","shell.execute_reply.started":"2023-09-13T07:27:26.013417Z","shell.execute_reply":"2023-09-13T07:27:26.013452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in 'republican\\tdemocratic\\tpolitician\\tliberal\\t'.split('\\t')[:-1]:\n    print(glove_vectors[i])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.015977Z","iopub.status.idle":"2023-09-13T07:27:26.017080Z","shell.execute_reply.started":"2023-09-13T07:27:26.016720Z","shell.execute_reply":"2023-09-13T07:27:26.016754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in test_dataset_1:\n    print(i[2])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.018743Z","iopub.status.idle":"2023-09-13T07:27:26.019508Z","shell.execute_reply.started":"2023-09-13T07:27:26.019259Z","shell.execute_reply":"2023-09-13T07:27:26.019282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nset_seed(42)\nrnd = np.random.randn(25)\ndef get_repr(i):\n    tokens = i.split('\\t')[:-1] if i!='' else ['']\n    #print(tokens)\n\n    word_embeddings = []\n\n    for token in tokens:\n        if token in glove_vectors.index_to_key:\n            word_embeddings.append(glove_vectors[token])\n    print(word_embeddings)\n    # Calculate the average embedding\n    if word_embeddings:\n        avg_embedding = np.mean(word_embeddings, axis=0)\n    else:\n        avg_embedding = rnd\n        \n    return avg_embedding\n    \nfor i in os.listdir('/kaggle/input/full-ops'):\n    print(i)\n    with open('/kaggle/input/full-ops/'+i, 'rb') as f:\n        lod = pickle.load(f)\n        y = lod[1]\n        k = []\n        p = []\n        for i in test_dataset:\n            k.append(get_repr(lod[0][i[3]]))\n            a,b= i[0],i[1]\n            p.append(np.concatenate([a,b],axis=-1))\n\n    k = np.asarray(k)\n    p = np.asarray(p)\n    \n    X = np.concatenate([k,p],axis=-1) # inp w/ clip representation w/ exp\n    X_ = p # inp w/ clip representation w/o exp\n    X__ = k # inp w/o clip representation w/ exp\n    \n    from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n    from sklearn import svm\n    from sklearn.neural_network import MLPClassifier\n    from sklearn.ensemble import GradientBoostingClassifier\n    #clf = svm.SVC(kernel='poly', C=2, random_state=42)\n    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n    kf = KFold(n_splits=5)\n    y = np.array(y)\n    vals = []\n    for train, test in kf.split(X):\n        \n        X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n        X_train_, X_test_, y_train, y_test = X_[train], X_[test], y[train], y[test]\n        X_train__, X_test__, y_train, y_test = X__[train], X__[test], y[train], y[test]\n        \n        \n        clf1 = make_pipeline(StandardScaler(),GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0))\n        clf1.fit(X_train, y_train)\n        y_pred = clf1.predict(X_test)\n        \n        clf2 = make_pipeline(StandardScaler(),GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0))\n        clf2.fit(X_train_, y_train)\n        y_pred_ = clf2.predict(X_test_)\n        \n        clf3 = make_pipeline(StandardScaler(), GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0))\n        clf3.fit(X_train__, y_train)\n        y_pred__ = clf3.predict(X_test__)\n        \n        l, nl = 0,0\n        \n        for i ,j in zip(y_pred__,y_test):\n            if i==j:\n                l+=1\n            else:\n                nl+=1\n        a,b=0,0\n        for i,j,k,x in zip(y_pred,y_pred_,y_test,y_pred__):\n            if k==x:\n                a += int(i==k) - int(j==k)\n            elif k!=x:\n                b += int(i==k) - int(j==k)\n        \n        print(.5*(a/l)+.5*(b/nl))\n        vals.append(.5*(a/l)+.5*(b/nl))\n    print('mean ', np.mean(vals), 'std ', np.std(vals))\n    \n            \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n    #     y_pred = cross_val_predict(clf, X, y, cv=3)\n    #     y_pred_ = cross_val_predict(clf, X_, y, cv=3)\n    #     y_pred__ = cross_val_predict(clf, X__, y, cv=3)\n\n    #     print(y_pred)\n    #     print(y_pred.shape)\n\n    #     print(y_pred_)\n    #     print(y_pred_.shape)\n\n    #     print(0/0)\n    \n    \n    \n\n        ","metadata":{"execution":{"iopub.status.busy":"2023-09-20T11:08:29.633300Z","iopub.execute_input":"2023-09-20T11:08:29.633652Z","iopub.status.idle":"2023-09-20T11:08:31.222663Z","shell.execute_reply.started":"2023-09-20T11:08:29.633620Z","shell.execute_reply":"2023-09-20T11:08:31.219610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle","metadata":{"execution":{"iopub.status.busy":"2023-09-22T18:01:47.546845Z","iopub.execute_input":"2023-09-22T18:01:47.547262Z","iopub.status.idle":"2023-09-22T18:01:47.553230Z","shell.execute_reply.started":"2023-09-22T18:01:47.547228Z","shell.execute_reply":"2023-09-22T18:01:47.551159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files = ['/kaggle/input/full-ops/iclr_3500_-0.10.1_on_on.pkl', '/kaggle/input/full-ops/iclr_ur_0.01_ball_on_on.pkl', '/kaggle/input/full-ops/iclr_baseline_ig.pkl', '/kaggle/input/full-ops/iclr_ur_ur_on_on.pkl']","metadata":{"execution":{"iopub.status.busy":"2023-09-22T18:01:48.381843Z","iopub.execute_input":"2023-09-22T18:01:48.382203Z","iopub.status.idle":"2023-09-22T18:01:48.387095Z","shell.execute_reply.started":"2023-09-22T18:01:48.382172Z","shell.execute_reply":"2023-09-22T18:01:48.386018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nrandom.seed(420)\nk = random.sample([i for i in range(1700)], 900)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T17:56:42.574662Z","iopub.execute_input":"2023-09-20T17:56:42.575017Z","iopub.status.idle":"2023-09-20T17:56:42.582094Z","shell.execute_reply.started":"2023-09-20T17:56:42.574986Z","shell.execute_reply":"2023-09-20T17:56:42.580785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nkk = {}\nfor file in files:\n    print(file)\n    ids_ = []\n    kk[file] = []\n    with open(file, 'rb') as f:\n        lod = pickle.load(f)\n        dic = lod[0]\n        #         print(dic)\n        #         break\n        counter = 0\n        for i,lo in zip(dic,lod[1]):\n            \n            ids_.append(i)\n            kk[file].append(dic[i])\n\n            pred = lo\n            #act = id2text[i[4:]]\n            #print(i)\n            #break\n            if str(i)=='img/91768.png':\n                print(i, dic[i])\n                break\n                    \n            counter+=1\n            \n         \n    print('**')\n            ","metadata":{"execution":{"iopub.status.busy":"2023-09-20T18:30:46.195624Z","iopub.execute_input":"2023-09-20T18:30:46.195989Z","iopub.status.idle":"2023-09-20T18:30:46.213598Z","shell.execute_reply.started":"2023-09-20T18:30:46.195960Z","shell.execute_reply":"2023-09-20T18:30:46.212607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nkk = {}\nfor file in files:\n    print(file)\n    ids_ = []\n    kk[file] = []\n    with open(file, 'rb') as f:\n        lod = pickle.load(f)\n        dic = lod[0]\n        counter = 0\n        for i,lo in zip(dic,lod[1]):\n            if counter in k:\n                ids_.append(i)\n                kk[file].append(dic[i])\n                \n                pred = lo\n                act = id2text[i[4:]]\n                \n                if pred==0 and act==0:\n                    print(i, dic[i])\n                    print(pred,act) #1,0\n                    \n            counter+=1\n            if counter==700:\n                break\n         \n    print('**')\n            ","metadata":{"execution":{"iopub.status.busy":"2023-09-20T13:13:28.294490Z","iopub.execute_input":"2023-09-20T13:13:28.294875Z","iopub.status.idle":"2023-09-20T13:13:28.345415Z","shell.execute_reply.started":"2023-09-20T13:13:28.294846Z","shell.execute_reply":"2023-09-20T13:13:28.344556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k = ['img/52978.png', 'img/28197.png']\nfor i,j in zip(lod[0],lod[1]):\n    if i in k:\n        print(i,j)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T11:59:59.331121Z","iopub.execute_input":"2023-09-20T11:59:59.331489Z","iopub.status.idle":"2023-09-20T11:59:59.338295Z","shell.execute_reply.started":"2023-09-20T11:59:59.331458Z","shell.execute_reply":"2023-09-20T11:59:59.337240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.DataFrame(kk)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T09:30:46.010705Z","iopub.execute_input":"2023-09-20T09:30:46.011101Z","iopub.status.idle":"2023-09-20T09:30:46.016907Z","shell.execute_reply.started":"2023-09-20T09:30:46.011070Z","shell.execute_reply":"2023-09-20T09:30:46.015841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T09:30:46.544010Z","iopub.execute_input":"2023-09-20T09:30:46.544367Z","iopub.status.idle":"2023-09-20T09:30:46.558285Z","shell.execute_reply.started":"2023-09-20T09:30:46.544338Z","shell.execute_reply":"2023-09-20T09:30:46.557089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('human_eval.csv', sep=',')","metadata":{"execution":{"iopub.status.busy":"2023-09-20T09:31:23.474829Z","iopub.execute_input":"2023-09-20T09:31:23.475205Z","iopub.status.idle":"2023-09-20T09:31:23.482886Z","shell.execute_reply.started":"2023-09-20T09:31:23.475176Z","shell.execute_reply":"2023-09-20T09:31:23.481789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.listdir('/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2023-09-20T09:03:45.646927Z","iopub.execute_input":"2023-09-20T09:03:45.647324Z","iopub.status.idle":"2023-09-20T09:03:45.655071Z","shell.execute_reply.started":"2023-09-20T09:03:45.647295Z","shell.execute_reply":"2023-09-20T09:03:45.653868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/working/human_eval.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-20T09:07:28.970109Z","iopub.execute_input":"2023-09-20T09:07:28.970472Z","iopub.status.idle":"2023-09-20T09:07:28.979999Z","shell.execute_reply.started":"2023-09-20T09:07:28.970443Z","shell.execute_reply":"2023-09-20T09:07:28.979027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T09:07:34.452899Z","iopub.execute_input":"2023-09-20T09:07:34.453591Z","iopub.status.idle":"2023-09-20T09:07:34.466684Z","shell.execute_reply.started":"2023-09-20T09:07:34.453556Z","shell.execute_reply":"2023-09-20T09:07:34.465417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import *\nfrom scipy.spatial import distance\nimport pickle\nset_seed(42)\nrnd = np.random.randn(25)\n\n#loc = ['iclr_baseline_ig.pkl', 'iclr_baseline_ixg.pkl', 'iclr_baseline_ks.pkl', 'iclr_baseline_saliency.pkl', 'iclr_500_ur_on_on.pkl']\n\n#loc = ['iclr_2500_0.1_on_off.pkl', 'iclr_500_0.1_on_off.pkl', 'iclr_3500_ball_0.1_on_off.pkl', 'iclr_1500_0.1_on_off.pkl', 'iclr_2500_-0.10.1_on_on.pkl', 'iclr_500_ball_0.1_on_on.pkl', 'iclr_3500_ball_-0.10.1_on_on.pkl', 'iclr_1500_ball_0.1_on_on.pkl']\nloc = ['iclr_3500_ball_0.1_on_off.pkl',  'iclr_3500_-0.10.1_on_on.pkl']\n\ndef get_repr(i,CNT):\n    tokens = i.split('\\t')[:-1] if i!='' else ['']\n    #print(tokens)\n\n    word_embeddings = []\n    intra_dist = []\n    for token in tokens:\n        if token in glove_vectors.index_to_key:\n            word_embeddings.append(glove_vectors[token])\n    \n    # Calculate the average embedding\n    if word_embeddings:\n        avg_embedding = np.mean(word_embeddings, axis=0)\n    else:\n        avg_embedding = rnd\n        CNT+=1\n    \n    \n    for we in word_embeddings:\n        #dist = np.linalg.norm(we-avg_embedding)\n        dist = distance.sqeuclidean(we, avg_embedding)\n        intra_dist.append(dist)\n    \n    intra_dist = np.mean(intra_dist)\n    \n    return avg_embedding, CNT, intra_dist\n    \nfor i in os.listdir('/kaggle/input/full-ops'):\n    print(i)\n    if i not in loc:\n        continue\n    CNT=0\n    with open('/kaggle/input/full-ops/'+i, 'rb') as f:\n        lod = pickle.load(f)\n        y = lod[1]\n        k = []\n        p = []\n        ID = []\n        ID1 = []\n        for i in test_dataset:\n            embed, CNT, intra_dist = get_repr(lod[0][i[3]], CNT)\n            k.append(embed)\n            ID.append(intra_dist)\n            a,b= i[0],i[1]\n            p.append(np.concatenate([a,b],axis=-1))\n    \n    print(CNT)\n    ID = np.nan_to_num(ID)\n    ID_mean = np.mean(np.asarray(k), axis=0)\n    \n    for i in k:\n        #dist = np.linalg.norm(i-ID_mean)\n        dist = distance.sqeuclidean(i, ID_mean)\n        ID1.append(dist)\n        \n    \n    ID1 = np.nan_to_num(ID1)\n    k = np.asarray(k)\n    p = np.asarray(p)\n    \n    X = np.concatenate([k,p],axis=-1) # inp w/ clip representation w/ exp -> w/ both\n    X_ = p # inp w/ clip representation w/o exp -> w/ only input\n    X__ = k # inp w/o clip representation w/ exp -> w/ only exp\n    \n    from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n    from sklearn import svm\n    from sklearn.neural_network import MLPClassifier\n    from sklearn.ensemble import GradientBoostingClassifier\n    #clf = svm.SVC(kernel='poly', C=2, random_state=42)\n    \n    kf = KFold(n_splits=4)\n    y = np.array(y)\n    vals = []\n    vals_lus = []\n    k1,k2,k3 = [],[],[]\n    C,S = [],[]\n    for train, test in kf.split(X):\n        \n        X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n        X_train_, X_test_, y_train, y_test = X_[train], X_[test], y[train], y[test]\n        X_train__, X_test__, y_train, y_test = X__[train], X__[test], y[train], y[test]\n        \n        \n        clf1 = make_pipeline(StandardScaler(),svm.SVC(probability=True, kernel='rbf', C=2, random_state=42))\n        clf1.fit(X_train, y_train)\n        y_pred = clf1.predict(X_test)\n        \n        clf2 = make_pipeline(StandardScaler(),svm.SVC(probability=True,kernel='rbf', C=2, random_state=42))\n        clf2.fit(X_train_, y_train)\n        y_pred_ = clf2.predict(X_test_)\n        \n        clf3 = make_pipeline(StandardScaler(), svm.SVC(probability=True,kernel='rbf', C=2, random_state=42))\n        clf3.fit(X_train__, y_train)\n        y_pred__ = clf3.predict(X_test__)\n        \n        \n        y_pred_proba_w_both = clf1.predict_proba(X_test)\n        y_pred_proba_w_inp = clf2.predict_proba(X_test_)\n        y_pred_proba_w_exp = clf3.predict_proba(X_test__)\n        \n        \n        \n        comprehensiveness, sufficiency = 0,0\n        \n        counter = 0\n        for pred_proba_w_both, pred_proba_w_inp, pred_proba_w_exp, pred_class in zip(y_pred_proba_w_both,y_pred_proba_w_inp,y_pred_proba_w_exp,y_pred):\n            comprehensiveness += (pred_proba_w_both[pred_class] - pred_proba_w_inp[pred_class])\n            sufficiency += (pred_proba_w_both[pred_class] - pred_proba_w_exp[pred_class])\n            counter+=1\n        \n        \n        comprehensiveness = comprehensiveness / counter\n        sufficiency = sufficiency / counter\n            \n        C.append(comprehensiveness)\n        S.append(sufficiency)\n            \n            \n            \n       \n        \n        l, nl = 0,0\n        us = 0\n        for i ,j in zip(y_pred__,y_test):\n            if i==j:\n                l+=1\n            else:\n                nl+=1\n        a,b=0,0\n        for i,j,k,x in zip(y_pred,y_pred_,y_test,y_pred__):\n            us+=int(i==k) - int(j==k)\n            if k==x:\n                a += int(i==k) - int(j==k)\n            elif k!=x:\n                b += int(i==k) - int(j==k)\n        \n        #print('LAS ',.5*(a/l)+.5*(b/nl))\n        #print('Leakage Unadjusted Simulatability (LUS)', (us/(l+nl)))\n        vals_lus.append(us/(l+nl))\n        #print('Comprehensiveness ', comprehensiveness)\n        #print('Sufficiency ', sufficiency)\n        #print('f1 between prediction of proposed model and SVM w/ both inp and exp {}'.format(f1_score(y_test, y_pred, average='macro')))\n        #print('f1 between prediction of proposed model and SVM w/ only inp {}'.format(f1_score(y_test, y_pred_, average='macro')))\n        #print('f1 between prediction of proposed model and SVM w/ only exp {}'.format(f1_score(y_test, y_pred__, average='macro')))\n        vals.append(.5*(a/l)+.5*(b/nl))\n        k1.append(f1_score(y_test, y_pred, average='macro'))\n        k2.append(f1_score(y_test, y_pred_, average='macro'))\n        k3.append(f1_score(y_test, y_pred__, average='macro'))\n        \n        \n    print('Intra mean ', np.mean(ID), 'Intra std ', np.std(ID))\n    print('Inter mean ', np.mean(ID1), 'Inter std ', np.std(ID1))\n    print('LAS mean ', np.mean(vals), 'LAS std ', np.std(vals))\n    print('LUS mean ', np.mean(vals_lus), 'LUS std ', np.std(vals_lus))\n    print('Comprehensiveness mean ', np.mean(C), 'Comprehensiveness std ', np.std(C))\n    print('Sufficiency mean ', np.mean(S), 'Sufficiency std ', np.std(S))\n    print('Avg. f1 between prediction of proposed model and SVM w/ both inp and exp {}'.format(np.mean(k1)))\n    print('Avg. f1 between prediction of proposed model and SVM w/ only inp {}'.format(np.mean(k2)))\n    print('Avg. f1 between prediction of proposed model and SVM w/ only exp {}'.format(np.mean(k3)))\n    \n            \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n    #     y_pred = cross_val_predict(clf, X, y, cv=3)\n    #     y_pred_ = cross_val_predict(clf, X_, y, cv=3)\n    #     y_pred__ = cross_val_predict(clf, X__, y, cv=3)\n\n    #     print(y_pred)\n    #     print(y_pred.shape)\n\n    #     print(y_pred_)\n    #     print(y_pred_.shape)\n\n    #     print(0/0)\n    \n    \n    \n\n        ","metadata":{"execution":{"iopub.status.busy":"2023-09-27T17:43:07.827809Z","iopub.execute_input":"2023-09-27T17:43:07.828277Z","iopub.status.idle":"2023-09-27T17:44:25.950882Z","shell.execute_reply.started":"2023-09-27T17:43:07.828236Z","shell.execute_reply":"2023-09-27T17:44:25.949838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import *\nfrom scipy.spatial import distance\nimport pickle\nset_seed(42)\nrnd = np.random.randn(25)\n\ndef get_repr(i,CNT):\n    tokens = i.split('\\t')[:-1] if i!='' else ['']\n    #print(tokens)\n\n    word_embeddings = []\n    intra_dist = []\n    for token in tokens:\n        if token in glove_vectors.index_to_key:\n            word_embeddings.append(glove_vectors[token])\n    \n    # Calculate the average embedding\n    if word_embeddings:\n        avg_embedding = np.mean(word_embeddings, axis=0)\n    else:\n        avg_embedding = rnd\n        CNT+=1\n    \n    \n    for we in word_embeddings:\n        #dist = np.linalg.norm(we-avg_embedding)\n        dist = distance.sqeuclidean(we, avg_embedding)\n        intra_dist.append(dist)\n    \n    intra_dist = np.mean(intra_dist)\n    \n    return avg_embedding, CNT, intra_dist\n    \nfor i in os.listdir('/kaggle/input/full-ops'):\n    print(i)\n    CNT=0\n    with open('/kaggle/input/full-ops/'+i, 'rb') as f:\n        lod = pickle.load(f)\n        y = lod[1]\n        k = []\n        p = []\n        ID = []\n        ID1 = []\n        for i in test_dataset:\n            embed, CNT, intra_dist = get_repr(lod[0][i[3]], CNT)\n            k.append(embed)\n            ID.append(intra_dist)\n            a,b= i[0],i[1]\n            p.append(np.concatenate([a,b],axis=-1))\n    \n    print(CNT)\n    ID = np.nan_to_num(ID)\n    ID_mean = np.mean(np.asarray(k), axis=0)\n    \n    for i in k:\n        #dist = np.linalg.norm(i-ID_mean)\n        dist = distance.sqeuclidean(i, ID_mean)\n        ID1.append(dist)\n        \n    \n    ID1 = np.nan_to_num(ID1)\n    k = np.asarray(k)\n    p = np.asarray(p)\n    \n    X = np.concatenate([k,p],axis=-1) # inp w/ clip representation w/ exp -> w/ both\n    X_ = p # inp w/ clip representation w/o exp -> w/ only input\n    X__ = k # inp w/o clip representation w/ exp -> w/ only exp\n    \n    from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n    from sklearn import svm\n    from sklearn.neural_network import MLPClassifier\n    from sklearn.ensemble import GradientBoostingClassifier\n    #clf = svm.SVC(kernel='poly', C=2, random_state=42)\n    \n    kf = KFold(n_splits=4)\n    y = np.array(y)\n    vals = []\n    vals_lus = []\n    k1,k2,k3 = [],[],[]\n    C,S = [],[]\n    for train, test in kf.split(X):\n        \n        X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n        X_train_, X_test_, y_train, y_test = X_[train], X_[test], y[train], y[test]\n        X_train__, X_test__, y_train, y_test = X__[train], X__[test], y[train], y[test]\n        \n        \n        clf1 = make_pipeline(StandardScaler(),svm.SVC(probability=True, kernel='rbf', C=2, random_state=42))\n        clf1.fit(X_train, y_train)\n        y_pred = clf1.predict(X_test)\n        \n        clf2 = make_pipeline(StandardScaler(),svm.SVC(probability=True,kernel='rbf', C=2, random_state=42))\n        clf2.fit(X_train_, y_train)\n        y_pred_ = clf2.predict(X_test_)\n        \n        clf3 = make_pipeline(StandardScaler(), svm.SVC(probability=True,kernel='rbf', C=2, random_state=42))\n        clf3.fit(X_train__, y_train)\n        y_pred__ = clf3.predict(X_test__)\n        \n        \n        y_pred_proba_w_both = clf1.predict_proba(X_test)\n        y_pred_proba_w_inp = clf2.predict_proba(X_test_)\n        y_pred_proba_w_exp = clf3.predict_proba(X_test__)\n        \n        \n        \n        comprehensiveness, sufficiency = 0,0\n        \n        counter = 0\n        for pred_proba_w_both, pred_proba_w_inp, pred_proba_w_exp, pred_class in zip(y_pred_proba_w_both,y_pred_proba_w_inp,y_pred_proba_w_exp,y_pred):\n            comprehensiveness += (pred_proba_w_both[pred_class] - pred_proba_w_inp[pred_class])\n            sufficiency += (pred_proba_w_both[pred_class] - pred_proba_w_exp[pred_class])\n            counter+=1\n        \n        \n        comprehensiveness = comprehensiveness / counter\n        sufficiency = sufficiency / counter\n            \n        C.append(comprehensiveness)\n        S.append(sufficiency)\n            \n            \n            \n       \n        \n        l, nl = 0,0\n        us = 0\n        for i ,j in zip(y_pred__,y_test):\n            if i==j:\n                l+=1\n            else:\n                nl+=1\n        a,b=0,0\n        for i,j,k,x in zip(y_pred,y_pred_,y_test,y_pred__):\n            us+=int(i==k) - int(j==k)\n            if k==x:\n                a += int(i==k) - int(j==k)\n            elif k!=x:\n                b += int(i==k) - int(j==k)\n        \n        #         print('LAS ',.5*(a/l)+.5*(b/nl))\n        #         print('Leakage Unadjusted Simulatability (LUS)', (us/(l+nl)))\n        vals_lus.append(us/(l+nl))\n        #         print('Comprehensiveness ', comprehensiveness)\n        #         print('Sufficiency ', sufficiency)\n        #         print('f1 between prediction of proposed model and SVM w/ both inp and exp {}'.format(f1_score(y_test, y_pred, average='macro')))\n        #         print('f1 between prediction of proposed model and SVM w/ only inp {}'.format(f1_score(y_test, y_pred_, average='macro')))\n        #         print('f1 between prediction of proposed model and SVM w/ only exp {}'.format(f1_score(y_test, y_pred__, average='macro')))\n        vals.append(.5*(a/l)+.5*(b/nl))\n        k1.append(f1_score(y_test, y_pred, average='macro'))\n        k2.append(f1_score(y_test, y_pred_, average='macro'))\n        k3.append(f1_score(y_test, y_pred__, average='macro'))\n        \n        \n    print('Intra mean ', np.mean(ID), 'Intra std ', np.std(ID))\n    print('Inter mean ', np.mean(ID1), 'Inter std ', np.std(ID1))\n    #     print('LAS mean ', np.mean(vals), 'LAS std ', np.std(vals))\n    #     print('LUS mean ', np.mean(vals_lus), 'LUS std ', np.std(vals_lus))\n    #     print('Comprehensiveness mean ', np.mean(C), 'Comprehensiveness std ', np.std(C))\n    #     print('Sufficiency mean ', np.mean(S), 'Sufficiency std ', np.std(S))\n    #     print('Avg. f1 between prediction of proposed model and SVM w/ both inp and exp {}'.format(np.mean(k1)))\n    #     print('Avg. f1 between prediction of proposed model and SVM w/ only inp {}'.format(np.mean(k2)))\n    #     print('Avg. f1 between prediction of proposed model and SVM w/ only exp {}'.format(np.mean(k3)))\n    \n            \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n    #     y_pred = cross_val_predict(clf, X, y, cv=3)\n    #     y_pred_ = cross_val_predict(clf, X_, y, cv=3)\n    #     y_pred__ = cross_val_predict(clf, X__, y, cv=3)\n\n    #     print(y_pred)\n    #     print(y_pred.shape)\n\n    #     print(y_pred_)\n    #     print(y_pred_.shape)\n\n    #     print(0/0)\n    \n    \n    \n\n        ","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:03:18.573455Z","iopub.execute_input":"2023-09-19T06:03:18.573834Z","iopub.status.idle":"2023-09-19T06:16:20.255895Z","shell.execute_reply.started":"2023-09-19T06:03:18.573803Z","shell.execute_reply":"2023-09-19T06:16:20.254743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import *\nimport pickle\nset_seed(42)\nrnd = np.random.randn(25)\n\ndef get_repr(i,CNT):\n    tokens = i.split('\\t')[:-1] if i!='' else ['']\n    #print(tokens)\n\n    word_embeddings = []\n\n    for token in tokens:\n        if token in glove_vectors.index_to_key:\n            word_embeddings.append(glove_vectors[token])\n    \n    # Calculate the average embedding\n    if word_embeddings:\n        avg_embedding = np.mean(word_embeddings, axis=0)\n    else:\n        avg_embedding = rnd\n        CNT+=1\n        \n    return avg_embedding, CNT\n    \nfor i in os.listdir('/kaggle/input/full-ops'):\n    print(i)\n    CNT=0\n    with open('/kaggle/input/full-ops/'+i, 'rb') as f:\n        lod = pickle.load(f)\n        y = []\n        k = []\n        p = []\n        for i in test_dataset:\n            y.append(i[2])\n            embed, CNT = get_repr(lod[0][i[3]], CNT)\n            k.append(embed)\n            a,b= i[0],i[1]\n            p.append(np.concatenate([a,b],axis=-1))\n    \n    print(CNT)\n    k = np.asarray(k)\n    p = np.asarray(p)\n    \n    X = np.concatenate([k,p],axis=-1) # inp w/ clip representation w/ exp -> w/ both\n    X_ = p # inp w/ clip representation w/o exp -> w/ only input\n    X__ = k # inp w/o clip representation w/ exp -> w/ only exp\n    \n    from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n    from sklearn import svm\n    from sklearn.neural_network import MLPClassifier\n    from sklearn.ensemble import GradientBoostingClassifier\n    #clf = svm.SVC(kernel='poly', C=2, random_state=42)\n    \n    kf = KFold(n_splits=4)\n    y = np.array(y)\n    vals = []\n    vals_lus = []\n    k1,k2,k3 = [],[],[]\n    C,S = [],[]\n    for train, test in kf.split(X):\n        \n        X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n        X_train_, X_test_, y_train, y_test = X_[train], X_[test], y[train], y[test]\n        X_train__, X_test__, y_train, y_test = X__[train], X__[test], y[train], y[test]\n        \n        \n        clf1 = make_pipeline(StandardScaler(),svm.SVC(probability=True, kernel='rbf', C=2, random_state=42))\n        clf1.fit(X_train, y_train)\n        y_pred = clf1.predict(X_test)\n        \n        clf2 = make_pipeline(StandardScaler(),svm.SVC(probability=True,kernel='rbf', C=2, random_state=42))\n        clf2.fit(X_train_, y_train)\n        y_pred_ = clf2.predict(X_test_)\n        \n        clf3 = make_pipeline(StandardScaler(), svm.SVC(probability=True,kernel='rbf', C=2, random_state=42))\n        clf3.fit(X_train__, y_train)\n        y_pred__ = clf3.predict(X_test__)\n        \n        \n        y_pred_proba_w_both = clf1.predict_proba(X_test)\n        y_pred_proba_w_inp = clf2.predict_proba(X_test_)\n        y_pred_proba_w_exp = clf3.predict_proba(X_test__)\n        \n        \n        \n        comprehensiveness, sufficiency = 0,0\n        \n        counter = 0\n        for pred_proba_w_both, pred_proba_w_inp, pred_proba_w_exp, pred_class in zip(y_pred_proba_w_both,y_pred_proba_w_inp,y_pred_proba_w_exp,y_pred):\n            comprehensiveness += (pred_proba_w_both[pred_class] - pred_proba_w_inp[pred_class])\n            sufficiency += (pred_proba_w_both[pred_class] - pred_proba_w_exp[pred_class])\n            counter+=1\n        \n        \n        comprehensiveness = comprehensiveness / counter\n        sufficiency = sufficiency / counter\n            \n        C.append(comprehensiveness)\n        S.append(sufficiency)\n            \n            \n            \n       \n        \n        l, nl = 0,0\n        us = 0\n        for i ,j in zip(y_pred__,y_test):\n            if i==j:\n                l+=1\n            else:\n                nl+=1\n        a,b=0,0\n        for i,j,k,x in zip(y_pred,y_pred_,y_test,y_pred__):\n            us+=int(i==k) - int(j==k)\n            if k==x:\n                a += int(i==k) - int(j==k)\n            elif k!=x:\n                b += int(i==k) - int(j==k)\n        \n        print('LAS ',.5*(a/l)+.5*(b/nl))\n        print('Leakage Unadjusted Simulatability (LUS)', (us/(l+nl)))\n        vals_lus.append(us/(l+nl))\n        print('Comprehensiveness ', comprehensiveness)\n        print('Sufficiency ', sufficiency)\n        print('f1 between prediction of proposed model and SVM w/ both inp and exp {}'.format(f1_score(y_test, y_pred, average='macro')))\n        print('f1 between prediction of proposed model and SVM w/ only inp {}'.format(f1_score(y_test, y_pred_, average='macro')))\n        print('f1 between prediction of proposed model and SVM w/ only exp {}'.format(f1_score(y_test, y_pred__, average='macro')))\n        vals.append(.5*(a/l)+.5*(b/nl))\n        k1.append(f1_score(y_test, y_pred, average='macro'))\n        k2.append(f1_score(y_test, y_pred_, average='macro'))\n        k3.append(f1_score(y_test, y_pred__, average='macro'))\n    print('LAS mean ', np.mean(vals), 'LAS std ', np.std(vals))\n    print('LUS mean ', np.mean(vals_lus), 'LUS std ', np.std(vals_lus))\n    print('Comprehensiveness mean ', np.mean(C), 'Comprehensiveness std ', np.std(C))\n    print('Sufficiency mean ', np.mean(S), 'Sufficiency std ', np.std(S))\n    print('Avg. f1 between prediction of proposed model and SVM w/ both inp and exp {}'.format(np.mean(k1)))\n    print('Avg. f1 between prediction of proposed model and SVM w/ only inp {}'.format(np.mean(k2)))\n    print('Avg. f1 between prediction of proposed model and SVM w/ only exp {}'.format(np.mean(k3)))\n    \n            \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n    #     y_pred = cross_val_predict(clf, X, y, cv=3)\n    #     y_pred_ = cross_val_predict(clf, X_, y, cv=3)\n    #     y_pred__ = cross_val_predict(clf, X__, y, cv=3)\n\n    #     print(y_pred)\n    #     print(y_pred.shape)\n\n    #     print(y_pred_)\n    #     print(y_pred_.shape)\n\n    #     print(0/0)\n    \n    \n    \n\n        ","metadata":{"execution":{"iopub.status.busy":"2023-09-16T13:14:53.702853Z","iopub.execute_input":"2023-09-16T13:14:53.703247Z","iopub.status.idle":"2023-09-16T13:29:01.970432Z","shell.execute_reply.started":"2023-09-16T13:14:53.703214Z","shell.execute_reply":"2023-09-16T13:29:01.968493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Mean values for metric A for three models\nmean_values = [0.023, 0.019, 0.019, 0.027]\n\n# Three different setups (you should have similar arrays for these setups)\nsetup1 = [0.012, 0.016, 0.023, 0.02]  # Replace with your actual values\nsetup2 = [0.018, -0.005, 0.019, 0.022]  # Replace with your actual values\n\n\n# X-axis labels (if needed)\nmodels = ['500', '1500', '2500', '3500']\n\n# Plotting the graph\nplt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n\n# Plot each setup as a separate line\nplt.plot(models, mean_values, label='epsilon=0.1')\nplt.plot(models, setup1, label='epsilon=None')\nplt.plot(models, setup2, label='epsilon=0.01')\n\n# Adding labels and title\nplt.xlabel('Models')\nplt.ylabel('Mean Value of Metric A')\nplt.title('Mean Value of Metric A for Different Setups')\n\n# Adding a legend\nplt.legend()\n\n# Display the plot\nplt.grid(True)\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Mean values for metric A for three models\nmean_values = [0.023, 0.019, 0.019, 0.027]\n\n# Three different setups (you should have similar arrays for these setups)\nsetup1 = [0.012, 0.016, 0.023, 0.02]  # Replace with your actual values\nsetup2 = [0.018, -0.005, 0.019, 0.022]  # Replace with your actual values\n\n\n# X-axis labels (if needed)\nmodels = ['500', '1500', '2500', '3500']\n\n# Plotting the graph\nplt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n\n# Plot each setup as a separate line\nplt.plot(models, mean_values, label='epsilon=0.1')\nplt.plot(models, setup1, label='epsilon=None')\nplt.plot(models, setup2, label='epsilon=0.01')\n\n# Adding labels and title\nplt.xlabel('Models')\nplt.ylabel('Mean Value of Metric A')\nplt.title('Mean Value of Metric A for Different Setups')\n\n# Adding a legend\nplt.legend()\n\n# Display the plot\nplt.grid(True)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-16T11:16:54.278329Z","iopub.execute_input":"2023-09-16T11:16:54.279233Z","iopub.status.idle":"2023-09-16T11:16:54.654151Z","shell.execute_reply.started":"2023-09-16T11:16:54.279194Z","shell.execute_reply":"2023-09-16T11:16:54.652937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Mean values for metric A for three models\nmean_values = [0.1, 0.2, 0.3]\n\n# Three different setups (you should have similar arrays for these setups)\nsetup1 = [0.15, 0.25, 0.35]  # Replace with your actual values\nsetup2 = [0.12, 0.22, 0.32]  # Replace with your actual values\nsetup3 = [0.18, 0.28, 0.38]  # Replace with your actual values\n\n# Create a DataFrame for the data\nimport pandas as pd\n\ndata = pd.DataFrame({\n    'Models': ['Model 1', 'Model 2', 'Model 3'],\n    'Setup 1': mean_values,\n    'Setup 2': setup1,\n    'Setup 3': setup2\n})\n\n# Set the style for the plot (optional)\nsns.set(style='whitegrid')\n\n# Create the line plot using Seaborn\nplt.figure(figsize=(10, 6))\nsns.lineplot(x='Models', y='value', hue='variable', data=pd.melt(data, ['Models']))\n\n# Adding labels and title\nplt.xlabel('Models')\nplt.ylabel('Mean Value of Metric A')\nplt.title('Mean Value of Metric A for Different Setups')\n\n# Display the plot\nplt.legend(title='Setups')\nplt.grid(True)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-16T11:06:23.767662Z","iopub.execute_input":"2023-09-16T11:06:23.768117Z","iopub.status.idle":"2023-09-16T11:06:24.466989Z","shell.execute_reply.started":"2023-09-16T11:06:23.768083Z","shell.execute_reply":"2023-09-16T11:06:24.466028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import *\nset_seed(42)\nrnd = np.random.randn(25)\n\ndef get_repr(i,CNT):\n    tokens = i.split('\\t')[:-1] if i!='' else ['']\n    #print(tokens)\n\n    word_embeddings = []\n\n    for token in tokens:\n        if token in glove_vectors.index_to_key:\n            word_embeddings.append(glove_vectors[token])\n    \n    # Calculate the average embedding\n    if word_embeddings:\n        avg_embedding = np.mean(word_embeddings, axis=0)\n    else:\n        avg_embedding = rnd\n        CNT+=1\n        \n    return avg_embedding, CNT\n    \nfor i in os.listdir('/kaggle/input/extra-full-ops'):\n    print(i)\n    CNT=0\n    with open('/kaggle/input/extra-full-ops/'+i, 'rb') as f:\n        lod = pickle.load(f)\n        y = lod[1]\n        k = []\n        p = []\n        for i in test_dataset:\n            embed, CNT = get_repr(lod[0][i[3]], CNT)\n            k.append(embed)\n            a,b= i[0],i[1]\n            p.append(np.concatenate([a,b],axis=-1))\n    \n    print(CNT)\n    k = np.asarray(k)\n    p = np.asarray(p)\n    \n    X = np.concatenate([k,p],axis=-1) # inp w/ clip representation w/ exp -> w/ both\n    X_ = p # inp w/ clip representation w/o exp -> w/ only input\n    X__ = k # inp w/o clip representation w/ exp -> w/ only exp\n    \n    from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n    from sklearn import svm\n    from sklearn.neural_network import MLPClassifier\n    from sklearn.ensemble import GradientBoostingClassifier\n    #clf = svm.SVC(kernel='poly', C=2, random_state=42)\n    \n    kf = KFold(n_splits=4)\n    y = np.array(y)\n    vals = []\n    k1,k2,k3 = [],[],[]\n    for train, test in kf.split(X):\n        \n        X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n        X_train_, X_test_, y_train, y_test = X_[train], X_[test], y[train], y[test]\n        X_train__, X_test__, y_train, y_test = X__[train], X__[test], y[train], y[test]\n        \n        \n        clf1 = make_pipeline(StandardScaler(),svm.SVC(kernel='rbf', C=2, random_state=42))\n        clf1.fit(X_train, y_train)\n        y_pred = clf1.predict(X_test)\n        \n        clf2 = make_pipeline(StandardScaler(),svm.SVC(kernel='rbf', C=2, random_state=42))\n        clf2.fit(X_train_, y_train)\n        y_pred_ = clf2.predict(X_test_)\n        \n        clf3 = make_pipeline(StandardScaler(), svm.SVC(kernel='rbf', C=2, random_state=42))\n        clf3.fit(X_train__, y_train)\n        y_pred__ = clf3.predict(X_test__)\n        \n        l, nl = 0,0\n        \n        for i ,j in zip(y_pred__,y_test):\n            if i==j:\n                l+=1\n            else:\n                nl+=1\n        a,b=0,0\n        for i,j,k,x in zip(y_pred,y_pred_,y_test,y_pred__):\n            if k==x:\n                a += int(i==k) - int(j==k)\n            elif k!=x:\n                b += int(i==k) - int(j==k)\n        \n        print('LAS, ',.5*(a/l)+.5*(b/nl))\n        print('f1 between prediction of proposed model and SVM w/ both inp and exp {}'.format(f1_score(y_test, y_pred, average='macro')))\n        print('f1 between prediction of proposed model and SVM w/ only inp {}'.format(f1_score(y_test, y_pred_, average='macro')))\n        print('f1 between prediction of proposed model and SVM w/ only exp {}'.format(f1_score(y_test, y_pred__, average='macro')))\n        vals.append(.5*(a/l)+.5*(b/nl))\n        k1.append(f1_score(y_test, y_pred, average='macro'))\n        k2.append(f1_score(y_test, y_pred_, average='macro'))\n        k3.append(f1_score(y_test, y_pred__, average='macro'))\n    print('LAS mean ', np.mean(vals), 'LAS std ', np.std(vals))\n    print('Avg. f1 between prediction of proposed model and SVM w/ both inp and exp {}'.format(np.mean(k1)))\n    print('Avg. f1 between prediction of proposed model and SVM w/ only inp {}'.format(np.mean(k2)))\n    print('Avg. f1 between prediction of proposed model and SVM w/ only exp {}'.format(np.mean(k3)))\n    \n            \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n    #     y_pred = cross_val_predict(clf, X, y, cv=3)\n    #     y_pred_ = cross_val_predict(clf, X_, y, cv=3)\n    #     y_pred__ = cross_val_predict(clf, X__, y, cv=3)\n\n    #     print(y_pred)\n    #     print(y_pred.shape)\n\n    #     print(y_pred_)\n    #     print(y_pred_.shape)\n\n    #     print(0/0)\n    \n    \n    \n\n        ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:10:08.124132Z","iopub.execute_input":"2023-09-13T11:10:08.124507Z","iopub.status.idle":"2023-09-13T11:10:32.136488Z","shell.execute_reply.started":"2023-09-13T11:10:08.124476Z","shell.execute_reply":"2023-09-13T11:10:32.135496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import *\nset_seed(42)\nrnd = np.random.randn(25)\n\ndef get_repr(i,CNT):\n    tokens = i.split('\\t')[:-1] if i!='' else ['']\n    #print(tokens)\n\n    word_embeddings = []\n\n    for token in tokens:\n        if token in glove_vectors.index_to_key:\n            word_embeddings.append(glove_vectors[token])\n    \n    # Calculate the average embedding\n    if word_embeddings:\n        avg_embedding = np.mean(word_embeddings, axis=0)\n    else:\n        avg_embedding = rnd\n        CNT+=1\n        \n    return avg_embedding, CNT\n    \nfor i in os.listdir('/kaggle/input/extra-ur-ur'):\n    print(i)\n    CNT=0\n    with open('/kaggle/input/extra-ur-ur/'+i, 'rb') as f:\n        lod = pickle.load(f)\n        y = lod[1]\n        k = []\n        p = []\n        for i in test_dataset:\n            embed, CNT = get_repr(lod[0][i[3]], CNT)\n            k.append(embed)\n            a,b= i[0],i[1]\n            p.append(np.concatenate([a,b],axis=-1))\n    \n    print(CNT)\n    k = np.asarray(k)\n    p = np.asarray(p)\n    \n    X = np.concatenate([k,p],axis=-1) # inp w/ clip representation w/ exp -> w/ both\n    X_ = p # inp w/ clip representation w/o exp -> w/ only input\n    X__ = k # inp w/o clip representation w/ exp -> w/ only exp\n    \n    from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n    from sklearn import svm\n    from sklearn.neural_network import MLPClassifier\n    from sklearn.ensemble import GradientBoostingClassifier\n    #clf = svm.SVC(kernel='poly', C=2, random_state=42)\n    \n    kf = KFold(n_splits=4)\n    y = np.array(y)\n    vals = []\n    k1,k2,k3 = [],[],[]\n    for train, test in kf.split(X):\n        \n        X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n        X_train_, X_test_, y_train, y_test = X_[train], X_[test], y[train], y[test]\n        X_train__, X_test__, y_train, y_test = X__[train], X__[test], y[train], y[test]\n        \n        \n        clf1 = make_pipeline(StandardScaler(),svm.SVC(kernel='rbf', C=2, random_state=42))\n        clf1.fit(X_train, y_train)\n        y_pred = clf1.predict(X_test)\n        \n        clf2 = make_pipeline(StandardScaler(),svm.SVC(kernel='rbf', C=2, random_state=42))\n        clf2.fit(X_train_, y_train)\n        y_pred_ = clf2.predict(X_test_)\n        \n        clf3 = make_pipeline(StandardScaler(), svm.SVC(kernel='rbf', C=2, random_state=42))\n        clf3.fit(X_train__, y_train)\n        y_pred__ = clf3.predict(X_test__)\n        \n        l, nl = 0,0\n        \n        for i ,j in zip(y_pred__,y_test):\n            if i==j:\n                l+=1\n            else:\n                nl+=1\n        a,b=0,0\n        for i,j,k,x in zip(y_pred,y_pred_,y_test,y_pred__):\n            if k==x:\n                a += int(i==k) - int(j==k)\n            elif k!=x:\n                b += int(i==k) - int(j==k)\n        \n        print('LAS, ',.5*(a/l)+.5*(b/nl))\n        print('f1 between prediction of proposed model and SVM w/ both inp and exp {}'.format(f1_score(y_test, y_pred, average='macro')))\n        print('f1 between prediction of proposed model and SVM w/ only inp {}'.format(f1_score(y_test, y_pred_, average='macro')))\n        print('f1 between prediction of proposed model and SVM w/ only exp {}'.format(f1_score(y_test, y_pred__, average='macro')))\n        vals.append(.5*(a/l)+.5*(b/nl))\n        k1.append(f1_score(y_test, y_pred, average='macro'))\n        k2.append(f1_score(y_test, y_pred_, average='macro'))\n        k3.append(f1_score(y_test, y_pred__, average='macro'))\n    print('LAS mean ', np.mean(vals), 'LAS std ', np.std(vals))\n    print('Avg. f1 between prediction of proposed model and SVM w/ both inp and exp {}'.format(np.mean(k1)))\n    print('Avg. f1 between prediction of proposed model and SVM w/ only inp {}'.format(np.mean(k2)))\n    print('Avg. f1 between prediction of proposed model and SVM w/ only exp {}'.format(np.mean(k3)))\n    \n            \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n    #     y_pred = cross_val_predict(clf, X, y, cv=3)\n    #     y_pred_ = cross_val_predict(clf, X_, y, cv=3)\n    #     y_pred__ = cross_val_predict(clf, X__, y, cv=3)\n\n    #     print(y_pred)\n    #     print(y_pred.shape)\n\n    #     print(y_pred_)\n    #     print(y_pred_.shape)\n\n    #     print(0/0)\n    \n    \n    \n\n        ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T12:23:12.403698Z","iopub.execute_input":"2023-09-13T12:23:12.404087Z","iopub.status.idle":"2023-09-13T12:24:20.513460Z","shell.execute_reply.started":"2023-09-13T12:23:12.404034Z","shell.execute_reply":"2023-09-13T12:24:20.512319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import *\nset_seed(42)\nrnd = np.random.randn(25)\n\ndef get_repr(i,CNT):\n    tokens = i.split('\\t')[:-1] if i!='' else ['']\n    #print(tokens)\n\n    word_embeddings = []\n\n    for token in tokens:\n        if token in glove_vectors.index_to_key:\n            word_embeddings.append(glove_vectors[token])\n    \n    # Calculate the average embedding\n    if word_embeddings:\n        avg_embedding = np.mean(word_embeddings, axis=0)\n    else:\n        avg_embedding = rnd\n        CNT+=1\n        \n    return avg_embedding, CNT\n    \nfor i in os.listdir('/kaggle/input/final-extra'):\n    print(i)\n    CNT=0\n    with open('/kaggle/input/final-extra/'+i, 'rb') as f:\n        lod = pickle.load(f)\n        y = lod[1]\n        k = []\n        p = []\n        for i in test_dataset:\n            embed, CNT = get_repr(lod[0][i[3]], CNT)\n            k.append(embed)\n            a,b= i[0],i[1]\n            p.append(np.concatenate([a,b],axis=-1))\n    \n    print(CNT)\n    k = np.asarray(k)\n    p = np.asarray(p)\n    \n    X = np.concatenate([k,p],axis=-1) # inp w/ clip representation w/ exp -> w/ both\n    X_ = p # inp w/ clip representation w/o exp -> w/ only input\n    X__ = k # inp w/o clip representation w/ exp -> w/ only exp\n    \n    from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n    from sklearn import svm\n    from sklearn.neural_network import MLPClassifier\n    from sklearn.ensemble import GradientBoostingClassifier\n    #clf = svm.SVC(kernel='poly', C=2, random_state=42)\n    \n    kf = KFold(n_splits=4)\n    y = np.array(y)\n    vals = []\n    k1,k2,k3 = [],[],[]\n    for train, test in kf.split(X):\n        \n        X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n        X_train_, X_test_, y_train, y_test = X_[train], X_[test], y[train], y[test]\n        X_train__, X_test__, y_train, y_test = X__[train], X__[test], y[train], y[test]\n        \n        \n        clf1 = make_pipeline(StandardScaler(),svm.SVC(kernel='rbf', C=2, random_state=42))\n        clf1.fit(X_train, y_train)\n        y_pred = clf1.predict(X_test)\n        \n        clf2 = make_pipeline(StandardScaler(),svm.SVC(kernel='rbf', C=2, random_state=42))\n        clf2.fit(X_train_, y_train)\n        y_pred_ = clf2.predict(X_test_)\n        \n        clf3 = make_pipeline(StandardScaler(), svm.SVC(kernel='rbf', C=2, random_state=42))\n        clf3.fit(X_train__, y_train)\n        y_pred__ = clf3.predict(X_test__)\n        \n        l, nl = 0,0\n        \n        for i ,j in zip(y_pred__,y_test):\n            if i==j:\n                l+=1\n            else:\n                nl+=1\n        a,b=0,0\n        for i,j,k,x in zip(y_pred,y_pred_,y_test,y_pred__):\n            if k==x:\n                a += int(i==k) - int(j==k)\n            elif k!=x:\n                b += int(i==k) - int(j==k)\n        \n        print('LAS, ',.5*(a/l)+.5*(b/nl))\n        print('f1 between prediction of proposed model and SVM w/ both inp and exp {}'.format(f1_score(y_test, y_pred, average='macro')))\n        print('f1 between prediction of proposed model and SVM w/ only inp {}'.format(f1_score(y_test, y_pred_, average='macro')))\n        print('f1 between prediction of proposed model and SVM w/ only exp {}'.format(f1_score(y_test, y_pred__, average='macro')))\n        vals.append(.5*(a/l)+.5*(b/nl))\n        k1.append(f1_score(y_test, y_pred, average='macro'))\n        k2.append(f1_score(y_test, y_pred_, average='macro'))\n        k3.append(f1_score(y_test, y_pred__, average='macro'))\n    print('LAS mean ', np.mean(vals), 'LAS std ', np.std(vals))\n    print('Avg. f1 between prediction of proposed model and SVM w/ both inp and exp {}'.format(np.mean(k1)))\n    print('Avg. f1 between prediction of proposed model and SVM w/ only inp {}'.format(np.mean(k2)))\n    print('Avg. f1 between prediction of proposed model and SVM w/ only exp {}'.format(np.mean(k3)))\n    \n            \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n    #     y_pred = cross_val_predict(clf, X, y, cv=3)\n    #     y_pred_ = cross_val_predict(clf, X_, y, cv=3)\n    #     y_pred__ = cross_val_predict(clf, X__, y, cv=3)\n\n    #     print(y_pred)\n    #     print(y_pred.shape)\n\n    #     print(y_pred_)\n    #     print(y_pred_.shape)\n\n    #     print(0/0)\n    \n    \n    \n\n        ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:40:42.545674Z","iopub.execute_input":"2023-09-13T13:40:42.546126Z","iopub.status.idle":"2023-09-13T13:41:08.251188Z","shell.execute_reply.started":"2023-09-13T13:40:42.546091Z","shell.execute_reply":"2023-09-13T13:41:08.249965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nset_seed(42)\nrnd = np.random.randn(25)\ndef get_repr(i):\n    tokens = i.split('\\t')[:-1] if i!='' else ['']\n    #print(tokens)\n\n    word_embeddings = []\n\n    for token in tokens:\n        if token in glove_vectors.index_to_key:\n            word_embeddings.append(glove_vectors[token])\n    \n    # Calculate the average embedding\n    if word_embeddings:\n        avg_embedding = np.mean(word_embeddings, axis=0)\n    else:\n        avg_embedding = rnd\n        \n    return avg_embedding\n    \nfor i in os.listdir('/kaggle/input/full-ops'):\n    print(i)\n    with open('/kaggle/input/full-ops/'+i, 'rb') as f:\n        lod = pickle.load(f)\n        y = lod[1]\n        k = []\n        p = []\n        for i in test_dataset:\n            k.append(get_repr(lod[0][i[3]]))\n            a,b= i[0],i[1]\n            p.append(np.concatenate([a,b],axis=-1))\n\n    k = np.asarray(k)\n    p = np.asarray(p)\n    \n    X = np.concatenate([k,p],axis=-1) # inp w/ clip representation w/ exp\n    X_ = p # inp w/ clip representation w/o exp\n    X__ = k # inp w/o clip representation w/ exp\n    \n    from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n    from sklearn import svm\n    from sklearn.neural_network import MLPClassifier\n    from sklearn.ensemble import GradientBoostingClassifier\n    #clf = svm.SVC(kernel='poly', C=2, random_state=42)\n    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n    kf = KFold(n_splits=2)\n    y = np.array(y)\n    vals = []\n    for train, test in kf.split(X):\n        \n        X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n        X_train_, X_test_, y_train, y_test = X_[train], X_[test], y[train], y[test]\n        X_train__, X_test__, y_train, y_test = X__[train], X__[test], y[train], y[test]\n        \n        \n        clf1 = make_pipeline(StandardScaler(),svm.SVC(kernel='rbf', C=4, random_state=42))\n        clf1.fit(X_train, y_train)\n        y_pred = clf1.predict(X_test)\n        \n        clf2 = make_pipeline(StandardScaler(),svm.SVC(kernel='rbf', C=4, random_state=42))\n        clf2.fit(X_train_, y_train)\n        y_pred_ = clf2.predict(X_test_)\n        \n        clf3 = make_pipeline(StandardScaler(), svm.SVC(kernel='rbf', C=4, random_state=42))\n        clf3.fit(X_train__, y_train)\n        y_pred__ = clf3.predict(X_test__)\n        \n        l, nl = 0,0\n        \n        for i ,j in zip(y_pred__,y_test):\n            if i==j:\n                l+=1\n            else:\n                nl+=1\n        a,b=0,0\n        for i,j,k,x in zip(y_pred,y_pred_,y_test,y_pred__):\n            if k==x:\n                a += int(i==k) - int(j==k)\n            elif k!=x:\n                b += int(i==k) - int(j==k)\n        \n        print(.5*(a/l)+.5*(b/nl))\n        vals.append(.5*(a/l)+.5*(b/nl))\n    print('mean ', np.mean(vals), 'std ', np.std(vals))\n    \n            \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n    #     y_pred = cross_val_predict(clf, X, y, cv=3)\n    #     y_pred_ = cross_val_predict(clf, X_, y, cv=3)\n    #     y_pred__ = cross_val_predict(clf, X__, y, cv=3)\n\n    #     print(y_pred)\n    #     print(y_pred.shape)\n\n    #     print(y_pred_)\n    #     print(y_pred_.shape)\n\n    #     print(0/0)\n    \n    \n    \n\n        ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:43:06.542296Z","iopub.execute_input":"2023-09-13T07:43:06.542658Z","iopub.status.idle":"2023-09-13T07:44:14.021036Z","shell.execute_reply.started":"2023-09-13T07:43:06.542628Z","shell.execute_reply":"2023-09-13T07:44:14.019727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\ndef get_repr(i):\n    tokens = i.split('\\t')[:-1] if i!='' else ['']\n    #print(tokens)\n\n    word_embeddings = []\n\n    for token in tokens:\n        if token in glove_vectors.index_to_key:\n            word_embeddings.append(glove_vectors[token])\n\n    # Calculate the average embedding\n    if word_embeddings:\n        avg_embedding = np.mean(word_embeddings, axis=0)\n    else:\n        avg_embedding = rnd\n        \n    return avg_embedding\n    \nfor i in os.listdir('/kaggle/input/extras'):\n    print(i)\n    with open('/kaggle/input/extras/'+i, 'rb') as f:\n        lod = pickle.load(f)\n        y = lod[1]\n        k = []\n        p = []\n        for i in test_dataset_1:\n            k.append(get_repr(lod[0][i[3]]))\n            a,b= i[0],i[1]\n            p.append(np.concatenate([a,b],axis=-1))\n\n    k = np.asarray(k)\n    p = np.asarray(p)\n    \n    X = np.concatenate([k,p],axis=-1) # inp w/ clip representation w/ exp\n    X_ = p # inp w/ clip representation w/o exp\n    X__ = k # inp w/o clip representation w/ exp\n    \n    from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n    from sklearn import svm\n    from sklearn.neural_network import MLPClassifier\n    from sklearn.ensemble import GradientBoostingClassifier\n    #clf = svm.SVC(kernel='poly', C=2, random_state=42)\n    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n    kf = KFold(n_splits=5)\n    y = np.array(y)\n    vals = []\n    for train, test in kf.split(X):\n        \n        X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n        X_train_, X_test_, y_train, y_test = X_[train], X_[test], y[train], y[test]\n        X_train__, X_test__, y_train, y_test = X__[train], X__[test], y[train], y[test]\n        \n        \n        clf1 = make_pipeline(StandardScaler(),GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0))\n        clf1.fit(X_train, y_train)\n        y_pred = clf1.predict(X_test)\n        \n        clf2 = make_pipeline(StandardScaler(),GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0))\n        clf2.fit(X_train_, y_train)\n        y_pred_ = clf2.predict(X_test_)\n        \n        clf3 = make_pipeline(StandardScaler(),GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0))\n        clf3.fit(X_train__, y_train)\n        y_pred__ = clf3.predict(X_test__)\n        \n        l, nl = 0,0\n        \n        for i ,j in zip(y_pred__,y_test):\n            if i==j:\n                l+=1\n            else:\n                nl+=1\n        a,b=0,0\n        for i,j,k,x in zip(y_pred,y_pred_,y_test,y_pred__):\n            if k==x:\n                a += int(i==k) - int(j==k)\n            elif k!=x:\n                b += int(i==k) - int(j==k)\n        \n        vals.append(.5*(a/l)+.5*(b/nl))\n        print(.5*(a/l)+.5*(b/nl))\n    print('mean ', np.mean(vals), 'std ', np.std(vals))\n    \n            \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n    #     y_pred = cross_val_predict(clf, X, y, cv=3)\n    #     y_pred_ = cross_val_predict(clf, X_, y, cv=3)\n    #     y_pred__ = cross_val_predict(clf, X__, y, cv=3)\n\n    #     print(y_pred)\n    #     print(y_pred.shape)\n\n    #     print(y_pred_)\n    #     print(y_pred_.shape)\n\n    #     print(0/0)\n    \n    \n    \n\n        ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = np.array([[1,2],[0,8]])\na[np.array([0])]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.025424Z","iopub.status.idle":"2023-09-13T07:27:26.026572Z","shell.execute_reply.started":"2023-09-13T07:27:26.026194Z","shell.execute_reply":"2023-09-13T07:27:26.026228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.028565Z","iopub.status.idle":"2023-09-13T07:27:26.029662Z","shell.execute_reply.started":"2023-09-13T07:27:26.029303Z","shell.execute_reply":"2023-09-13T07:27:26.029337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if p:\n    print(1)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.031690Z","iopub.status.idle":"2023-09-13T07:27:26.032530Z","shell.execute_reply.started":"2023-09-13T07:27:26.032280Z","shell.execute_reply":"2023-09-13T07:27:26.032303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"0.33062397372742197 0.3229131047815565","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.033962Z","iopub.status.idle":"2023-09-13T07:27:26.034705Z","shell.execute_reply.started":"2023-09-13T07:27:26.034455Z","shell.execute_reply":"2023-09-13T07:27:26.034488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"1193514","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.036116Z","iopub.status.idle":"2023-09-13T07:27:26.036861Z","shell.execute_reply.started":"2023-09-13T07:27:26.036621Z","shell.execute_reply":"2023-09-13T07:27:26.036645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"leakage = []\nnon_leakage = []\nglobal_dict = {}\nfor ii,ti, gol, ids in tqdm(test_dataset_1):\n    we = []\n    ii = ii.unsqueeze(dim=0)\n    ti = ti.unsqueeze(dim=0)\n    gol = [gol]\n    ids = [ids]\n    \n    for id_ in ids: \n        tokens = [i for i in d_ids[id_].split('\\t') if i!='']\n        #print(tokens)\n\n        word_embeddings = []\n\n        for token in tokens:\n            if token in glove_vectors.index_to_key:\n                word_embeddings.append(glove_vectors[token])\n\n        # Calculate the average embedding\n        if word_embeddings:\n            avg_embedding = np.mean(word_embeddings, axis=0)\n        else:\n            # Handle the case where none of the words were found in the vocabulary\n            avg_embedding = np.zeros(25)  # You can use a zero vector or other defaults\n\n        we.append(avg_embedding)\n\n    we = np.asarray(we)\n\n\n    #print(we.shape)\n\n\n\n\n\n    i = ii.float().to(device)\n    t = ti.float().to(device)\n\n\n    batch_size = i.shape[0]\n    optimizer.zero_grad()\n\n    logits, m = tinymodel(i,t, torch.tensor(we).to(device), train=False)\n    logits_no_exp,_ = tinymodel(i,t, torch.tensor(we).to(device), train=False, no_exp=True)\n    logits_only_exp,_ = tinymodel(i,t, torch.tensor(we).to(device), train=False,only_exp=True)\n    \n    \n  \n    #print(gol)\n    #print(logits_only_exp.argmax(dim=-1).item(), logits.argmax(dim=-1).item(), logits_no_exp.argmax(dim=-1).item())\n    \n    if gol[0]==logits_only_exp.argmax(dim=-1).item():\n        leakage.append(ids[0])\n    elif gol[0]!=logits_only_exp.argmax(dim=-1).item():\n        non_leakage.append(ids[0]) \n    \n    l = int(gol[0]==logits.argmax(dim=-1).item()) - int(gol[0]==logits_no_exp.argmax(dim=-1).item())\n    \n    global_dict[ids[0]] = l\n        \n    \n    #print(0/0)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.038259Z","iopub.status.idle":"2023-09-13T07:27:26.039058Z","shell.execute_reply.started":"2023-09-13T07:27:26.038763Z","shell.execute_reply":"2023-09-13T07:27:26.038786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l1,l2 = 0,0\nfor i in leakage:\n    l1+=global_dict[i]\nl1 = l1/len(leakage)\n\nfor i in non_leakage:\n    l2+=global_dict[i]\nl2 = l2/len(non_leakage)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.041083Z","iopub.status.idle":"2023-09-13T07:27:26.042189Z","shell.execute_reply.started":"2023-09-13T07:27:26.041826Z","shell.execute_reply":"2023-09-13T07:27:26.041860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"0.5*l1+0.5*l2","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.044181Z","iopub.status.idle":"2023-09-13T07:27:26.045272Z","shell.execute_reply.started":"2023-09-13T07:27:26.044913Z","shell.execute_reply":"2023-09-13T07:27:26.044963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l1,l2","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.046839Z","iopub.status.idle":"2023-09-13T07:27:26.047599Z","shell.execute_reply.started":"2023-09-13T07:27:26.047349Z","shell.execute_reply":"2023-09-13T07:27:26.047371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(leakage)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.048997Z","iopub.status.idle":"2023-09-13T07:27:26.049777Z","shell.execute_reply.started":"2023-09-13T07:27:26.049538Z","shell.execute_reply":"2023-09-13T07:27:26.049562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seed(42)\nal, alc,ti,op,tt,t_id = get_performance_test()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.051181Z","iopub.status.idle":"2023-09-13T07:27:26.051936Z","shell.execute_reply.started":"2023-09-13T07:27:26.051693Z","shell.execute_reply":"2023-09-13T07:27:26.051717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.tensor(tokenizer1.encode('[KB] trump are'))","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.053547Z","iopub.status.idle":"2023-09-13T07:27:26.054746Z","shell.execute_reply.started":"2023-09-13T07:27:26.054386Z","shell.execute_reply":"2023-09-13T07:27:26.054421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"al, alc,ti,op,tt,t_id = get_performance_test()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.056760Z","iopub.status.idle":"2023-09-13T07:27:26.057873Z","shell.execute_reply.started":"2023-09-13T07:27:26.057526Z","shell.execute_reply":"2023-09-13T07:27:26.057560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s = ['when', 'why', 'our']\nfinal_tokens = [\n   \"cops\",\n\"police\",\n\"gun\",\n\"logical\",\n\"criminal\",\n\"pos\",\n\"law\",\n\"logic\",\n\"crime\",\n\"unarmed\",\n\"comedy\",\n\"common\",\n\"criminals\",\n\"you\",\"when\", \"us\"\n]\n\nfinal_tokens = [i for i in final_tokens if (i not in s and len(i)>2)]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.059904Z","iopub.status.idle":"2023-09-13T07:27:26.060687Z","shell.execute_reply.started":"2023-09-13T07:27:26.060436Z","shell.execute_reply":"2023-09-13T07:27:26.060460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_tokens","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.062079Z","iopub.status.idle":"2023-09-13T07:27:26.062826Z","shell.execute_reply.started":"2023-09-13T07:27:26.062586Z","shell.execute_reply":"2023-09-13T07:27:26.062608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.064400Z","iopub.status.idle":"2023-09-13T07:27:26.065303Z","shell.execute_reply.started":"2023-09-13T07:27:26.065059Z","shell.execute_reply":"2023-09-13T07:27:26.065083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from gensim import corpora, models\n\n# def extract_central_concept_lda(token_list, num_topics=2, passes=10):\n#     # Create a dictionary from the token list\n#     dictionary = corpora.Dictionary([token_list])\n    \n#     # Create a document-term matrix\n#     doc_term_matrix = [dictionary.doc2bow(token_list)]\n    \n#     # Create an LDA model\n#     lda_model = models.LdaModel(doc_term_matrix, num_topics=num_topics, id2word=dictionary, passes=passes)\n    \n#     # Extract the top words from all topics\n#     topic_words = []\n#     for topic_id in range(num_topics):\n#         topic_words.extend([word for word, _ in lda_model.show_topic(topic_id)])\n    \n#     # Calculate the most common word among all topics\n#     central_concept = max(set(topic_words), key=topic_words.count)\n    \n#     return central_concept\n\n# # Example token list\n# token_list = [\"apple\", \"banana\", \"apple\", \"orange\", \"banana\", \"apple\", \"grape\"]\n\n# central_concept_lda = extract_central_concept_lda(token_list)\n# print(\"Central Concept (LDA):\", central_concept_lda)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.067110Z","iopub.status.idle":"2023-09-13T07:27:26.068251Z","shell.execute_reply.started":"2023-09-13T07:27:26.067886Z","shell.execute_reply":"2023-09-13T07:27:26.067920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m spacy download en_core_web_md","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.070256Z","iopub.status.idle":"2023-09-13T07:27:26.071367Z","shell.execute_reply.started":"2023-09-13T07:27:26.071018Z","shell.execute_reply":"2023-09-13T07:27:26.071053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import spacy\n\n# Load pre-trained word vectors model\nnlp = spacy.load(\"en_core_web_md\")\n\n\n\n\nfrom gensim.models import Word2Vec\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport numpy as np\nfrom collections import Counter\n\ndef extract_central_concept_word2vec(token_list):\n    # Train a Word2Vec model\n    model = Word2Vec([token_list], vector_size=100, window=5, min_count=1, sg=1)\n    \n    # Calculate the average vector for all tokens\n    #token_vectors = [model.wv[token] for token in token_list]\n    #avg_vector = np.mean(token_vectors, axis=0)\n    token_vectors = [nlp(token).vector for token in token_list]\n    avg_vector = sum(token_vectors) / len(token_vectors)\n    similar_words = nlp.vocab.vectors.most_similar(avg_vector.reshape(1, -1), n=10)\n    print(similar_words)\n    for i in similar_words[0][0]:\n        print(nlp.vocab.strings[i])\n    # Calculate cosine similarities between average vector and token vectors\n    #     similarities = cosine_similarity([avg_vector], token_vectors)\n\n    #     # Create a frequency counter for the words\n    #     word_frequencies = Counter(token_list)\n\n    #     # Find the most frequent word among the most similar tokens\n    #     central_word_index = np.argmax(similarities)\n    #     central_word = token_list[central_word_index]\n\n    #     return central_word\n\n\n\n\n# Example token list\ntoken_list = ['qaida',\n'jihadist',\n'iraqi',\n'islamist',\n'islamic',\n'muslim',\n'islam',\n'jihad']\n\ncentral_concept_word_vectors = extract_central_concept_word2vec(token_list)\nprint(\"Central Concept (Word Vectors):\", central_concept_word_vectors)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.073266Z","iopub.status.idle":"2023-09-13T07:27:26.074069Z","shell.execute_reply.started":"2023-09-13T07:27:26.073777Z","shell.execute_reply":"2023-09-13T07:27:26.073801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp.vocab.vectors.most_similar","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.075425Z","iopub.status.idle":"2023-09-13T07:27:26.076183Z","shell.execute_reply.started":"2023-09-13T07:27:26.075928Z","shell.execute_reply":"2023-09-13T07:27:26.075968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/FreddeFrallan/Non-Residual-Prompting","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.077569Z","iopub.status.idle":"2023-09-13T07:27:26.078330Z","shell.execute_reply.started":"2023-09-13T07:27:26.078089Z","shell.execute_reply":"2023-09-13T07:27:26.078113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -r /kaggle/working/Non-Residual-Prompting/requirements.txt","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.079888Z","iopub.status.idle":"2023-09-13T07:27:26.081028Z","shell.execute_reply.started":"2023-09-13T07:27:26.080678Z","shell.execute_reply":"2023-09-13T07:27:26.080715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tt","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.082474Z","iopub.status.idle":"2023-09-13T07:27:26.083309Z","shell.execute_reply.started":"2023-09-13T07:27:26.083047Z","shell.execute_reply":"2023-09-13T07:27:26.083073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!bash '/kaggle/working/Non-Residual-Prompting/inference.sh'","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.084797Z","iopub.status.idle":"2023-09-13T07:27:26.085717Z","shell.execute_reply.started":"2023-09-13T07:27:26.085352Z","shell.execute_reply":"2023-09-13T07:27:26.085378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python /kaggle/working/Non-Residual-Prompting/InferenceExample.py","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.087444Z","iopub.status.idle":"2023-09-13T07:27:26.088221Z","shell.execute_reply.started":"2023-09-13T07:27:26.087976Z","shell.execute_reply":"2023-09-13T07:27:26.088000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_id","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.089608Z","iopub.status.idle":"2023-09-13T07:27:26.090398Z","shell.execute_reply.started":"2023-09-13T07:27:26.090155Z","shell.execute_reply":"2023-09-13T07:27:26.090180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_aware_token_idx = []\noutput_aware_tokens = []\nfor i in op.topk(5000).indices:\n    k = model1.transformer.wte(i.cuda()).detach().cpu().unsqueeze(1)\n    \n    #output_aware_token_idx.append(ti.mm(k))\n    val = torch.nn.functional.cosine_similarity(ti,k.T)[0].item()\n    if val>0:\n        output_aware_token_idx.append(val)\n        output_aware_tokens.append(tokenizer1.decode(i))\n    #     print('{} -> {}'.format(tokenizer1.decode(i), ti.mm(k).squeeze()))\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.098402Z","iopub.status.idle":"2023-09-13T07:27:26.099186Z","shell.execute_reply.started":"2023-09-13T07:27:26.098915Z","shell.execute_reply":"2023-09-13T07:27:26.098964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_aware_tokens = list(map(lambda x: x.strip().lower(), output_aware_tokens))","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.100609Z","iopub.status.idle":"2023-09-13T07:27:26.101384Z","shell.execute_reply.started":"2023-09-13T07:27:26.101140Z","shell.execute_reply":"2023-09-13T07:27:26.101164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_aware_tokens[0:10]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.102772Z","iopub.status.idle":"2023-09-13T07:27:26.103545Z","shell.execute_reply.started":"2023-09-13T07:27:26.103301Z","shell.execute_reply":"2023-09-13T07:27:26.103324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_aware_token_idx[0:10]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.104973Z","iopub.status.idle":"2023-09-13T07:27:26.105726Z","shell.execute_reply.started":"2023-09-13T07:27:26.105485Z","shell.execute_reply":"2023-09-13T07:27:26.105507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(output_aware_token_idx)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.107175Z","iopub.status.idle":"2023-09-13T07:27:26.107922Z","shell.execute_reply.started":"2023-09-13T07:27:26.107680Z","shell.execute_reply":"2023-09-13T07:27:26.107703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image = preprocess(Image.open('./data/img/28197.png')).unsqueeze(0).to(device)\n\n# clip_feats = []\n# for i in tqdm(output_aware_tokens):\n#     text = clip.tokenize([i]).to(device)\n\n#     with torch.no_grad():\n#         image_features = model.encode_image(image)\n#         text_features = model.encode_text(text)\n#         clip_feats.append(torch.nn.functional.cosine_similarity(image_features, text_features)[0].item())\n#         #clip_feats.append(image_features.mm(text_features.T).squeeze().detach().cpu().item())\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.116031Z","iopub.status.idle":"2023-09-13T07:27:26.116797Z","shell.execute_reply.started":"2023-09-13T07:27:26.116553Z","shell.execute_reply":"2023-09-13T07:27:26.116576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = preprocess(Image.open('./data/'+t_id)).unsqueeze(0).to(device)\ntext = clip.tokenize(output_aware_tokens).to(device)\n# clip_feats = []\ntext_cand = clip.tokenize(tt).to(device)\n\n    \n\nwith torch.no_grad():\n    if_ = model.encode_image(image)\n    tf_ = model.encode_text(text_cand)\n    \n    print(if_.shape, tf_.shape)\n    multimodal_features = (if_+tf_)/2\n    text_features = model.encode_text(text)\n    \n    clip_feats = torch.nn.functional.cosine_similarity(multimodal_features, text_features, dim=1)\n\n\nclip_feats = clip_feats.cpu().numpy().tolist()\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.118255Z","iopub.status.idle":"2023-09-13T07:27:26.119029Z","shell.execute_reply.started":"2023-09-13T07:27:26.118754Z","shell.execute_reply":"2023-09-13T07:27:26.118777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(clip_feats)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.120401Z","iopub.status.idle":"2023-09-13T07:27:26.121183Z","shell.execute_reply.started":"2023-09-13T07:27:26.120910Z","shell.execute_reply":"2023-09-13T07:27:26.120960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_aware_tokens[0:10]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.122637Z","iopub.status.idle":"2023-09-13T07:27:26.123425Z","shell.execute_reply.started":"2023-09-13T07:27:26.123178Z","shell.execute_reply":"2023-09-13T07:27:26.123203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clip_feats[0:10]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.124803Z","iopub.status.idle":"2023-09-13T07:27:26.125580Z","shell.execute_reply.started":"2023-09-13T07:27:26.125330Z","shell.execute_reply":"2023-09-13T07:27:26.125353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max(clip_feats), min(clip_feats)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.134214Z","iopub.status.idle":"2023-09-13T07:27:26.135012Z","shell.execute_reply.started":"2023-09-13T07:27:26.134738Z","shell.execute_reply":"2023-09-13T07:27:26.134761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_aware_token_idx[0:10]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.136501Z","iopub.status.idle":"2023-09-13T07:27:26.137559Z","shell.execute_reply.started":"2023-09-13T07:27:26.137315Z","shell.execute_reply":"2023-09-13T07:27:26.137338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max(output_aware_token_idx), min(output_aware_token_idx)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.138999Z","iopub.status.idle":"2023-09-13T07:27:26.139801Z","shell.execute_reply.started":"2023-09-13T07:27:26.139527Z","shell.execute_reply":"2023-09-13T07:27:26.139551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_feats = []","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.141228Z","iopub.status.idle":"2023-09-13T07:27:26.142008Z","shell.execute_reply.started":"2023-09-13T07:27:26.141735Z","shell.execute_reply":"2023-09-13T07:27:26.141759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,j in zip(output_aware_token_idx, clip_feats):\n    #tmp = 2*i*j/(i+j)\n    tmp = 1.0*j+0.05*i\n    #tmp = j\n    combined_feats.append(tmp)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.143410Z","iopub.status.idle":"2023-09-13T07:27:26.144187Z","shell.execute_reply.started":"2023-09-13T07:27:26.143916Z","shell.execute_reply":"2023-09-13T07:27:26.143964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.argsort(combined_feats)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.150742Z","iopub.status.idle":"2023-09-13T07:27:26.151568Z","shell.execute_reply.started":"2023-09-13T07:27:26.151284Z","shell.execute_reply":"2023-09-13T07:27:26.151307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in np.argsort(combined_feats)[-1:-20:-1]:\n    print(output_aware_tokens[i])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.153021Z","iopub.status.idle":"2023-09-13T07:27:26.153779Z","shell.execute_reply.started":"2023-09-13T07:27:26.153534Z","shell.execute_reply":"2023-09-13T07:27:26.153559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in np.argsort(combined_feats)[-1:-10:-1]:\n    print(output_aware_tokens[i])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.155171Z","iopub.status.idle":"2023-09-13T07:27:26.155923Z","shell.execute_reply.started":"2023-09-13T07:27:26.155674Z","shell.execute_reply":"2023-09-13T07:27:26.155697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_aware_tokens[138]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.157336Z","iopub.status.idle":"2023-09-13T07:27:26.158115Z","shell.execute_reply.started":"2023-09-13T07:27:26.157843Z","shell.execute_reply":"2023-09-13T07:27:26.157866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_features.mm(text_features.T)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.160913Z","iopub.status.idle":"2023-09-13T07:27:26.161691Z","shell.execute_reply.started":"2023-09-13T07:27:26.161446Z","shell.execute_reply":"2023-09-13T07:27:26.161470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_features.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.163987Z","iopub.status.idle":"2023-09-13T07:27:26.165295Z","shell.execute_reply.started":"2023-09-13T07:27:26.165044Z","shell.execute_reply":"2023-09-13T07:27:26.165069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fp = text_features.mm(image_features.T)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.167912Z","iopub.status.idle":"2023-09-13T07:27:26.168729Z","shell.execute_reply.started":"2023-09-13T07:27:26.168465Z","shell.execute_reply":"2023-09-13T07:27:26.168488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_aware_token_idx = torch.stack(output_aware_token_idx).squeeze()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.170476Z","iopub.status.idle":"2023-09-13T07:27:26.171248Z","shell.execute_reply.started":"2023-09-13T07:27:26.171006Z","shell.execute_reply":"2023-09-13T07:27:26.171030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_aware_token_idx = output_aware_token_idx.unsqueeze(1) ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.172632Z","iopub.status.idle":"2023-09-13T07:27:26.173417Z","shell.execute_reply.started":"2023-09-13T07:27:26.173173Z","shell.execute_reply":"2023-09-13T07:27:26.173197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fp.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.174797Z","iopub.status.idle":"2023-09-13T07:27:26.175570Z","shell.execute_reply.started":"2023-09-13T07:27:26.175326Z","shell.execute_reply":"2023-09-13T07:27:26.175349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_aware_token_idx.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.177005Z","iopub.status.idle":"2023-09-13T07:27:26.177866Z","shell.execute_reply.started":"2023-09-13T07:27:26.177589Z","shell.execute_reply":"2023-09-13T07:27:26.177616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fin_feats = (fp.cpu()+output_aware_token_idx.cpu())/2","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.179793Z","iopub.status.idle":"2023-09-13T07:27:26.180777Z","shell.execute_reply.started":"2023-09-13T07:27:26.180532Z","shell.execute_reply":"2023-09-13T07:27:26.180555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fin_feats.squeeze().argsort()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.182210Z","iopub.status.idle":"2023-09-13T07:27:26.183016Z","shell.execute_reply.started":"2023-09-13T07:27:26.182730Z","shell.execute_reply":"2023-09-13T07:27:26.182753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in fin_feats.squeeze().argsort():\n    print(output_aware_tokens[i])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.184461Z","iopub.status.idle":"2023-09-13T07:27:26.185249Z","shell.execute_reply.started":"2023-09-13T07:27:26.185004Z","shell.execute_reply":"2023-09-13T07:27:26.185028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_aware_token_idx.argsort()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.186651Z","iopub.status.idle":"2023-09-13T07:27:26.187458Z","shell.execute_reply.started":"2023-09-13T07:27:26.187216Z","shell.execute_reply":"2023-09-13T07:27:26.187240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_idx = op.topk(500).indices","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.188858Z","iopub.status.idle":"2023-09-13T07:27:26.189644Z","shell.execute_reply.started":"2023-09-13T07:27:26.189394Z","shell.execute_reply":"2023-09-13T07:27:26.189417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_idx","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.191081Z","iopub.status.idle":"2023-09-13T07:27:26.191820Z","shell.execute_reply.started":"2023-09-13T07:27:26.191579Z","shell.execute_reply":"2023-09-13T07:27:26.191604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in output_aware_token_idx.argsort():\n    print(tokenizer1.decode(all_idx[i.item()]))\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.193167Z","iopub.status.idle":"2023-09-13T07:27:26.193903Z","shell.execute_reply.started":"2023-09-13T07:27:26.193663Z","shell.execute_reply":"2023-09-13T07:27:26.193686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_aware_token_idx.argmax()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.195255Z","iopub.status.idle":"2023-09-13T07:27:26.196018Z","shell.execute_reply.started":"2023-09-13T07:27:26.195751Z","shell.execute_reply":"2023-09-13T07:27:26.195775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer1.decode(op.topk(50).indices[output_aware_token_idx.argmax().item()])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.197372Z","iopub.status.idle":"2023-09-13T07:27:26.198143Z","shell.execute_reply.started":"2023-09-13T07:27:26.197875Z","shell.execute_reply":"2023-09-13T07:27:26.197899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer1.encode('deformity')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.199457Z","iopub.status.idle":"2023-09-13T07:27:26.200218Z","shell.execute_reply.started":"2023-09-13T07:27:26.199972Z","shell.execute_reply":"2023-09-13T07:27:26.199996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer1.decode([40720, 48443])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.201549Z","iopub.status.idle":"2023-09-13T07:27:26.202307Z","shell.execute_reply.started":"2023-09-13T07:27:26.202068Z","shell.execute_reply":"2023-09-13T07:27:26.202092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k = model1.transformer.wte(torch.tensor(tokenizer1.encode('')).cuda()).detach().cpu()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.203632Z","iopub.status.idle":"2023-09-13T07:27:26.204390Z","shell.execute_reply.started":"2023-09-13T07:27:26.204148Z","shell.execute_reply":"2023-09-13T07:27:26.204171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k = k.mean(dim=0).unsqueeze(0)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.205715Z","iopub.status.idle":"2023-09-13T07:27:26.206499Z","shell.execute_reply.started":"2023-09-13T07:27:26.206238Z","shell.execute_reply":"2023-09-13T07:27:26.206262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.207820Z","iopub.status.idle":"2023-09-13T07:27:26.208615Z","shell.execute_reply.started":"2023-09-13T07:27:26.208375Z","shell.execute_reply":"2023-09-13T07:27:26.208398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ti.mm(k.T)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.210060Z","iopub.status.idle":"2023-09-13T07:27:26.210793Z","shell.execute_reply.started":"2023-09-13T07:27:26.210547Z","shell.execute_reply":"2023-09-13T07:27:26.210570Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokens_index = torch.mm(ti, E_.T)[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.212140Z","iopub.status.idle":"2023-09-13T07:27:26.212883Z","shell.execute_reply.started":"2023-09-13T07:27:26.212642Z","shell.execute_reply":"2023-09-13T07:27:26.212665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokens_index.topk(2)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.214284Z","iopub.status.idle":"2023-09-13T07:27:26.215052Z","shell.execute_reply.started":"2023-09-13T07:27:26.214778Z","shell.execute_reply":"2023-09-13T07:27:26.214801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"itm = tokens_index.topk(2).indices[-1].item()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.216377Z","iopub.status.idle":"2023-09-13T07:27:26.217152Z","shell.execute_reply.started":"2023-09-13T07:27:26.216875Z","shell.execute_reply":"2023-09-13T07:27:26.216899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"itm","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.218478Z","iopub.status.idle":"2023-09-13T07:27:26.219274Z","shell.execute_reply.started":"2023-09-13T07:27:26.218999Z","shell.execute_reply":"2023-09-13T07:27:26.219022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"E_ = E.detach().cpu()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.220597Z","iopub.status.idle":"2023-09-13T07:27:26.221350Z","shell.execute_reply.started":"2023-09-13T07:27:26.221104Z","shell.execute_reply":"2023-09-13T07:27:26.221128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"E_ += E.detach().cpu()[itm,:]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.222674Z","iopub.status.idle":"2023-09-13T07:27:26.223441Z","shell.execute_reply.started":"2023-09-13T07:27:26.223201Z","shell.execute_reply":"2023-09-13T07:27:26.223224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"E_.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.224778Z","iopub.status.idle":"2023-09-13T07:27:26.225539Z","shell.execute_reply.started":"2023-09-13T07:27:26.225298Z","shell.execute_reply":"2023-09-13T07:27:26.225320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.transformer.wte.weight","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.226875Z","iopub.status.idle":"2023-09-13T07:27:26.227650Z","shell.execute_reply.started":"2023-09-13T07:27:26.227410Z","shell.execute_reply":"2023-09-13T07:27:26.227433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# grad_.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.228985Z","iopub.status.idle":"2023-09-13T07:27:26.229752Z","shell.execute_reply.started":"2023-09-13T07:27:26.229479Z","shell.execute_reply":"2023-09-13T07:27:26.229503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"E.T.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.231114Z","iopub.status.idle":"2023-09-13T07:27:26.231851Z","shell.execute_reply.started":"2023-09-13T07:27:26.231606Z","shell.execute_reply":"2023-09-13T07:27:26.231631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"E.detach().cpu()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.233201Z","iopub.status.idle":"2023-09-13T07:27:26.233969Z","shell.execute_reply.started":"2023-09-13T07:27:26.233702Z","shell.execute_reply":"2023-09-13T07:27:26.233724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"al, alc,ti,op = get_performance_test()\nl2l = {'normal':0, 'offensive':1}\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.235349Z","iopub.status.idle":"2023-09-13T07:27:26.236109Z","shell.execute_reply.started":"2023-09-13T07:27:26.235836Z","shell.execute_reply":"2023-09-13T07:27:26.235859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"al, alc = get_performance_test_nm()\nl2l = {'normal':0, 'offensive':1}\nal_ = list(map(lambda x: l2l[x.strip()], al))\nalc_ = list(map(lambda x: l2l[x.strip()], alc))\nprint(f1_score(gl_test, al_, average='macro'), f1_score(gl_test, alc_, average='macro'))\nprint(accuracy_score(gl_test, al_), accuracy_score(gl_test, alc_))","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.237579Z","iopub.status.idle":"2023-09-13T07:27:26.238349Z","shell.execute_reply.started":"2023-09-13T07:27:26.238106Z","shell.execute_reply":"2023-09-13T07:27:26.238129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gl_test  = []\nfor _,_,g,_ in test_dataset:\n    gl_test.append(g)","metadata":{"id":"vsOg7-PIC7ry","execution":{"iopub.status.busy":"2023-09-13T07:27:26.239730Z","iopub.status.idle":"2023-09-13T07:27:26.240520Z","shell.execute_reply.started":"2023-09-13T07:27:26.240254Z","shell.execute_reply":"2023-09-13T07:27:26.240278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gl_test","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.241834Z","iopub.status.idle":"2023-09-13T07:27:26.242600Z","shell.execute_reply.started":"2023-09-13T07:27:26.242360Z","shell.execute_reply":"2023-09-13T07:27:26.242382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.243925Z","iopub.status.idle":"2023-09-13T07:27:26.244688Z","shell.execute_reply.started":"2023-09-13T07:27:26.244445Z","shell.execute_reply":"2023-09-13T07:27:26.244469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# E[tokenizer1.encode(tokenizer1.eos_token),:]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.246088Z","iopub.status.idle":"2023-09-13T07:27:26.246851Z","shell.execute_reply.started":"2023-09-13T07:27:26.246610Z","shell.execute_reply":"2023-09-13T07:27:26.246633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# all_labs = []\n# for ii in tqdm(range(500)):  \n#     dix = {0:'normal', 1:'offensive'}\n\n#     i = im_tensor_[ii,:].unsqueeze(0)\n#     t = tx_tensor_[ii,:].unsqueeze(0)\n#     #     print(i.shape, t.shape)\n#     i = i.float().to(device)\n#     t = t.float().to(device)\n#     batch_size = i.shape[0]\n#     optimizer.zero_grad()\n#     optimizer1.zero_grad()\n#     logits, m = tinymodel(i,t)\n#     # print(m)\n#     m = m.unsqueeze(dim=1)\n\n#     gumbel_logits = F.gumbel_softmax(logits, tau=1, hard=True)\n#     # print(gumbel_logits)\n#     agmx = gumbel_logits.argmax(dim=1)\n    \n\n#     # print(agmx, logits.argmax(dim=1))\n#     prmpt0, lab0 = get_tokens([tokenizer1.eos_token]*batch_size)\n#     prpmt = ['model thinks the meme is ']*batch_size\n\n#     portion1,lab1 = get_tokens(prpmt,begin=True)\n#     portion2,lab3 = get_tokens(['output of the classifier multimodal embedding is ']*batch_size)\n#     lab4 = [tokenizer1.encode('-')[:] for i in range(batch_size)]\n#     lab4 = torch.tensor(lab4)\n\n#     # portion3 = get_tokens(['the meme is actually'])\n\n\n\n\n\n\n#     kk = []\n#     labs_verbalized = []\n#     # batch_prompt = ['the model thinks the meme is ']*32\n#     lab2 = []\n#     for i in gumbel_logits:\n#         agmx = i.argmax()\n#         # print(agmx)\n#         # print(dix[agmx.item()])\n#         tokenized_ = tokenizer1.encode(dix[agmx.item()])[:]\n#         labs_verbalized.append(dix[agmx.item()])\n#         # print(tokenized_)\n#         lab2.append(tokenized_)\n#         embedding = E[tokenized_[0]]\n#         one_hot = i.view(-1, 1)\n#         # print(embedding.shape, one_hot, one_hot.shape)\n\n#         e = torch.sum(one_hot*embedding, dim=0)\n#         kk.append(e)\n#     lab2 = torch.tensor(lab2)\n#     string = ['the meme is actually']\n#     portion3,lab5 = get_tokens(string)\n#     inp_embed = torch.stack(kk).unsqueeze(dim=1)\n#     # print(inp_embed)\n#     # print(inp_embed.shape)\n#     # print(portion1.shape,inp_embed.shape,portion2.shape,m.shape,portion3.shape)\n#     final_embeds = torch.cat((prmpt0,portion1,inp_embed,portion2,m,portion3),dim=1)\n#     # print(final_embeds.shape)\n#     # print(lab1.shape, lab2.shape, lab3.shape, lab4.shape, lab5.shape)\n#     labs = torch.cat((lab0,lab1,lab2,lab3,lab4,lab5),dim=1)\n#     #     print(final_embeds.shape, labs.shape)\n#     # print(0/0)\n#     #     print(tokenizer1.batch_decode(labs))\n#     output2 = model1(inputs_embeds = final_embeds.half())\n#     #     print(output2.logits.argmax(dim=-1))\n#     llm_lab = tokenizer1.decode(output2.logits.argmax(dim=-1)[0][-1])\n#     all_labs.append(llm_lab)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.248252Z","iopub.status.idle":"2023-09-13T07:27:26.248916Z","shell.execute_reply.started":"2023-09-13T07:27:26.248730Z","shell.execute_reply":"2023-09-13T07:27:26.248748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output2.logits.argmax(dim=-1)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.250305Z","iopub.status.idle":"2023-09-13T07:27:26.251066Z","shell.execute_reply.started":"2023-09-13T07:27:26.250797Z","shell.execute_reply":"2023-09-13T07:27:26.250820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer1.batch_decode(output2.logits.argmax(dim=-1))","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.252412Z","iopub.status.idle":"2023-09-13T07:27:26.253177Z","shell.execute_reply.started":"2023-09-13T07:27:26.252918Z","shell.execute_reply":"2023-09-13T07:27:26.252965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# all_labs_clf_","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.254506Z","iopub.status.idle":"2023-09-13T07:27:26.255261Z","shell.execute_reply.started":"2023-09-13T07:27:26.255019Z","shell.execute_reply":"2023-09-13T07:27:26.255043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_score(gl_test, all_labs_, average='macro')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.256618Z","iopub.status.idle":"2023-09-13T07:27:26.257381Z","shell.execute_reply.started":"2023-09-13T07:27:26.257130Z","shell.execute_reply":"2023-09-13T07:27:26.257160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(gl_test, all_labs_)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.258689Z","iopub.status.idle":"2023-09-13T07:27:26.259458Z","shell.execute_reply.started":"2023-09-13T07:27:26.259218Z","shell.execute_reply":"2023-09-13T07:27:26.259241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"balanced_accuracy_score(gl_test, all_labs_)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T07:27:26.260790Z","iopub.status.idle":"2023-09-13T07:27:26.261586Z","shell.execute_reply.started":"2023-09-13T07:27:26.261344Z","shell.execute_reply":"2023-09-13T07:27:26.261367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntokenizer1.decode(tokenizer1.encode('offensive')[1:])","metadata":{"id":"TjSMrd4zRFM9","outputId":"33aee683-f35e-43b2-fc44-e6d63aafc63b","execution":{"iopub.status.busy":"2023-09-13T07:27:26.262910Z","iopub.status.idle":"2023-09-13T07:27:26.263685Z","shell.execute_reply.started":"2023-09-13T07:27:26.263441Z","shell.execute_reply":"2023-09-13T07:27:26.263465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.manual_seed(0)\nimport random\nrandom.seed(0)\nimport numpy as np\nnp.random.seed(0)\ntinymodel = TinyModel(mdl,rand=False).to(device)\n# E = model1.transformer.wte.weight.detach()\nE = model1.model.model.embed_tokens.weight.detach()\noptimizer = optim.Adam(tinymodel.parameters(), lr=0.0005)\noptimizer1 = optim.Adam(model1.parameters(), lr=0.0005)\ndix = {0:'normal', 1:'offensive'}\n\n# Training loop\nnum_epochs = 10\ndef transpose(x):\n    return x.transpose(-2, -1)\n\nfor epoch in range(num_epochs):\n  l=0\n  cnt = 0\n  l_lm = 0\n  l_clf = 0\n  tinymodel.train()\n  for i,t, gol in dataloader:\n      # print(batch_model1, batch_model1)\n      i = i.float().to(device)\n      t = t.float().to(device)\n      batch_size = i.shape[0]\n      optimizer.zero_grad()\n      optimizer1.zero_grad()\n      logits, m = tinymodel(i,t)\n      # print(m)\n      m = m.unsqueeze(dim=1)\n\n      gumbel_logits = F.gumbel_softmax(logits, tau=1, hard=True)\n      # print(gumbel_logits)\n      agmx = gumbel_logits.argmax(dim=1)\n\n      # print(agmx, logits.argmax(dim=1))\n      prpmt = ['model thinks the meme is ']*batch_size\n\n      portion1,lab1 = get_tokens(prpmt,begin=True)\n      portion2,lab3 = get_tokens(['output of the classifier multimodal embedding is ']*batch_size)\n      lab4 = [tokenizer1.encode('-')[1:] for i in range(batch_size)]\n      lab4 = torch.tensor(lab4)\n\n      # portion3 = get_tokens(['the meme is actually'])\n\n\n\n\n\n\n      kk = []\n      labs_verbalized = []\n      # batch_prompt = ['the model thinks the meme is ']*32\n      lab2 = []\n      for i in gumbel_logits:\n        agmx = i.argmax()\n        # print(agmx)\n        # print(dix[agmx.item()])\n        tokenized_ = tokenizer1.encode(dix[agmx.item()])[1:]\n        labs_verbalized.append(dix[agmx.item()])\n        # print(tokenized_)\n        lab2.append(tokenized_)\n        embedding = E[tokenized_[0]]\n        one_hot = i.view(-1, 1)\n        # print(embedding.shape, one_hot, one_hot.shape)\n\n        e = torch.sum(one_hot*embedding, dim=0)\n        kk.append(e)\n      lab2 = torch.tensor(lab2)\n      string = ['the meme is actually {}'.format(i) for i in labs_verbalized]\n      portion3,lab5 = get_tokens(string)\n      inp_embed = torch.stack(kk).unsqueeze(dim=1)\n      # print(inp_embed)\n      # print(inp_embed.shape)\n      # print(portion1.shape,inp_embed.shape,portion2.shape,m.shape,portion3.shape)\n      final_embeds = torch.cat((portion1,inp_embed,portion2,m,portion3),dim=1)\n      # print(final_embeds.shape)\n      # print(lab1.shape, lab2.shape, lab3.shape, lab4.shape, lab5.shape)\n      labs = torch.cat((lab1,lab2,lab3,lab4,lab5),dim=1)\n      print(final_embeds.shape, labs.shape)\n      # print(0/0)\n      output2 = model1(inputs_embeds = final_embeds.half(), labels = labs.long())\n      # print(output2.loss)\n      # print(0/0)\n      loss_lm = output2.loss\n\n\n\n\n      loss_clf = torch.nn.functional.cross_entropy(logits, gol.to(device), reduction='mean')\n\n      loss = loss_lm+loss_clf\n\n      loss.backward()\n      optimizer.step()\n      optimizer1.step()\n\n\n      l+=loss.detach().item()\n      l_clf+=loss_clf.detach().item()\n      l_lm+=loss_lm.detach().item()\n      cnt+=1\n\n  print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {l/cnt}, Loss clf: {l_clf/cnt}, Loss llm: {l_lm/cnt}\")\n  tinymodel.eval()\n  pred,_ = tinymodel(im_tensor_.float().to(device),tx_tensor_.float().to(device))\n  pred = pred.argmax(dim=1).detach().cpu().numpy()\n  print(f1_score(gl_, pred, average='macro'), accuracy_score(gl_, pred))\nprint(\"Training complete!\")\n","metadata":{"id":"r8WofzVT2GNh","outputId":"4eb6cee6-0623-465d-f5e0-9106919c5040","execution":{"iopub.status.busy":"2023-09-13T07:27:26.265110Z","iopub.status.idle":"2023-09-13T07:27:26.265835Z","shell.execute_reply.started":"2023-09-13T07:27:26.265597Z","shell.execute_reply":"2023-09-13T07:27:26.265619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dix = {0:'normal', 1:'offensive'}\n\ni = im_tensor_[0,:].unsqueeze(0)\nt = tx_tensor_[0,:].unsqueeze(0)\nprint(i.shape, t.shape)\ni = i.float().to(device)\nt = t.float().to(device)\nbatch_size = i.shape[0]\noptimizer.zero_grad()\noptimizer1.zero_grad()\nlogits, m = tinymodel(i,t)\n# print(m)\nm = m.unsqueeze(dim=1)\n\ngumbel_logits = F.gumbel_softmax(logits, tau=1, hard=True)\n# print(gumbel_logits)\nagmx = gumbel_logits.argmax(dim=1)\n\n# print(agmx, logits.argmax(dim=1))\nprpmt = ['model thinks the meme is ']*batch_size\n\nportion1,lab1 = get_tokens(prpmt,begin=True)\nportion2,lab3 = get_tokens(['output of the classifier multimodal embedding is ']*batch_size)\nlab4 = [tokenizer1.encode('-')[1:] for i in range(batch_size)]\nlab4 = torch.tensor(lab4)\n\n# portion3 = get_tokens(['the meme is actually'])\n\n\n\n\n\n\nkk = []\nlabs_verbalized = []\n# batch_prompt = ['the model thinks the meme is ']*32\nlab2 = []\nfor i in gumbel_logits:\n  agmx = i.argmax()\n  # print(agmx)\n  # print(dix[agmx.item()])\n  tokenized_ = tokenizer1.encode(dix[agmx.item()])[1:]\n  labs_verbalized.append(dix[agmx.item()])\n  # print(tokenized_)\n  lab2.append(tokenized_)\n  embedding = E[tokenized_[0]]\n  one_hot = i.view(-1, 1)\n  # print(embedding.shape, one_hot, one_hot.shape)\n\n  e = torch.sum(one_hot*embedding, dim=0)\n  kk.append(e)\nlab2 = torch.tensor(lab2)\nstring = ['the meme is actually {}'.format(i) for i in labs_verbalized]\nportion3,lab5 = get_tokens(string)\ninp_embed = torch.stack(kk).unsqueeze(dim=1)\n# print(inp_embed)\n# print(inp_embed.shape)\n# print(portion1.shape,inp_embed.shape,portion2.shape,m.shape,portion3.shape)\nfinal_embeds = torch.cat((portion1,inp_embed,portion2,m,portion3),dim=1)\n# print(final_embeds.shape)\n# print(lab1.shape, lab2.shape, lab3.shape, lab4.shape, lab5.shape)\nlabs = torch.cat((lab1,lab2,lab3,lab4,lab5),dim=1)\nprint(final_embeds.shape, labs.shape)\n# print(0/0)\noutput2 = model1(inputs_embeds = final_embeds.half(), labels = labs.long())","metadata":{"id":"q4oeqJ0ZUwWF","outputId":"959b8b20-f8c7-4432-b623-1c9bcf9c993e","execution":{"iopub.status.busy":"2023-09-13T07:27:26.267291Z","iopub.status.idle":"2023-09-13T07:27:26.268059Z","shell.execute_reply.started":"2023-09-13T07:27:26.267789Z","shell.execute_reply":"2023-09-13T07:27:26.267813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output2","metadata":{"id":"XWGTNotjV8tl","outputId":"bfcb5274-1fe8-4cd7-bf15-8a4b77193756","execution":{"iopub.status.busy":"2023-09-13T07:27:26.269388Z","iopub.status.idle":"2023-09-13T07:27:26.270208Z","shell.execute_reply.started":"2023-09-13T07:27:26.269924Z","shell.execute_reply":"2023-09-13T07:27:26.269976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import torch\n# torch.manual_seed(0)\n# import random\n# random.seed(0)\n# import numpy as np\n# np.random.seed(0)\n# tinymodel = TinyModel(mdl_rand,rand=False).to(device)\n# optimizer = optim.Adam(tinymodel.parameters(), lr=0.0005)\n\n\n# # Training loop\n# num_epochs = 10\n# def transpose(x):\n#     return x.transpose(-2, -1)\n\n# for epoch in range(num_epochs):\n#   l=0\n#   cnt = 0\n#   tinymodel.train()\n#   for i,t, gol in dataloader:\n#       # print(batch_model1, batch_model1)\n#       i = i.float().to(device)\n#       t = t.float().to(device)\n\n#       optimizer.zero_grad()\n#       logits = tinymodel(i,t)\n#       # b = model2(batch_model2)\n\n\n\n#       loss = torch.nn.functional.cross_entropy(logits, gol.to(device), reduction='mean')\n#       loss.backward()\n#       optimizer.step()\n\n\n#       l+=loss.detach().item()\n#       cnt+=1\n\n#   print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {l/cnt}\")\n#   tinymodel.eval()\n#   pred = tinymodel(im_tensor_.float().to(device),tx_tensor_.float().to(device))\n#   pred = pred.argmax(dim=1).detach().cpu().numpy()\n#   print(f1_score(gl_, pred, average='macro'), accuracy_score(gl_, pred))\n# print(\"Training complete!\")\n","metadata":{"id":"aR2jVNQ8xxAP","execution":{"iopub.status.busy":"2023-09-13T07:27:26.271855Z","iopub.status.idle":"2023-09-13T07:27:26.272630Z","shell.execute_reply.started":"2023-09-13T07:27:26.272385Z","shell.execute_reply":"2023-09-13T07:27:26.272411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im_tensor_.shape","metadata":{"id":"x7cZU7kAeeKU","outputId":"bad513ac-1393-47b9-9828-0246d5d08371","execution":{"iopub.status.busy":"2023-09-13T07:27:26.273974Z","iopub.status.idle":"2023-09-13T07:27:26.274717Z","shell.execute_reply.started":"2023-09-13T07:27:26.274476Z","shell.execute_reply":"2023-09-13T07:27:26.274499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tinymodel.eval()\npred = tinymodel(im_tensor_.float().to(device),tx_tensor_.float().to(device))","metadata":{"id":"-ykiP2PM2GQI","execution":{"iopub.status.busy":"2023-09-13T07:27:26.276105Z","iopub.status.idle":"2023-09-13T07:27:26.276835Z","shell.execute_reply.started":"2023-09-13T07:27:26.276592Z","shell.execute_reply":"2023-09-13T07:27:26.276615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = pred.argmax(dim=1).detach().cpu().numpy()","metadata":{"id":"_hB7T7YC2GSN","execution":{"iopub.status.busy":"2023-09-13T07:27:26.278212Z","iopub.status.idle":"2023-09-13T07:27:26.278981Z","shell.execute_reply.started":"2023-09-13T07:27:26.278714Z","shell.execute_reply":"2023-09-13T07:27:26.278737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred","metadata":{"id":"PjB7csnw1pl_","outputId":"453d1727-bd54-43fa-824f-256efee1619d","execution":{"iopub.status.busy":"2023-09-13T07:27:26.280307Z","iopub.status.idle":"2023-09-13T07:27:26.281070Z","shell.execute_reply.started":"2023-09-13T07:27:26.280800Z","shell.execute_reply":"2023-09-13T07:27:26.280823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gl_","metadata":{"id":"_2A0cSdL-Knk","outputId":"4cd3827f-5741-4585-e5d0-9dde52375fdc","execution":{"iopub.status.busy":"2023-09-13T07:27:26.282451Z","iopub.status.idle":"2023-09-13T07:27:26.283211Z","shell.execute_reply.started":"2023-09-13T07:27:26.282969Z","shell.execute_reply":"2023-09-13T07:27:26.282994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import *\nf1_score(gl_, pred, average='macro'), accuracy_score(gl_, pred)","metadata":{"id":"KVT6bWGx5z1Z","outputId":"25ea5227-5103-4c4b-a6bb-a7e5fb42a44f","execution":{"iopub.status.busy":"2023-09-13T07:27:26.284538Z","iopub.status.idle":"2023-09-13T07:27:26.285295Z","shell.execute_reply.started":"2023-09-13T07:27:26.285054Z","shell.execute_reply":"2023-09-13T07:27:26.285077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import *\nf1_score(gl_, pred, average='macro'), accuracy_score(gl_, pred)","metadata":{"id":"aaMGHw-h57fT","outputId":"67b0e84e-6ba8-47b8-d476-836eb5aa5299","execution":{"iopub.status.busy":"2023-09-13T07:27:26.286687Z","iopub.status.idle":"2023-09-13T07:27:26.287456Z","shell.execute_reply.started":"2023-09-13T07:27:26.287207Z","shell.execute_reply":"2023-09-13T07:27:26.287231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"aCJ6IQuR57h6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"D95172B857kU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"EXYsybMr57qO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"hZeAO5P257ss"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"id":"BsHrB8MjxXUm","execution":{"iopub.status.busy":"2023-09-13T07:27:26.288790Z","iopub.status.idle":"2023-09-13T07:27:26.289547Z","shell.execute_reply.started":"2023-09-13T07:27:26.289307Z","shell.execute_reply":"2023-09-13T07:27:26.289330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Qz2vYq_hyiA3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(multimodal_tensor.numpy(), gold_label, test_size=0.2, random_state=42)","metadata":{"id":"EuV5LVc-xgNM","execution":{"iopub.status.busy":"2023-09-13T07:27:26.290876Z","iopub.status.idle":"2023-09-13T07:27:26.291665Z","shell.execute_reply.started":"2023-09-13T07:27:26.291425Z","shell.execute_reply":"2023-09-13T07:27:26.291448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np","metadata":{"id":"sOUu5-VYx19D","execution":{"iopub.status.busy":"2023-09-13T07:27:26.293010Z","iopub.status.idle":"2023-09-13T07:27:26.293755Z","shell.execute_reply.started":"2023-09-13T07:27:26.293517Z","shell.execute_reply":"2023-09-13T07:27:26.293540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.shape(X_train), np.shape(X_test)","metadata":{"id":"xA0OtdMOxuji","outputId":"bedc3117-7ee2-4e29-d5cf-151f3e6f5184","execution":{"iopub.status.busy":"2023-09-13T07:27:26.295105Z","iopub.status.idle":"2023-09-13T07:27:26.295833Z","shell.execute_reply.started":"2023-09-13T07:27:26.295594Z","shell.execute_reply":"2023-09-13T07:27:26.295617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit(X_train)\n\npred = kmeans.predict(X_test)\n","metadata":{"id":"R66QQH5bxwNx","execution":{"iopub.status.busy":"2023-09-13T07:27:26.297413Z","iopub.status.idle":"2023-09-13T07:27:26.298179Z","shell.execute_reply.started":"2023-09-13T07:27:26.297912Z","shell.execute_reply":"2023-09-13T07:27:26.297958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred","metadata":{"id":"79rAOtOhyMOg","outputId":"c9efe62b-3249-48d6-ba08-5959f9025e54","execution":{"iopub.status.busy":"2023-09-13T07:27:26.299499Z","iopub.status.idle":"2023-09-13T07:27:26.300259Z","shell.execute_reply.started":"2023-09-13T07:27:26.300020Z","shell.execute_reply":"2023-09-13T07:27:26.300043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_test","metadata":{"id":"emeIrqw6yNXw","execution":{"iopub.status.busy":"2023-09-13T07:27:26.301611Z","iopub.status.idle":"2023-09-13T07:27:26.302365Z","shell.execute_reply.started":"2023-09-13T07:27:26.302122Z","shell.execute_reply":"2023-09-13T07:27:26.302145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score","metadata":{"id":"Y4QYG7g3yPZq","execution":{"iopub.status.busy":"2023-09-13T07:27:26.303684Z","iopub.status.idle":"2023-09-13T07:27:26.304444Z","shell.execute_reply.started":"2023-09-13T07:27:26.304203Z","shell.execute_reply":"2023-09-13T07:27:26.304226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_score(y_test, pred, average='micro')","metadata":{"id":"aGa0BNozyUiV","outputId":"8204a80a-7d12-451b-a5f3-3d1ce2dad556","execution":{"iopub.status.busy":"2023-09-13T07:27:26.305753Z","iopub.status.idle":"2023-09-13T07:27:26.306533Z","shell.execute_reply.started":"2023-09-13T07:27:26.306269Z","shell.execute_reply":"2023-09-13T07:27:26.306293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im_tensor.shape, tx_tensor.shape","metadata":{"id":"kITfu_O9zJra","outputId":"909b7442-cd63-44cd-d1a9-8f18332b37ee","execution":{"iopub.status.busy":"2023-09-13T07:27:26.307897Z","iopub.status.idle":"2023-09-13T07:27:26.308665Z","shell.execute_reply.started":"2023-09-13T07:27:26.308420Z","shell.execute_reply":"2023-09-13T07:27:26.308443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(torch.cat((im_tensor,tx_tensor),dim=1).numpy(), gold_label, test_size=0.33, random_state=42)","metadata":{"id":"RjvrK6p6yaOZ","execution":{"iopub.status.busy":"2023-09-13T07:27:26.310092Z","iopub.status.idle":"2023-09-13T07:27:26.311076Z","shell.execute_reply.started":"2023-09-13T07:27:26.310660Z","shell.execute_reply":"2023-09-13T07:27:26.310719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kmeans = KMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit(X_train)\n\npred = kmeans.predict(X_test)\nf1_score(y_test, pred, average='micro')","metadata":{"id":"DCqBZ4l-y4Lu","outputId":"70c411be-2d5a-4ced-c875-27f372cb3798","execution":{"iopub.status.busy":"2023-09-13T07:27:26.312636Z","iopub.status.idle":"2023-09-13T07:27:26.313436Z","shell.execute_reply.started":"2023-09-13T07:27:26.313180Z","shell.execute_reply":"2023-09-13T07:27:26.313205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"6uExwqudzWw9"},"execution_count":null,"outputs":[]}]}